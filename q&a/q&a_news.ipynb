{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install langchain_community tiktoken langchain-openai langchainhub chromadb langchain ragas datasets cohere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dotenv\n",
    "from langchain.text_splitter import CharacterTextSplitter, RecursiveCharacterTextSplitter\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.document_loaders import DirectoryLoader\n",
    "from langchain_openai import AzureOpenAIEmbeddings\n",
    "dotenv.load_dotenv()\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from ragas import evaluate\n",
    "from ragas.metrics import (\n",
    "    faithfulness,\n",
    "    answer_relevancy,\n",
    "    context_recall,\n",
    "    context_precision,\n",
    "    answer_similarity,\n",
    "    answer_correctness,\n",
    ")\n",
    "from datasets import Dataset\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "from operator import itemgetter\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.tracebacklimit = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_API_KEY = os.environ.get(\"OPENAI_API_KEY\")\n",
    "OPENAI_API_VERSION = os.environ.get(\"OPENAI_API_VERSION\")\n",
    "AZURE_OPENAI_ENDPOINT = os.environ.get(\"AZURE_OPENAI_ENDPOINT\")\n",
    "OPENAI_MODEL = os.environ.get(\"OPENAI_MODEL\")\n",
    "OPENAI_DEPLOYMENT = os.environ.get(\"OPENAI_DEPLOYMENT\")\n",
    "EMBEDDING_MODEL = os.environ.get(\"EMBEDDING_MODEL\")\n",
    "EMBEDDING_DEPLOYMENT = os.environ.get(\"EMBEDDING_DEPLOYMENT\")\n",
    "OPENAI_MODEL_GPT4 = os.environ.get(\"OPENAI_MODEL_GPT4\")\n",
    "OPENAI_DEPLOYMENT_GPT4 = os.environ.get(\"OPENAI_DEPLOYMENT_GPT4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation part"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = [\n",
    "    \"Who was Alexei Navalny supposed to be exchanged for in the planned prisoner swap, according to his colleague Maria Pevchikh?\",\n",
    "    \"Why did the door blow out of Boeing 737 Max shortly after take-off?\",\n",
    "    \"When did it mark 2 years since Russia's envasion in Ukraine?\",\n",
    "    \"What is Sora AI, how does it work, and when can the general public expect to use it?\",\n",
    "    \"What are the potential key issues that could impact the 2024 U.S. presidential election between Joe Biden and Donald Trump, and how might they impact the outcome?\",\n",
    "    \"Why does Elon Musk want a bigger stake in Tesla, and what concerns does he express about the current structure of the company?\",\n",
    "    \"What are the shopping habits of Gen Alpha, and why are mature brands interested in targeting this demographic?\",\n",
    "    \"What happened during the Hamas attacks on Israel in 2023?\",\n",
    "    \"On January 15, 2024, how did Kim Jong Un call South Korea?\",\n",
    "    \"Why did Prince William pull out of the godfather's memorial service on 27.02.2024?\"\n",
    "]\n",
    "\n",
    "ground_truths = [\n",
    "    [\"Alexei Navalny was supposed to be exchanged for Vadim Krasikov, a Russian hitman serving a life sentence for murder in Germany, as claimed by Maria Pevchikh.\"],  \n",
    "    [\"Bolts were missing.\"],\n",
    "    [\"On February 24, 2024.\"],\n",
    "    [\"Sora AI is an artificial intelligence tool developed by OpenAI that can generate realistic videos up to 1 minute long based on textual prompts. It utilizes diffusion models, a method used in AI image generators, to create videos by understanding the association between images and accompanying alt text. As of now, Sora is not available to the general public; OpenAI is following a cautious approach by first testing it with a small group of 'red teamers' for potential harm or risks, followed by availability to visual artists, designers, and filmmakers before a potential public release, likely under a pay-to-use model similar to GPT. While Sora has shown significant advancements in AI video generation compared to previous attempts, it is not perfect, with occasional flaws and limitations seen in hand-picked videos released by OpenAI.\"],\n",
    "    [\"The potential key issues that could impact the 2024 U.S. presidential election between Joe Biden and Donald Trump include contrasting economic views, with Americans historically voting based on their economic well-being; the contentious topics of abortion and immigration, with Democrats focusing on abortion rights and Republicans emphasizing border security; and external factors like the Gaza War and its impact on Biden's support base. Other factors include crime rates, environmental concerns, and foreign policy. Additionally, the health and age of both candidates could be scrutinized, and the potential emergence of third-party candidates or independents might introduce unpredictability. Trump's legal challenges, facing 91 charges and four criminal trials, could influence public opinion, and the specter of the January 2021 Capitol attack may resonate differently among Republican and Democratic voters. Overall, these factors contribute to the complexity and uncertainty of the upcoming presidential race.\"],\n",
    "    [\"Elon Musk wants a bigger stake in Tesla to gain more control over the company's direction, especially regarding its investments in artificial intelligence (AI) features. He is concerned about Tesla's vulnerability to a 'takeover by dubious interests' and aims to have 25% voting control to ensure the company's leadership in AI and robotics. Musk suggests that without this control, he would prefer to develop products outside of Tesla.\"],\n",
    "    [\"Gen Alpha, born between 2010 and 2024, prefers to shop at adult brands like Lululemon, Sephora, Walmart, and Target, following the trends of their millennial parents. Adult brands are interested in targeting Gen Alpha due to their economic potential, with an estimated economic footprint of $5.46 trillion by 2029. These brands can secure the loyalty of the next generation by expanding their offerings to cater to the specific needs of Gen Alpha.\"],\n",
    "    [\"On the morning of 7 October, waves of Hamas gunmen stormed across Gaza's border into Israel, killing about 1,200 people. Hamas also fired thousands of rockets. Those killed included children, the elderly and 364 young people at a music festival.  Hamas took more than 250 others to Gaza as hostages.\"],\n",
    "    [\"Kim Jong Un  'principal enemy.' He intensified nuclear threats, conducted missile tests, and abolished government agencies promoting cooperation and reunification. Analysts, including Robert L. Carlin and Siegfried Hecker, suggest he may be preparing for a military attack on South Korea.\"],\n",
    "    [\"Due to 'personal matter'.\"]\n",
    "]\n",
    "answers_llm = []\n",
    "contexts_llm = [[\"\"],[\"\"],[\"\"],[\"\"],[\"\"],[\"\"],[\"\"],[\"\"],[\"\"],[\"\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_client = AzureOpenAIEmbeddings(\n",
    "    azure_deployment=EMBEDDING_DEPLOYMENT,\n",
    "    openai_api_version=OPENAI_API_VERSION)\n",
    "llm = AzureChatOpenAI(model_name=OPENAI_MODEL, azure_deployment=OPENAI_DEPLOYMENT,temperature=0)\n",
    "llm_gpt4 = AzureChatOpenAI(model_name=OPENAI_MODEL_GPT4, azure_deployment=OPENAI_DEPLOYMENT_GPT4,temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation_llm(questions, answers, contexts, ground_truths):\n",
    "    data = {\n",
    "        \"question\": questions,\n",
    "        \"answer\": answers,\n",
    "        \"contexts\": contexts,\n",
    "        \"ground_truths\": ground_truths\n",
    "    }\n",
    "    dataset = Dataset.from_dict(data)\n",
    "    azure_configs = {\n",
    "        \"base_url\": AZURE_OPENAI_ENDPOINT,\n",
    "        \"model_deployment\": OPENAI_DEPLOYMENT,\n",
    "        \"model_name\": OPENAI_MODEL,\n",
    "        \"embedding_deployment\": EMBEDDING_DEPLOYMENT,\n",
    "        \"embedding_name\": EMBEDDING_MODEL,  \n",
    "    }\n",
    "\n",
    "    azure_model = AzureChatOpenAI(\n",
    "        openai_api_version=OPENAI_API_VERSION,\n",
    "        azure_endpoint=azure_configs[\"base_url\"],\n",
    "        azure_deployment=azure_configs[\"model_deployment\"],\n",
    "        model=azure_configs[\"model_name\"],\n",
    "        validate_base_url=False,\n",
    "    )\n",
    "\n",
    "    azure_embeddings = AzureOpenAIEmbeddings(\n",
    "        openai_api_version=OPENAI_API_VERSION,\n",
    "        azure_endpoint=azure_configs[\"base_url\"],\n",
    "        azure_deployment=azure_configs[\"embedding_deployment\"],\n",
    "        model=azure_configs[\"embedding_name\"],\n",
    "    )\n",
    "    result = evaluate(\n",
    "        dataset = dataset, \n",
    "        metrics=[\n",
    "            faithfulness,\n",
    "            answer_relevancy,\n",
    "            answer_similarity,\n",
    "            answer_correctness,\n",
    "        ], \n",
    "        llm=azure_model, \n",
    "        embeddings=azure_embeddings,\n",
    "    )\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation_rag(questions, answers, contexts, ground_truths):\n",
    "    data = {\n",
    "        \"question\": questions,\n",
    "        \"answer\": answers,\n",
    "        \"contexts\": contexts,\n",
    "        \"ground_truths\": ground_truths\n",
    "    }\n",
    "    dataset = Dataset.from_dict(data)\n",
    "    azure_configs = {\n",
    "        \"base_url\": AZURE_OPENAI_ENDPOINT,\n",
    "        \"model_deployment\": OPENAI_DEPLOYMENT,\n",
    "        \"model_name\": OPENAI_MODEL,\n",
    "        \"embedding_deployment\": EMBEDDING_DEPLOYMENT,\n",
    "        \"embedding_name\": EMBEDDING_MODEL,  # most likely\n",
    "    }\n",
    "\n",
    "    azure_model = AzureChatOpenAI(\n",
    "        openai_api_version=OPENAI_API_VERSION,\n",
    "        azure_endpoint=azure_configs[\"base_url\"],\n",
    "        azure_deployment=azure_configs[\"model_deployment\"],\n",
    "        model=azure_configs[\"model_name\"],\n",
    "        validate_base_url=False,\n",
    "    )\n",
    "\n",
    "    azure_embeddings = AzureOpenAIEmbeddings(\n",
    "        openai_api_version=OPENAI_API_VERSION,\n",
    "        azure_endpoint=azure_configs[\"base_url\"],\n",
    "        azure_deployment=azure_configs[\"embedding_deployment\"],\n",
    "        model=azure_configs[\"embedding_name\"],\n",
    "    )\n",
    "    result = evaluate(\n",
    "        dataset = dataset, \n",
    "        metrics=[\n",
    "            faithfulness,\n",
    "            answer_relevancy,\n",
    "            context_precision,\n",
    "            context_recall,\n",
    "            answer_similarity,\n",
    "            answer_correctness,\n",
    "        ], \n",
    "        llm=azure_model, \n",
    "        embeddings=azure_embeddings,\n",
    "        raise_exceptions=False,\n",
    "    )\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\"System\", \"Faithfulness\", \"Answer Relevancy\", \"Context Precision\", \"Context Recall\", \"Answer Similarity\", \"Answer Correctness\"]\n",
    "results_df = pd.DataFrame(columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_average = 0\n",
    "def find_highest(average_score):\n",
    "    global max_average\n",
    "    if average_score > max_average:\n",
    "        max_average = average_score\n",
    "        print(\"This is the new best value!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dictionary(result):\n",
    "    dict_result = dict(result)\n",
    "    average_score = sum(dict_result.values()) / len(dict_result)\n",
    "    print(f\"The average score is: {average_score}\")\n",
    "    find_highest(average_score)\n",
    "    return average_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_system(system_name, questions, answers, contexts, ground_truths):\n",
    "    result = evaluation_rag(questions, answers, contexts, ground_truths)\n",
    "    average = dictionary(result)\n",
    "    # Create a dictionary to store the results\n",
    "    system_results = {\n",
    "        \"System\": system_name,\n",
    "        \"Faithfulness\": result[\"faithfulness\"],\n",
    "        \"Answer Relevancy\": result[\"answer_relevancy\"],\n",
    "        \"Context Precision\": result[\"context_precision\"],\n",
    "        \"Context Recall\": result[\"context_recall\"],\n",
    "        \"Answer Similarity\": result[\"answer_similarity\"],\n",
    "        \"Answer Correctness\": result[\"answer_correctness\"],\n",
    "        \"Average\": average\n",
    "    }\n",
    "    df_system_results = pd.DataFrame([system_results])\n",
    "    return df_system_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_LLM(system_name, questions, answers, contexts, ground_truths):\n",
    "    result = evaluation_rag(questions, answers, contexts, ground_truths)\n",
    "    average = dictionary(result)\n",
    "    # Create a dictionary to store the results\n",
    "    system_results = {\n",
    "        \"System\": system_name,\n",
    "        \"Faithfulness\": result[\"faithfulness\"],\n",
    "        \"Answer Relevancy\": result[\"answer_relevancy\"],\n",
    "        \"Context Precision\": np.nan,\n",
    "        \"Context Recall\": np.nan,\n",
    "        \"Answer Similarity\": result[\"answer_similarity\"],\n",
    "        \"Answer Correctness\": result[\"answer_correctness\"],\n",
    "        \"Average\": average\n",
    "    }\n",
    "    df_llm_results = pd.DataFrame([system_results])\n",
    "    return df_llm_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General answers by LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"{question}\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_chain =(\n",
    "    { \"question\": itemgetter(\"question\")}\n",
    "    | RunnablePassthrough()\n",
    "    | {\"response\": prompt | llm}\n",
    ")\n",
    "llm_chain_gpt4 =(\n",
    "    { \"question\": itemgetter(\"question\")}\n",
    "    | RunnablePassthrough()\n",
    "    | {\"response\": prompt | llm_gpt4}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for query in questions:\n",
    "    response = llm_chain.invoke({\"question\": query})\n",
    "    answers_llm.append(response[\"response\"].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "passing column names as 'ground_truths' is deprecated and will be removed in the next version, please use 'ground_truth' instead. Note that `ground_truth` should be of type string and not Sequence[string] like `ground_truths`\n",
      "Evaluating: 100%|██████████| 60/60 [00:08<00:00,  6.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average score is: 0.6253870004200923\n",
      "This is the new best value!\n",
      "    System  Faithfulness  Answer Relevancy  Context Precision  Context Recall  \\\n",
      "0  GPT-3.5           1.0          0.375595                NaN             NaN   \n",
      "\n",
      "   Answer Similarity  Answer Correctness   Average  \n",
      "0           0.847668             0.45406  0.625387  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sigitalapina\\AppData\\Local\\Temp\\ipykernel_16924\\800954320.py:2: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  results_df = pd.concat([results_df, llm_results], ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "llm_results = evaluate_LLM(\"GPT-3.5\", questions, answers_llm, contexts_llm, ground_truths)\n",
    "results_df = pd.concat([results_df, llm_results], ignore_index=True)\n",
    "print(llm_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "passing column names as 'ground_truths' is deprecated and will be removed in the next version, please use 'ground_truth' instead. Note that `ground_truth` should be of type string and not Sequence[string] like `ground_truths`\n",
      "Evaluating: 100%|██████████| 60/60 [00:07<00:00,  7.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average score is: 0.5506575325401026\n",
      "  System  Faithfulness  Answer Relevancy  Context Precision  Context Recall  \\\n",
      "0  GPT-4          0.75          0.360955                NaN             NaN   \n",
      "\n",
      "   Answer Similarity  Answer Correctness   Average  \n",
      "0           0.835999            0.415325  0.550658  \n"
     ]
    }
   ],
   "source": [
    "answers_llm_gpt4 = []\n",
    "for query in questions:\n",
    "    response = llm_chain_gpt4.invoke({\"question\": query})\n",
    "    answers_llm_gpt4.append(response[\"response\"].content)\n",
    "llm_results_gpt4 = evaluate_LLM(\"GPT-4\",questions, answers_llm_gpt4, contexts_llm, ground_truths)\n",
    "results_df = pd.concat([results_df, llm_results_gpt4], ignore_index=True)\n",
    "print(llm_results_gpt4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>System</th>\n",
       "      <th>Faithfulness</th>\n",
       "      <th>Answer Relevancy</th>\n",
       "      <th>Context Precision</th>\n",
       "      <th>Context Recall</th>\n",
       "      <th>Answer Similarity</th>\n",
       "      <th>Answer Correctness</th>\n",
       "      <th>Average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GPT-3.5</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.375595</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.847668</td>\n",
       "      <td>0.454060</td>\n",
       "      <td>0.625387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GPT-4</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.360955</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.835999</td>\n",
       "      <td>0.415325</td>\n",
       "      <td>0.550658</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    System  Faithfulness  Answer Relevancy  Context Precision  Context Recall  \\\n",
       "0  GPT-3.5          1.00          0.375595                NaN             NaN   \n",
       "1    GPT-4          0.75          0.360955                NaN             NaN   \n",
       "\n",
       "   Answer Similarity  Answer Correctness   Average  \n",
       "0           0.847668            0.454060  0.625387  \n",
       "1           0.835999            0.415325  0.550658  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"User input {question}. \n",
    "Context {context}.\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieval_chain(prompt, retriever, llm):\n",
    "    retrieval_augmented_qa_chain = (\n",
    "        {\"context\": itemgetter(\"question\") | retriever, \"question\": itemgetter(\"question\")}\n",
    "        | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
    "        | {\"response\": prompt | llm, \"context\": itemgetter(\"context\")}\n",
    "    )\n",
    "    return retrieval_augmented_qa_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DirectoryLoader('../news', glob=\"./*.txt\", loader_cls=TextLoader)\n",
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = CharacterTextSplitter()\n",
    "chunks = text_splitter.split_documents(documents)\n",
    "db_naive = Chroma.from_documents(chunks, embeddings_client, persist_directory = \"../vectordb/naive\")\n",
    "retriever_naive = db_naive.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_naive = Chroma(persist_directory = \"../vectordb/naive\", embedding_function=embeddings_client)\n",
    "retriever_naive = db_naive.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "answers_naive = []\n",
    "contexts_naive = []\n",
    "for query in questions:\n",
    "    try:  \n",
    "        response = retrieval_chain(prompt, retriever_naive, llm).invoke({\"question\": query})\n",
    "        # Access the response content\n",
    "        answers_naive.append(response[\"response\"].content)\n",
    "        # Access the context content\n",
    "        context_content = [context.page_content for context in response[\"context\"]]\n",
    "        contexts_naive.append(context_content)  \n",
    "    except Exception as e:  \n",
    "        print(f\"Warning: {e}\" + \"on the following question: \" + query)  \n",
    "        answers_naive.append(\"No answer\")\n",
    "        context_full = retriever_naive.get_relevant_documents(query)\n",
    "        context_content = [context.page_content for context in context_full]\n",
    "        contexts_naive.append(context_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "passing column names as 'ground_truths' is deprecated and will be removed in the next version, please use 'ground_truth' instead. Note that `ground_truth` should be of type string and not Sequence[string] like `ground_truths`\n",
      "Evaluating:  23%|██▎       | 14/60 [00:05<00:16,  2.85it/s]Task exception was never retrieved\n",
      "future: <Task finished name='Task-186' coro=<AsyncClient.aclose() done, defined at c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\httpx\\_client.py:2011> exception=RuntimeError('Event loop is closed')>\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\httpx\\_client.py\", line 2018, in aclose\n",
      "    await self._transport.aclose()\n",
      "  File \"c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\httpx\\_transports\\default.py\", line 385, in aclose\n",
      "    await self._pool.aclose()\n",
      "  File \"c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\httpcore\\_async\\connection_pool.py\", line 313, in aclose\n",
      "    await self._close_connections(closing_connections)\n",
      "  File \"c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\httpcore\\_async\\connection_pool.py\", line 305, in _close_connections\n",
      "    await connection.aclose()\n",
      "  File \"c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\httpcore\\_async\\connection.py\", line 171, in aclose\n",
      "    await self._connection.aclose()\n",
      "  File \"c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\httpcore\\_async\\http11.py\", line 265, in aclose\n",
      "    await self._network_stream.aclose()\n",
      "  File \"c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\httpcore\\_backends\\anyio.py\", line 54, in aclose\n",
      "    await self._stream.aclose()\n",
      "  File \"c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\anyio\\streams\\tls.py\", line 202, in aclose\n",
      "    await self.transport_stream.aclose()\n",
      "  File \"c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 1191, in aclose\n",
      "    self._transport.close()\n",
      "  File \"C:\\Users\\sigitalapina\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\selector_events.py\", line 860, in close\n",
      "    self._loop.call_soon(self._call_connection_lost, None)\n",
      "  File \"C:\\Users\\sigitalapina\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\base_events.py\", line 761, in call_soon\n",
      "    self._check_closed()\n",
      "  File \"C:\\Users\\sigitalapina\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\base_events.py\", line 519, in _check_closed\n",
      "    raise RuntimeError('Event loop is closed')\n",
      "RuntimeError: Event loop is closed\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-187' coro=<AsyncClient.aclose() done, defined at c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\httpx\\_client.py:2011> exception=RuntimeError('Event loop is closed')>\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\httpx\\_client.py\", line 2018, in aclose\n",
      "    await self._transport.aclose()\n",
      "  File \"c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\httpx\\_transports\\default.py\", line 385, in aclose\n",
      "    await self._pool.aclose()\n",
      "  File \"c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\httpcore\\_async\\connection_pool.py\", line 313, in aclose\n",
      "    await self._close_connections(closing_connections)\n",
      "  File \"c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\httpcore\\_async\\connection_pool.py\", line 305, in _close_connections\n",
      "    await connection.aclose()\n",
      "  File \"c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\httpcore\\_async\\connection.py\", line 171, in aclose\n",
      "    await self._connection.aclose()\n",
      "  File \"c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\httpcore\\_async\\http11.py\", line 265, in aclose\n",
      "    await self._network_stream.aclose()\n",
      "  File \"c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\httpcore\\_backends\\anyio.py\", line 54, in aclose\n",
      "    await self._stream.aclose()\n",
      "  File \"c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\anyio\\streams\\tls.py\", line 202, in aclose\n",
      "    await self.transport_stream.aclose()\n",
      "  File \"c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 1191, in aclose\n",
      "    self._transport.close()\n",
      "  File \"C:\\Users\\sigitalapina\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\selector_events.py\", line 860, in close\n",
      "    self._loop.call_soon(self._call_connection_lost, None)\n",
      "  File \"C:\\Users\\sigitalapina\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\base_events.py\", line 761, in call_soon\n",
      "    self._check_closed()\n",
      "  File \"C:\\Users\\sigitalapina\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\base_events.py\", line 519, in _check_closed\n",
      "    raise RuntimeError('Event loop is closed')\n",
      "RuntimeError: Event loop is closed\n",
      "Evaluating: 100%|██████████| 60/60 [00:13<00:00,  4.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average score is: 0.8433780682264684\n",
      "This is the new best value!\n",
      "  System  Faithfulness  Answer Relevancy  Context Precision  Context Recall  \\\n",
      "0  Naive      0.904762          0.773143                0.9            0.98   \n",
      "\n",
      "   Answer Similarity  Answer Correctness   Average  \n",
      "0           0.902388            0.599976  0.843378  \n"
     ]
    }
   ],
   "source": [
    "result_naive_rag = evaluate_system(\"Naive\", questions, answers_naive, contexts_naive, ground_truths)\n",
    "results_df = pd.concat([results_df, result_naive_rag], ignore_index=True)\n",
    "print(result_naive_rag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>System</th>\n",
       "      <th>Faithfulness</th>\n",
       "      <th>Answer Relevancy</th>\n",
       "      <th>Context Precision</th>\n",
       "      <th>Context Recall</th>\n",
       "      <th>Answer Similarity</th>\n",
       "      <th>Answer Correctness</th>\n",
       "      <th>Average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GPT-3.5</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.375595</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.847668</td>\n",
       "      <td>0.454060</td>\n",
       "      <td>0.625387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GPT-4</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.360955</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.835999</td>\n",
       "      <td>0.415325</td>\n",
       "      <td>0.550658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Naive</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.773143</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.902388</td>\n",
       "      <td>0.599976</td>\n",
       "      <td>0.843378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Recursive</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.772477</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.902388</td>\n",
       "      <td>0.643756</td>\n",
       "      <td>0.852548</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      System  Faithfulness  Answer Relevancy  Context Precision  \\\n",
       "0    GPT-3.5      1.000000          0.375595                NaN   \n",
       "1      GPT-4      0.750000          0.360955                NaN   \n",
       "2      Naive      0.904762          0.773143                0.9   \n",
       "3  Recursive      0.916667          0.772477                0.9   \n",
       "\n",
       "   Context Recall  Answer Similarity  Answer Correctness   Average  \n",
       "0             NaN           0.847668            0.454060  0.625387  \n",
       "1             NaN           0.835999            0.415325  0.550658  \n",
       "2            0.98           0.902388            0.599976  0.843378  \n",
       "3            0.98           0.902388            0.643756  0.852548  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## try recursive text splitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder()\n",
    "chunks_r = text_splitter.split_documents(documents)\n",
    "db_basic = Chroma.from_documents(chunks_r, embeddings_client, persist_directory = \"../vectordb/recursive_basic\")\n",
    "retriever_basic = db_basic.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_basic = Chroma(persist_directory = \"../vectordb/recursive_basic\", embedding_function=embeddings_client)\n",
    "retriever_basic = db_basic.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Error code: 400 - {'error': {'message': \"This model's maximum context length is 8192 tokens. However, your messages resulted in 11067 tokens. Please reduce the length of the messages.\", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}}on the following question: What are the shopping habits of Gen Alpha, and why are mature brands interested in targeting this demographic?\n"
     ]
    }
   ],
   "source": [
    "answers_recursive = []\n",
    "contexts_recursive = []\n",
    "for query in questions:\n",
    "    try:  \n",
    "        response = retrieval_chain(prompt, retriever_basic, llm).invoke({\"question\": query})\n",
    "        # Access the response content\n",
    "        answers_recursive.append(response[\"response\"].content)\n",
    "        # Access the context content\n",
    "        context_content = [context.page_content for context in response[\"context\"]]\n",
    "        contexts_recursive.append(context_content)  \n",
    "    except Exception as e:  \n",
    "        print(f\"Warning: {e}\" + \"on the following question: \" + query)  \n",
    "        answers_recursive.append(\"No answer\")\n",
    "        context_full = retriever_basic.get_relevant_documents(query)\n",
    "        context_content = [context.page_content for context in context_full]\n",
    "        contexts_recursive.append(context_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "passing column names as 'ground_truths' is deprecated and will be removed in the next version, please use 'ground_truth' instead. Note that `ground_truth` should be of type string and not Sequence[string] like `ground_truths`\n",
      "Evaluating: 100%|██████████| 60/60 [00:11<00:00,  5.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average score is: 0.8525479235764283\n",
      "This is the new best value!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>System</th>\n",
       "      <th>Faithfulness</th>\n",
       "      <th>Answer Relevancy</th>\n",
       "      <th>Context Precision</th>\n",
       "      <th>Context Recall</th>\n",
       "      <th>Answer Similarity</th>\n",
       "      <th>Answer Correctness</th>\n",
       "      <th>Average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Recursive</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.772477</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.902388</td>\n",
       "      <td>0.643756</td>\n",
       "      <td>0.852548</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      System  Faithfulness  Answer Relevancy  Context Precision  \\\n",
       "0  Recursive      0.916667          0.772477                0.9   \n",
       "\n",
       "   Context Recall  Answer Similarity  Answer Correctness   Average  \n",
       "0            0.98           0.902388            0.643756  0.852548  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_recursive = evaluate_system(\"Recursive\", questions, answers_naive, contexts_naive, ground_truths)\n",
    "results_df = pd.concat([results_df, result_recursive], ignore_index=True)\n",
    "result_recursive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## chunk size change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_and_evaluate(name, retriever, prompt, llm, results_df):\n",
    "    answers = []\n",
    "    contexts_extra = []\n",
    "\n",
    "    for query in questions:\n",
    "        try:  \n",
    "            response = retrieval_chain(prompt, retriever, llm).invoke({\"question\": query})\n",
    "            # Access the response content\n",
    "            answers.append(response[\"response\"].content)\n",
    "            # Access the context content\n",
    "            context_content = [context.page_content for context in response[\"context\"]]\n",
    "            contexts_extra.append(context_content)  \n",
    "        except Exception as e:  \n",
    "            print(f\"Warning: {e}\" + \"on the following question: \" + query)  \n",
    "            answers.append(\"No answer\")\n",
    "            context_full = retriever.get_relevant_documents(query)\n",
    "            context_content = [context.page_content for context in context_full]\n",
    "            contexts_extra.append(context_content)\n",
    "\n",
    "    result = evaluate_system(name, questions, answers, contexts_extra, ground_truths)\n",
    "    results_df = pd.concat([results_df, result], ignore_index=True)\n",
    "    return result, results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55\n"
     ]
    }
   ],
   "source": [
    "# # THE FIRST TIME RUN THIS, AFTER RUN THE NEXT CELL\n",
    "# text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(chunk_size = 1000, chunk_overlap = 0)\n",
    "# chunks_1000 = text_splitter.split_documents(documents)\n",
    "# print(len(chunks_1000))\n",
    "# db_1000 = Chroma.from_documents(chunks_1000, embeddings_client, persist_directory = \"../news/vectordb-edit/recursive_1000\")\n",
    "# db_1000.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# db_1000 = Chroma(persist_directory = \"../news/vectordb-edit/recursive_1000\", embedding_function=embeddings_client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "passing column names as 'ground_truths' is deprecated and will be removed in the next version, please use 'ground_truth' instead. Note that `ground_truth` should be of type string and not Sequence[string] like `ground_truths`\n",
      "Evaluating: 100%|██████████| 60/60 [00:10<00:00,  5.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average score is: 0.7505457735075017\n",
      "This is the new best value!\n",
      "CHUNK SIZE 1000, 0% overlap\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>System</th>\n",
       "      <th>Faithfulness</th>\n",
       "      <th>Answer Relevancy</th>\n",
       "      <th>Context Precision</th>\n",
       "      <th>Context Recall</th>\n",
       "      <th>Answer Similarity</th>\n",
       "      <th>Answer Correctness</th>\n",
       "      <th>Average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Chunk 1000, overlap 0%</td>\n",
       "      <td>0.716667</td>\n",
       "      <td>0.599047</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.847668</td>\n",
       "      <td>0.459893</td>\n",
       "      <td>0.750546</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   System  Faithfulness  Answer Relevancy  Context Precision  \\\n",
       "0  Chunk 1000, overlap 0%      0.716667          0.599047                0.9   \n",
       "\n",
       "   Context Recall  Answer Similarity  Answer Correctness   Average  \n",
       "0            0.98           0.847668            0.459893  0.750546  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# retriever_1000 = db_1000.as_retriever()\n",
    "# result_1000_0 = run_and_evaluate(\"Chunk 1000, overlap 0%\",retriever_1000, prompt, llm, results_df)\n",
    "# print(\"CHUNK SIZE 1000, 0% overlap\")\n",
    "# result_1000_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>System</th>\n",
       "      <th>Faithfulness</th>\n",
       "      <th>Answer Relevancy</th>\n",
       "      <th>Context Precision</th>\n",
       "      <th>Context Recall</th>\n",
       "      <th>Answer Similarity</th>\n",
       "      <th>Answer Correctness</th>\n",
       "      <th>Average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GPT-3.5</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.375595</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.847668</td>\n",
       "      <td>0.454060</td>\n",
       "      <td>0.625387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GPT-4</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.360955</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.835999</td>\n",
       "      <td>0.415325</td>\n",
       "      <td>0.550658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Naive</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.773143</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.902388</td>\n",
       "      <td>0.599976</td>\n",
       "      <td>0.843378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Recursive</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.772477</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.902388</td>\n",
       "      <td>0.643756</td>\n",
       "      <td>0.852548</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      System  Faithfulness  Answer Relevancy  Context Precision  \\\n",
       "0    GPT-3.5      1.000000          0.375595                NaN   \n",
       "1      GPT-4      0.750000          0.360955                NaN   \n",
       "2      Naive      0.904762          0.773143                0.9   \n",
       "3  Recursive      0.916667          0.772477                0.9   \n",
       "\n",
       "   Context Recall  Answer Similarity  Answer Correctness   Average  \n",
       "0             NaN           0.847668            0.454060  0.625387  \n",
       "1             NaN           0.835999            0.415325  0.550658  \n",
       "2            0.98           0.902388            0.599976  0.843378  \n",
       "3            0.98           0.902388            0.643756  0.852548  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.to_csv(f\"../news/results/results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of chunks for chunk size 500, overlap 0%: 102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "passing column names as 'ground_truths' is deprecated and will be removed in the next version, please use 'ground_truth' instead. Note that `ground_truth` should be of type string and not Sequence[string] like `ground_truths`\n",
      "Evaluating: 100%|██████████| 60/60 [00:10<00:00,  5.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average score is: 0.8372452594212253\n",
      "CHUNK SIZE 500, 0% overlap:\n",
      "                  System  Faithfulness  Answer Relevancy  Context Precision  \\\n",
      "0  Chunk 500, overlap 0%           1.0          0.837908                0.8   \n",
      "\n",
      "   Context Recall  Answer Similarity  Answer Correctness   Average  \n",
      "0             0.9            0.92037            0.565194  0.837245  \n",
      "Number of chunks for chunk size 500, overlap 5%: 102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "passing column names as 'ground_truths' is deprecated and will be removed in the next version, please use 'ground_truth' instead. Note that `ground_truth` should be of type string and not Sequence[string] like `ground_truths`\n",
      "Evaluating: 100%|██████████| 60/60 [00:08<00:00,  6.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average score is: 0.8221936357202062\n",
      "CHUNK SIZE 500, 5% overlap:\n",
      "                  System  Faithfulness  Answer Relevancy  Context Precision  \\\n",
      "0  Chunk 500, overlap 5%         0.875          0.741242           0.847222   \n",
      "\n",
      "   Context Recall  Answer Similarity  Answer Correctness   Average  \n",
      "0           0.925           0.919578            0.625119  0.822194  \n",
      "Number of chunks for chunk size 500, overlap 10%: 107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "passing column names as 'ground_truths' is deprecated and will be removed in the next version, please use 'ground_truth' instead. Note that `ground_truth` should be of type string and not Sequence[string] like `ground_truths`\n",
      "Evaluating:   0%|          | 0/60 [00:00<?, ?it/s]Task exception was never retrieved\n",
      "future: <Task finished name='Task-512' coro=<AsyncClient.aclose() done, defined at c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\httpx\\_client.py:2011> exception=RuntimeError('Event loop is closed')>\n",
      "RuntimeError: Event loop is closed\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-513' coro=<AsyncClient.aclose() done, defined at c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\httpx\\_client.py:2011> exception=RuntimeError('Event loop is closed')>\n",
      "RuntimeError: Event loop is closed\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-514' coro=<AsyncClient.aclose() done, defined at c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\httpx\\_client.py:2011> exception=RuntimeError('Event loop is closed')>\n",
      "RuntimeError: Event loop is closed\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-515' coro=<AsyncClient.aclose() done, defined at c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\httpx\\_client.py:2011> exception=RuntimeError('Event loop is closed')>\n",
      "RuntimeError: Event loop is closed\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-516' coro=<AsyncClient.aclose() done, defined at c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\httpx\\_client.py:2011> exception=RuntimeError('Event loop is closed')>\n",
      "RuntimeError: Event loop is closed\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-517' coro=<AsyncClient.aclose() done, defined at c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\httpx\\_client.py:2011> exception=RuntimeError('Event loop is closed')>\n",
      "RuntimeError: Event loop is closed\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-518' coro=<AsyncClient.aclose() done, defined at c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\httpx\\_client.py:2011> exception=RuntimeError('Event loop is closed')>\n",
      "RuntimeError: Event loop is closed\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-519' coro=<AsyncClient.aclose() done, defined at c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\httpx\\_client.py:2011> exception=RuntimeError('Event loop is closed')>\n",
      "RuntimeError: Event loop is closed\n",
      "Evaluating: 100%|██████████| 60/60 [00:08<00:00,  6.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average score is: 0.829080551572552\n",
      "CHUNK SIZE 500, 10% overlap:\n",
      "                   System  Faithfulness  Answer Relevancy  Context Precision  \\\n",
      "0  Chunk 500, overlap 10%         0.875          0.744905               0.85   \n",
      "\n",
      "   Context Recall  Answer Similarity  Answer Correctness   Average  \n",
      "0            0.95           0.917581            0.636998  0.829081  \n",
      "Number of chunks for chunk size 500, overlap 15%: 113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "passing column names as 'ground_truths' is deprecated and will be removed in the next version, please use 'ground_truth' instead. Note that `ground_truth` should be of type string and not Sequence[string] like `ground_truths`\n",
      "Evaluating: 100%|██████████| 60/60 [00:13<00:00,  4.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average score is: 0.8097132090775329\n",
      "CHUNK SIZE 500, 15% overlap:\n",
      "                   System  Faithfulness  Answer Relevancy  Context Precision  \\\n",
      "0  Chunk 500, overlap 15%      0.888889          0.658863                0.9   \n",
      "\n",
      "   Context Recall  Answer Similarity  Answer Correctness   Average  \n",
      "0             0.9           0.912248             0.59828  0.809713  \n",
      "Number of chunks for chunk size 500, overlap 20%: 115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "passing column names as 'ground_truths' is deprecated and will be removed in the next version, please use 'ground_truth' instead. Note that `ground_truth` should be of type string and not Sequence[string] like `ground_truths`\n",
      "Evaluating: 100%|██████████| 60/60 [00:10<00:00,  5.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average score is: 0.8507321083714663\n",
      "CHUNK SIZE 500, 20% overlap:\n",
      "                   System  Faithfulness  Answer Relevancy  Context Precision  \\\n",
      "0  Chunk 500, overlap 20%      0.907143           0.81964           0.891667   \n",
      "\n",
      "   Context Recall  Answer Similarity  Answer Correctness   Average  \n",
      "0          0.9375            0.91602            0.632423  0.850732  \n",
      "Number of chunks for chunk size 1000, overlap 0%: 55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "passing column names as 'ground_truths' is deprecated and will be removed in the next version, please use 'ground_truth' instead. Note that `ground_truth` should be of type string and not Sequence[string] like `ground_truths`\n",
      "Evaluating: 100%|██████████| 60/60 [00:10<00:00,  5.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average score is: 0.8645487695803418\n",
      "This is the new best value!\n",
      "CHUNK SIZE 1000, 0% overlap:\n",
      "                   System  Faithfulness  Answer Relevancy  Context Precision  \\\n",
      "0  Chunk 1000, overlap 0%      0.944444          0.797138              0.925   \n",
      "\n",
      "   Context Recall  Answer Similarity  Answer Correctness   Average  \n",
      "0            0.98           0.917733            0.622977  0.864549  \n",
      "Number of chunks for chunk size 1000, overlap 5%: 55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "passing column names as 'ground_truths' is deprecated and will be removed in the next version, please use 'ground_truth' instead. Note that `ground_truth` should be of type string and not Sequence[string] like `ground_truths`\n",
      "Evaluating: 100%|██████████| 60/60 [00:10<00:00,  5.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average score is: 0.849747933599466\n",
      "CHUNK SIZE 1000, 5% overlap:\n",
      "                   System  Faithfulness  Answer Relevancy  Context Precision  \\\n",
      "0  Chunk 1000, overlap 5%      0.982143          0.702075              0.925   \n",
      "\n",
      "   Context Recall  Answer Similarity  Answer Correctness   Average  \n",
      "0            0.98           0.918439             0.59083  0.849748  \n",
      "Number of chunks for chunk size 1000, overlap 10%: 56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "passing column names as 'ground_truths' is deprecated and will be removed in the next version, please use 'ground_truth' instead. Note that `ground_truth` should be of type string and not Sequence[string] like `ground_truths`\n",
      "Evaluating: 100%|██████████| 60/60 [00:09<00:00,  6.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average score is: 0.878546090006025\n",
      "This is the new best value!\n",
      "CHUNK SIZE 1000, 10% overlap:\n",
      "                    System  Faithfulness  Answer Relevancy  Context Precision  \\\n",
      "0  Chunk 1000, overlap 10%           1.0          0.781964           0.933333   \n",
      "\n",
      "   Context Recall  Answer Similarity  Answer Correctness   Average  \n",
      "0            0.98            0.92265            0.653329  0.878546  \n",
      "Number of chunks for chunk size 1000, overlap 15%: 58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "passing column names as 'ground_truths' is deprecated and will be removed in the next version, please use 'ground_truth' instead. Note that `ground_truth` should be of type string and not Sequence[string] like `ground_truths`\n",
      "Evaluating: 100%|██████████| 60/60 [00:09<00:00,  6.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average score is: 0.8503212940324234\n",
      "CHUNK SIZE 1000, 15% overlap:\n",
      "                    System  Faithfulness  Answer Relevancy  Context Precision  \\\n",
      "0  Chunk 1000, overlap 15%      0.982143          0.697939                0.9   \n",
      "\n",
      "   Context Recall  Answer Similarity  Answer Correctness   Average  \n",
      "0            0.98           0.920154            0.621692  0.850321  \n",
      "Number of chunks for chunk size 1000, overlap 20%: 58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "passing column names as 'ground_truths' is deprecated and will be removed in the next version, please use 'ground_truth' instead. Note that `ground_truth` should be of type string and not Sequence[string] like `ground_truths`\n",
      "Evaluating: 100%|██████████| 60/60 [00:11<00:00,  5.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average score is: 0.8804388538467025\n",
      "This is the new best value!\n",
      "CHUNK SIZE 1000, 20% overlap:\n",
      "                    System  Faithfulness  Answer Relevancy  Context Precision  \\\n",
      "0  Chunk 1000, overlap 20%           1.0          0.889265           0.883333   \n",
      "\n",
      "   Context Recall  Answer Similarity  Answer Correctness   Average  \n",
      "0            0.98            0.92067            0.609364  0.880439  \n",
      "Number of chunks for chunk size 2000, overlap 0%: 37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "passing column names as 'ground_truths' is deprecated and will be removed in the next version, please use 'ground_truth' instead. Note that `ground_truth` should be of type string and not Sequence[string] like `ground_truths`\n",
      "Evaluating:  27%|██▋       | 16/60 [00:04<00:14,  2.96it/s]Runner in Executor raised an exception\n",
      "TypeError: expected string or buffer\n",
      "Evaluating: 100%|██████████| 60/60 [00:10<00:00,  5.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average score is: 0.8282927393085529\n",
      "CHUNK SIZE 2000, 0% overlap:\n",
      "                   System  Faithfulness  Answer Relevancy  Context Precision  \\\n",
      "0  Chunk 2000, overlap 0%      0.758913          0.825006           0.917361   \n",
      "\n",
      "   Context Recall  Answer Similarity  Answer Correctness   Average  \n",
      "0           0.825           0.862384            0.781092  0.828293  \n",
      "Number of chunks for chunk size 2000, overlap 5%: 37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "passing column names as 'ground_truths' is deprecated and will be removed in the next version, please use 'ground_truth' instead. Note that `ground_truth` should be of type string and not Sequence[string] like `ground_truths`\n",
      "Evaluating: 100%|██████████| 60/60 [00:10<00:00,  5.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average score is: 0.8156004343654494\n",
      "CHUNK SIZE 2000, 5% overlap:\n",
      "                   System  Faithfulness  Answer Relevancy  Context Precision  \\\n",
      "0  Chunk 2000, overlap 5%           1.0          0.732886               0.95   \n",
      "\n",
      "   Context Recall  Answer Similarity  Answer Correctness  Average  \n",
      "0           0.775           0.887796             0.54792   0.8156  \n",
      "Number of chunks for chunk size 2000, overlap 10%: 37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "passing column names as 'ground_truths' is deprecated and will be removed in the next version, please use 'ground_truth' instead. Note that `ground_truth` should be of type string and not Sequence[string] like `ground_truths`\n",
      "Evaluating: 100%|██████████| 60/60 [00:08<00:00,  6.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average score is: 0.8418491446511309\n",
      "CHUNK SIZE 2000, 10% overlap:\n",
      "                    System  Faithfulness  Answer Relevancy  Context Precision  \\\n",
      "0  Chunk 2000, overlap 10%           1.0          0.832789               0.95   \n",
      "\n",
      "   Context Recall  Answer Similarity  Answer Correctness   Average  \n",
      "0            0.78           0.910568            0.577737  0.841849  \n",
      "Number of chunks for chunk size 2000, overlap 15%: 37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "passing column names as 'ground_truths' is deprecated and will be removed in the next version, please use 'ground_truth' instead. Note that `ground_truth` should be of type string and not Sequence[string] like `ground_truths`\n",
      "Evaluating: 100%|██████████| 60/60 [00:09<00:00,  6.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average score is: 0.8346051315931802\n",
      "CHUNK SIZE 2000, 15% overlap:\n",
      "                    System  Faithfulness  Answer Relevancy  Context Precision  \\\n",
      "0  Chunk 2000, overlap 15%      0.958333          0.839517               0.95   \n",
      "\n",
      "   Context Recall  Answer Similarity  Answer Correctness   Average  \n",
      "0           0.775           0.910192            0.574588  0.834605  \n",
      "Number of chunks for chunk size 2000, overlap 20%: 37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "passing column names as 'ground_truths' is deprecated and will be removed in the next version, please use 'ground_truth' instead. Note that `ground_truth` should be of type string and not Sequence[string] like `ground_truths`\n",
      "Evaluating:  82%|████████▏ | 49/60 [00:06<00:00, 13.88it/s]Invalid JSON response. Expected dictionary with key 'question'\n",
      "Evaluating: 100%|██████████| 60/60 [00:08<00:00,  6.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average score is: 0.8195863903760162\n",
      "CHUNK SIZE 2000, 20% overlap:\n",
      "                    System  Faithfulness  Answer Relevancy  Context Precision  \\\n",
      "0  Chunk 2000, overlap 20%           1.0          0.734692           0.933333   \n",
      "\n",
      "   Context Recall  Answer Similarity  Answer Correctness   Average  \n",
      "0            0.78           0.894042            0.575451  0.819586  \n",
      "Number of chunks for chunk size 3000, overlap 0%: 32\n",
      "Warning: Error code: 400 - {'error': {'message': \"This model's maximum context length is 8192 tokens. However, your messages resulted in 8197 tokens. Please reduce the length of the messages.\", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}}on the following question: What are the shopping habits of Gen Alpha, and why are mature brands interested in targeting this demographic?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "passing column names as 'ground_truths' is deprecated and will be removed in the next version, please use 'ground_truth' instead. Note that `ground_truth` should be of type string and not Sequence[string] like `ground_truths`\n",
      "Evaluating:   2%|▏         | 1/60 [00:02<02:14,  2.28s/it]Runner in Executor raised an exception\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'message': \"This model's maximum context length is 8192 tokens. However, your messages resulted in 8258 tokens. Please reduce the length of the messages.\", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}}\n",
      "Evaluating:  97%|█████████▋| 58/60 [00:21<00:00,  5.14it/s]Runner in Executor raised an exception\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'message': \"This model's maximum context length is 8192 tokens. However, your messages resulted in 8445 tokens. Please reduce the length of the messages.\", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}}\n",
      "Evaluating:  98%|█████████▊| 59/60 [02:12<00:13, 13.28s/it]Runner in Executor raised an exception\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'message': \"This model's maximum context length is 8192 tokens. However, your messages resulted in 8572 tokens. Please reduce the length of the messages.\", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}}\n",
      "Evaluating: 100%|██████████| 60/60 [02:36<00:00,  2.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average score is: 0.8325463613991283\n",
      "CHUNK SIZE 3000, 0% overlap:\n",
      "                   System  Faithfulness  Answer Relevancy  Context Precision  \\\n",
      "0  Chunk 3000, overlap 0%      0.732732          0.922064           0.708958   \n",
      "\n",
      "   Context Recall  Answer Similarity  Answer Correctness   Average  \n",
      "0        0.970775            0.88303            0.777719  0.832546  \n",
      "Number of chunks for chunk size 3000, overlap 5%: 32\n",
      "Warning: Error code: 400 - {'error': {'message': \"This model's maximum context length is 8192 tokens. However, your messages resulted in 8197 tokens. Please reduce the length of the messages.\", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}}on the following question: What are the shopping habits of Gen Alpha, and why are mature brands interested in targeting this demographic?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "passing column names as 'ground_truths' is deprecated and will be removed in the next version, please use 'ground_truth' instead. Note that `ground_truth` should be of type string and not Sequence[string] like `ground_truths`\n",
      "Evaluating:  18%|█▊        | 11/60 [00:04<00:16,  2.89it/s]Runner in Executor raised an exception\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'message': \"This model's maximum context length is 8192 tokens. However, your messages resulted in 8258 tokens. Please reduce the length of the messages.\", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}}\n",
      "Evaluating:  33%|███▎      | 20/60 [00:04<00:07,  5.27it/s]Runner in Executor raised an exception\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'message': \"This model's maximum context length is 8192 tokens. However, your messages resulted in 8239 tokens. Please reduce the length of the messages.\", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}}\n",
      "Evaluating:  95%|█████████▌| 57/60 [00:21<00:00,  6.73it/s]Runner in Executor raised an exception\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'message': \"This model's maximum context length is 8192 tokens. However, your messages resulted in 8445 tokens. Please reduce the length of the messages.\", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}}\n",
      "Evaluating:  98%|█████████▊| 59/60 [01:25<00:09,  9.49s/it]Runner in Executor raised an exception\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'message': \"This model's maximum context length is 8192 tokens. However, your messages resulted in 8572 tokens. Please reduce the length of the messages.\", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}}\n",
      "Evaluating: 100%|██████████| 60/60 [02:36<00:00,  2.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average score is: 0.8015986348093008\n",
      "CHUNK SIZE 3000, 5% overlap:\n",
      "                   System  Faithfulness  Answer Relevancy  Context Precision  \\\n",
      "0  Chunk 3000, overlap 5%      0.908051          0.715152             0.9248   \n",
      "\n",
      "   Context Recall  Answer Similarity  Answer Correctness   Average  \n",
      "0        0.617445           0.852376            0.791767  0.801599  \n",
      "Number of chunks for chunk size 3000, overlap 10%: 32\n",
      "Warning: Error code: 400 - {'error': {'message': \"This model's maximum context length is 8192 tokens. However, your messages resulted in 8197 tokens. Please reduce the length of the messages.\", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}}on the following question: What are the shopping habits of Gen Alpha, and why are mature brands interested in targeting this demographic?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "passing column names as 'ground_truths' is deprecated and will be removed in the next version, please use 'ground_truth' instead. Note that `ground_truth` should be of type string and not Sequence[string] like `ground_truths`\n",
      "Evaluating:   2%|▏         | 1/60 [00:02<02:09,  2.19s/it]Runner in Executor raised an exception\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'message': \"This model's maximum context length is 8192 tokens. However, your messages resulted in 8258 tokens. Please reduce the length of the messages.\", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}}\n",
      "Evaluating:  95%|█████████▌| 57/60 [00:19<00:00,  5.55it/s]Runner in Executor raised an exception\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'message': \"This model's maximum context length is 8192 tokens. However, your messages resulted in 8572 tokens. Please reduce the length of the messages.\", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}}\n",
      "Evaluating:  98%|█████████▊| 59/60 [01:42<00:08,  8.36s/it]Runner in Executor raised an exception\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'message': \"This model's maximum context length is 8192 tokens. However, your messages resulted in 8445 tokens. Please reduce the length of the messages.\", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}}\n",
      "Evaluating: 100%|██████████| 60/60 [02:11<00:00,  2.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average score is: 0.7963583688335518\n",
      "CHUNK SIZE 3000, 10% overlap:\n",
      "                    System  Faithfulness  Answer Relevancy  Context Precision  \\\n",
      "0  Chunk 3000, overlap 10%      0.732732          0.920121           0.690971   \n",
      "\n",
      "   Context Recall  Answer Similarity  Answer Correctness   Average  \n",
      "0        0.783333           0.875408            0.775585  0.796358  \n",
      "Number of chunks for chunk size 3000, overlap 15%: 32\n",
      "Warning: Error code: 400 - {'error': {'message': \"This model's maximum context length is 8192 tokens. However, your messages resulted in 8197 tokens. Please reduce the length of the messages.\", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}}on the following question: What are the shopping habits of Gen Alpha, and why are mature brands interested in targeting this demographic?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "passing column names as 'ground_truths' is deprecated and will be removed in the next version, please use 'ground_truth' instead. Note that `ground_truth` should be of type string and not Sequence[string] like `ground_truths`\n",
      "Evaluating:   5%|▌         | 3/60 [00:02<00:36,  1.56it/s]Runner in Executor raised an exception\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'message': \"This model's maximum context length is 8192 tokens. However, your messages resulted in 8258 tokens. Please reduce the length of the messages.\", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}}\n",
      "Evaluating:  97%|█████████▋| 58/60 [00:21<00:00,  3.69it/s]Runner in Executor raised an exception\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'message': \"This model's maximum context length is 8192 tokens. However, your messages resulted in 8572 tokens. Please reduce the length of the messages.\", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}}\n",
      "Evaluating:  98%|█████████▊| 59/60 [02:42<00:22, 22.37s/it]Runner in Executor raised an exception\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'message': \"This model's maximum context length is 8192 tokens. However, your messages resulted in 8445 tokens. Please reduce the length of the messages.\", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}}\n",
      "Evaluating: 100%|██████████| 60/60 [02:51<00:00,  2.86s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average score is: 0.7998798801496001\n",
      "CHUNK SIZE 3000, 15% overlap:\n",
      "                    System  Faithfulness  Answer Relevancy  Context Precision  \\\n",
      "0  Chunk 3000, overlap 15%      0.729689          0.920638           0.653896   \n",
      "\n",
      "   Context Recall  Answer Similarity  Answer Correctness  Average  \n",
      "0        0.837898           0.882022            0.775137  0.79988  \n",
      "Number of chunks for chunk size 3000, overlap 20%: 32\n",
      "Warning: Error code: 400 - {'error': {'message': \"This model's maximum context length is 8192 tokens. However, your messages resulted in 9375 tokens. Please reduce the length of the messages.\", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}}on the following question: What are the shopping habits of Gen Alpha, and why are mature brands interested in targeting this demographic?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "passing column names as 'ground_truths' is deprecated and will be removed in the next version, please use 'ground_truth' instead. Note that `ground_truth` should be of type string and not Sequence[string] like `ground_truths`\n",
      "Evaluating:   0%|          | 0/60 [00:00<?, ?it/s]Runner in Executor raised an exception\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'message': \"This model's maximum context length is 8192 tokens. However, your messages resulted in 9248 tokens. Please reduce the length of the messages.\", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}}\n",
      "Evaluating:  20%|██        | 12/60 [00:04<00:14,  3.21it/s]Runner in Executor raised an exception\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'message': \"This model's maximum context length is 8192 tokens. However, your messages resulted in 9389 tokens. Please reduce the length of the messages.\", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}}\n",
      "Evaluating:  35%|███▌      | 21/60 [00:04<00:06,  5.87it/s]Runner in Executor raised an exception\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'message': \"This model's maximum context length is 8192 tokens. However, your messages resulted in 8256 tokens. Please reduce the length of the messages.\", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}}\n",
      "Evaluating:  95%|█████████▌| 57/60 [00:27<00:00,  4.88it/s]Runner in Executor raised an exception\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'message': \"This model's maximum context length is 8192 tokens. However, your messages resulted in 8445 tokens. Please reduce the length of the messages.\", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}}\n",
      "Evaluating:  98%|█████████▊| 59/60 [01:44<00:09,  9.73s/it]Runner in Executor raised an exception\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'message': \"This model's maximum context length is 8192 tokens. However, your messages resulted in 9703 tokens. Please reduce the length of the messages.\", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}}\n",
      "Evaluating: 100%|██████████| 60/60 [03:21<00:00,  3.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average score is: 0.8231238890592086\n",
      "CHUNK SIZE 3000, 20% overlap:\n",
      "                    System  Faithfulness  Answer Relevancy  Context Precision  \\\n",
      "0  Chunk 3000, overlap 20%      0.863351          0.770708           0.865681   \n",
      "\n",
      "   Context Recall  Answer Similarity  Answer Correctness   Average  \n",
      "0        0.915524           0.677045            0.846434  0.823124  \n"
     ]
    }
   ],
   "source": [
    "chunk_sizes = [500, 1000, 2000, 3000]\n",
    "overlap_percentages = [0, 5, 10, 15, 20]\n",
    "\n",
    "for chunk_size in chunk_sizes:\n",
    "    for overlap_percentage in overlap_percentages:\n",
    "        # Calculate overlap based on percentage\n",
    "        chunk_overlap = int(chunk_size * overlap_percentage / 100)\n",
    "        \n",
    "        # Create text splitter\n",
    "        text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
    "        \n",
    "        # Split documents\n",
    "        chunks = text_splitter.split_documents(documents)\n",
    "        \n",
    "        # Print number of chunks\n",
    "        print(f\"Number of chunks for chunk size {chunk_size}, overlap {overlap_percentage}%: {len(chunks)}\")\n",
    "        \n",
    "        # Create Chroma database\n",
    "        db = Chroma.from_documents(chunks, embeddings_client, persist_directory=f\"../news/vectordb-edit/chunking_{chunk_size}_{overlap_percentage}\")\n",
    "        db.persist()\n",
    "        \n",
    "        # Create retriever\n",
    "        retriever = db.as_retriever()\n",
    "        \n",
    "        # Run and evaluate\n",
    "        result,results_df = run_and_evaluate(f\"Chunk {chunk_size}, overlap {overlap_percentage}%\", retriever, prompt, llm, results_df)\n",
    "        print(f\"CHUNK SIZE {chunk_size}, {overlap_percentage}% overlap:\")\n",
    "        print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # THE FIRST TIME RUN THIS, AFTER RUN THE NEXT CELL\n",
    "# text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(chunk_size = 1000, chunk_overlap = 50)\n",
    "# chunks_1000_5 = text_splitter.split_documents(documents)\n",
    "# print(len(chunks_1000))\n",
    "# db_1000_5 = Chroma.from_documents(chunks_1000_5, embeddings_client, persist_directory = \"../news/vectordb-edit/recursive_1000_5\")\n",
    "# db_1000_5.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retriever_1000_5 = db_1000_5.as_retriever()\n",
    "# result_1000_5 = run_and_evaluate(\"Chunk 1000, overlap 0%\",retriever_1000_5, prompt, llm, results_df)\n",
    "# print(\"CHUNK SIZE 1000, 5% overlap\")\n",
    "# result_1000_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(chunk_size = 500, chunk_overlap = 50)\n",
    "# chunks_500 = text_splitter.split_documents(documents)\n",
    "# print(len(chunks_500))\n",
    "# db_500 = Chroma.from_documents(chunks_500, embeddings_client, persist_directory = \"../vectordb/recursive_500\")\n",
    "# retriever_500 = db_500.as_retriever()\n",
    "# result_500 = change_chunk_size(retriever_500)\n",
    "# print(\"CHUNK SIZE 500\")\n",
    "# print(result_500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(chunk_size = 2000, chunk_overlap = 200)\n",
    "# chunks_2000 = text_splitter.split_documents(documents)\n",
    "# print(len(chunks_2000))\n",
    "# db_2000 = Chroma.from_documents(chunks_2000, embeddings_client, persist_directory = \"../vectordb/recursive_2000\")\n",
    "# retriever_2000 = db_2000.as_retriever()\n",
    "# result_2000 = change_chunk_size(retriever_2000)\n",
    "# print(\"CHUNK SIZE 2000\")\n",
    "# print(result_2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(chunk_size = 3000, chunk_overlap = 300)\n",
    "# chunks_3000 = text_splitter.split_documents(documents)\n",
    "# print(len(chunks_3000))\n",
    "# db_3000 = Chroma.from_documents(chunks_3000, embeddings_client, persist_directory = \"../vectordb/recursive_3000\")\n",
    "# retriever_3000 = db_3000.as_retriever()\n",
    "# result_3000 = change_chunk_size(retriever_3000)\n",
    "# print(\"CHUNK SIZE 3000\")\n",
    "# print(result_3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>System</th>\n",
       "      <th>Faithfulness</th>\n",
       "      <th>Answer Relevancy</th>\n",
       "      <th>Context Precision</th>\n",
       "      <th>Context Recall</th>\n",
       "      <th>Answer Similarity</th>\n",
       "      <th>Answer Correctness</th>\n",
       "      <th>Average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GPT-3.5</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.375595</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.847668</td>\n",
       "      <td>0.454060</td>\n",
       "      <td>0.625387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GPT-4</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.360955</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.835999</td>\n",
       "      <td>0.415325</td>\n",
       "      <td>0.550658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Naive</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.773143</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.902388</td>\n",
       "      <td>0.599976</td>\n",
       "      <td>0.843378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Recursive</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.772477</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.902388</td>\n",
       "      <td>0.643756</td>\n",
       "      <td>0.852548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Chunk 500, overlap 0%</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.837908</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.920370</td>\n",
       "      <td>0.565194</td>\n",
       "      <td>0.837245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Chunk 500, overlap 5%</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.741242</td>\n",
       "      <td>0.847222</td>\n",
       "      <td>0.925000</td>\n",
       "      <td>0.919578</td>\n",
       "      <td>0.625119</td>\n",
       "      <td>0.822194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Chunk 500, overlap 10%</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.744905</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.917581</td>\n",
       "      <td>0.636998</td>\n",
       "      <td>0.829081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Chunk 500, overlap 15%</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.658863</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.912248</td>\n",
       "      <td>0.598280</td>\n",
       "      <td>0.809713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Chunk 500, overlap 20%</td>\n",
       "      <td>0.907143</td>\n",
       "      <td>0.819640</td>\n",
       "      <td>0.891667</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.916020</td>\n",
       "      <td>0.632423</td>\n",
       "      <td>0.850732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Chunk 1000, overlap 0%</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.797138</td>\n",
       "      <td>0.925000</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.917733</td>\n",
       "      <td>0.622977</td>\n",
       "      <td>0.864549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Chunk 1000, overlap 5%</td>\n",
       "      <td>0.982143</td>\n",
       "      <td>0.702075</td>\n",
       "      <td>0.925000</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.918439</td>\n",
       "      <td>0.590830</td>\n",
       "      <td>0.849748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Chunk 1000, overlap 10%</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.781964</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.922650</td>\n",
       "      <td>0.653329</td>\n",
       "      <td>0.878546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Chunk 1000, overlap 15%</td>\n",
       "      <td>0.982143</td>\n",
       "      <td>0.697939</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.920154</td>\n",
       "      <td>0.621692</td>\n",
       "      <td>0.850321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Chunk 1000, overlap 20%</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.889265</td>\n",
       "      <td>0.883333</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.920670</td>\n",
       "      <td>0.609364</td>\n",
       "      <td>0.880439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Chunk 2000, overlap 0%</td>\n",
       "      <td>0.758913</td>\n",
       "      <td>0.825006</td>\n",
       "      <td>0.917361</td>\n",
       "      <td>0.825000</td>\n",
       "      <td>0.862384</td>\n",
       "      <td>0.781092</td>\n",
       "      <td>0.828293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Chunk 2000, overlap 5%</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.732886</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.775000</td>\n",
       "      <td>0.887796</td>\n",
       "      <td>0.547920</td>\n",
       "      <td>0.815600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Chunk 2000, overlap 10%</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.832789</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.780000</td>\n",
       "      <td>0.910568</td>\n",
       "      <td>0.577737</td>\n",
       "      <td>0.841849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Chunk 2000, overlap 15%</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>0.839517</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.775000</td>\n",
       "      <td>0.910192</td>\n",
       "      <td>0.574588</td>\n",
       "      <td>0.834605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Chunk 2000, overlap 20%</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.734692</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.780000</td>\n",
       "      <td>0.894042</td>\n",
       "      <td>0.575451</td>\n",
       "      <td>0.819586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Chunk 3000, overlap 0%</td>\n",
       "      <td>0.732732</td>\n",
       "      <td>0.922064</td>\n",
       "      <td>0.708958</td>\n",
       "      <td>0.970775</td>\n",
       "      <td>0.883030</td>\n",
       "      <td>0.777719</td>\n",
       "      <td>0.832546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Chunk 3000, overlap 5%</td>\n",
       "      <td>0.908051</td>\n",
       "      <td>0.715152</td>\n",
       "      <td>0.924800</td>\n",
       "      <td>0.617445</td>\n",
       "      <td>0.852376</td>\n",
       "      <td>0.791767</td>\n",
       "      <td>0.801599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Chunk 3000, overlap 10%</td>\n",
       "      <td>0.732732</td>\n",
       "      <td>0.920121</td>\n",
       "      <td>0.690971</td>\n",
       "      <td>0.783333</td>\n",
       "      <td>0.875408</td>\n",
       "      <td>0.775585</td>\n",
       "      <td>0.796358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Chunk 3000, overlap 15%</td>\n",
       "      <td>0.729689</td>\n",
       "      <td>0.920638</td>\n",
       "      <td>0.653896</td>\n",
       "      <td>0.837898</td>\n",
       "      <td>0.882022</td>\n",
       "      <td>0.775137</td>\n",
       "      <td>0.799880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Chunk 3000, overlap 20%</td>\n",
       "      <td>0.863351</td>\n",
       "      <td>0.770708</td>\n",
       "      <td>0.865681</td>\n",
       "      <td>0.915524</td>\n",
       "      <td>0.677045</td>\n",
       "      <td>0.846434</td>\n",
       "      <td>0.823124</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     System  Faithfulness  Answer Relevancy  \\\n",
       "0                   GPT-3.5      1.000000          0.375595   \n",
       "1                     GPT-4      0.750000          0.360955   \n",
       "2                     Naive      0.904762          0.773143   \n",
       "3                 Recursive      0.916667          0.772477   \n",
       "4     Chunk 500, overlap 0%      1.000000          0.837908   \n",
       "5     Chunk 500, overlap 5%      0.875000          0.741242   \n",
       "6    Chunk 500, overlap 10%      0.875000          0.744905   \n",
       "7    Chunk 500, overlap 15%      0.888889          0.658863   \n",
       "8    Chunk 500, overlap 20%      0.907143          0.819640   \n",
       "9    Chunk 1000, overlap 0%      0.944444          0.797138   \n",
       "10   Chunk 1000, overlap 5%      0.982143          0.702075   \n",
       "11  Chunk 1000, overlap 10%      1.000000          0.781964   \n",
       "12  Chunk 1000, overlap 15%      0.982143          0.697939   \n",
       "13  Chunk 1000, overlap 20%      1.000000          0.889265   \n",
       "14   Chunk 2000, overlap 0%      0.758913          0.825006   \n",
       "15   Chunk 2000, overlap 5%      1.000000          0.732886   \n",
       "16  Chunk 2000, overlap 10%      1.000000          0.832789   \n",
       "17  Chunk 2000, overlap 15%      0.958333          0.839517   \n",
       "18  Chunk 2000, overlap 20%      1.000000          0.734692   \n",
       "19   Chunk 3000, overlap 0%      0.732732          0.922064   \n",
       "20   Chunk 3000, overlap 5%      0.908051          0.715152   \n",
       "21  Chunk 3000, overlap 10%      0.732732          0.920121   \n",
       "22  Chunk 3000, overlap 15%      0.729689          0.920638   \n",
       "23  Chunk 3000, overlap 20%      0.863351          0.770708   \n",
       "\n",
       "    Context Precision  Context Recall  Answer Similarity  Answer Correctness  \\\n",
       "0                 NaN             NaN           0.847668            0.454060   \n",
       "1                 NaN             NaN           0.835999            0.415325   \n",
       "2            0.900000        0.980000           0.902388            0.599976   \n",
       "3            0.900000        0.980000           0.902388            0.643756   \n",
       "4            0.800000        0.900000           0.920370            0.565194   \n",
       "5            0.847222        0.925000           0.919578            0.625119   \n",
       "6            0.850000        0.950000           0.917581            0.636998   \n",
       "7            0.900000        0.900000           0.912248            0.598280   \n",
       "8            0.891667        0.937500           0.916020            0.632423   \n",
       "9            0.925000        0.980000           0.917733            0.622977   \n",
       "10           0.925000        0.980000           0.918439            0.590830   \n",
       "11           0.933333        0.980000           0.922650            0.653329   \n",
       "12           0.900000        0.980000           0.920154            0.621692   \n",
       "13           0.883333        0.980000           0.920670            0.609364   \n",
       "14           0.917361        0.825000           0.862384            0.781092   \n",
       "15           0.950000        0.775000           0.887796            0.547920   \n",
       "16           0.950000        0.780000           0.910568            0.577737   \n",
       "17           0.950000        0.775000           0.910192            0.574588   \n",
       "18           0.933333        0.780000           0.894042            0.575451   \n",
       "19           0.708958        0.970775           0.883030            0.777719   \n",
       "20           0.924800        0.617445           0.852376            0.791767   \n",
       "21           0.690971        0.783333           0.875408            0.775585   \n",
       "22           0.653896        0.837898           0.882022            0.775137   \n",
       "23           0.865681        0.915524           0.677045            0.846434   \n",
       "\n",
       "     Average  \n",
       "0   0.625387  \n",
       "1   0.550658  \n",
       "2   0.843378  \n",
       "3   0.852548  \n",
       "4   0.837245  \n",
       "5   0.822194  \n",
       "6   0.829081  \n",
       "7   0.809713  \n",
       "8   0.850732  \n",
       "9   0.864549  \n",
       "10  0.849748  \n",
       "11  0.878546  \n",
       "12  0.850321  \n",
       "13  0.880439  \n",
       "14  0.828293  \n",
       "15  0.815600  \n",
       "16  0.841849  \n",
       "17  0.834605  \n",
       "18  0.819586  \n",
       "19  0.832546  \n",
       "20  0.801599  \n",
       "21  0.796358  \n",
       "22  0.799880  \n",
       "23  0.823124  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Highest average value: 0.8804388538467025\n"
     ]
    }
   ],
   "source": [
    "highest_average = results_df[\"Average\"].max()\n",
    "print(\"Highest average value:\", highest_average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.to_csv(f\"../news/results/results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### now time to look for different top-k\n",
    "\n",
    "Note: We continue with the size chunk of 1000 as it had the highest average score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_k = Chroma(persist_directory = \"../news/vectordb-edit/chunking_1000_20\", embedding_function=embeddings_client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "passing column names as 'ground_truths' is deprecated and will be removed in the next version, please use 'ground_truth' instead. Note that `ground_truth` should be of type string and not Sequence[string] like `ground_truths`\n",
      "Evaluating: 100%|██████████| 60/60 [00:14<00:00,  4.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average score is: 0.8366701197718719\n",
      "Results for K=2:\n",
      "                              System  Faithfulness  Answer Relevancy  \\\n",
      "0  Chunk size 3000, overlap 20%, K=2      0.958333          0.731547   \n",
      "\n",
      "   Context Precision  Context Recall  Answer Similarity  Answer Correctness  \\\n",
      "0                0.9             1.0           0.906164            0.523977   \n",
      "\n",
      "   Average  \n",
      "0  0.83667  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "passing column names as 'ground_truths' is deprecated and will be removed in the next version, please use 'ground_truth' instead. Note that `ground_truth` should be of type string and not Sequence[string] like `ground_truths`\n",
      "Evaluating:   0%|          | 0/60 [00:00<?, ?it/s]Task exception was never retrieved\n",
      "future: <Task finished name='Task-2058' coro=<AsyncClient.aclose() done, defined at c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\httpx\\_client.py:2011> exception=RuntimeError('Event loop is closed')>\n",
      "RuntimeError: Event loop is closed\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-2059' coro=<AsyncClient.aclose() done, defined at c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\httpx\\_client.py:2011> exception=RuntimeError('Event loop is closed')>\n",
      "RuntimeError: Event loop is closed\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-2060' coro=<AsyncClient.aclose() done, defined at c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\httpx\\_client.py:2011> exception=RuntimeError('Event loop is closed')>\n",
      "RuntimeError: Event loop is closed\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-2061' coro=<AsyncClient.aclose() done, defined at c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\httpx\\_client.py:2011> exception=RuntimeError('Event loop is closed')>\n",
      "RuntimeError: Event loop is closed\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-2062' coro=<AsyncClient.aclose() done, defined at c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\httpx\\_client.py:2011> exception=RuntimeError('Event loop is closed')>\n",
      "RuntimeError: Event loop is closed\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-2063' coro=<AsyncClient.aclose() done, defined at c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\httpx\\_client.py:2011> exception=RuntimeError('Event loop is closed')>\n",
      "RuntimeError: Event loop is closed\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-2064' coro=<AsyncClient.aclose() done, defined at c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\httpx\\_client.py:2011> exception=RuntimeError('Event loop is closed')>\n",
      "RuntimeError: Event loop is closed\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-2065' coro=<AsyncClient.aclose() done, defined at c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\httpx\\_client.py:2011> exception=RuntimeError('Event loop is closed')>\n",
      "RuntimeError: Event loop is closed\n",
      "Evaluating: 100%|██████████| 60/60 [00:08<00:00,  6.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average score is: 0.8221172613620668\n",
      "Results for K=3:\n",
      "                              System  Faithfulness  Answer Relevancy  \\\n",
      "0  Chunk size 3000, overlap 20%, K=3           1.0          0.640095   \n",
      "\n",
      "   Context Precision  Context Recall  Answer Similarity  Answer Correctness  \\\n",
      "0           0.883333           0.925           0.916328            0.567948   \n",
      "\n",
      "    Average  \n",
      "0  0.822117  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "passing column names as 'ground_truths' is deprecated and will be removed in the next version, please use 'ground_truth' instead. Note that `ground_truth` should be of type string and not Sequence[string] like `ground_truths`\n",
      "Evaluating: 100%|██████████| 60/60 [00:10<00:00,  5.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average score is: 0.844671933282164\n",
      "Results for K=5:\n",
      "                              System  Faithfulness  Answer Relevancy  \\\n",
      "0  Chunk size 3000, overlap 20%, K=5      0.968254          0.676828   \n",
      "\n",
      "   Context Precision  Context Recall  Answer Similarity  Answer Correctness  \\\n",
      "0           0.903333             1.0            0.91622            0.603396   \n",
      "\n",
      "    Average  \n",
      "0  0.844672  \n"
     ]
    }
   ],
   "source": [
    "k_values = [2, 3, 5]\n",
    "\n",
    "# Iterate over different k values\n",
    "for k in k_values:\n",
    "    # Create retriever with k value\n",
    "    retriever = db_k.as_retriever(search_kwargs={\"k\": k})\n",
    "    \n",
    "    # Run and evaluate\n",
    "    result,results_df = run_and_evaluate(f\"Chunk size {chunk_size}, overlap {overlap_percentage}%, K={k}\", retriever, prompt, llm, results_df)\n",
    "    print(f\"Results for K={k}:\")\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>System</th>\n",
       "      <th>Faithfulness</th>\n",
       "      <th>Answer Relevancy</th>\n",
       "      <th>Context Precision</th>\n",
       "      <th>Context Recall</th>\n",
       "      <th>Answer Similarity</th>\n",
       "      <th>Answer Correctness</th>\n",
       "      <th>Average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GPT-3.5</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.375595</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.847668</td>\n",
       "      <td>0.454060</td>\n",
       "      <td>0.625387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GPT-4</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.360955</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.835999</td>\n",
       "      <td>0.415325</td>\n",
       "      <td>0.550658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Naive</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.773143</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.902388</td>\n",
       "      <td>0.599976</td>\n",
       "      <td>0.843378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Recursive</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.772477</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.902388</td>\n",
       "      <td>0.643756</td>\n",
       "      <td>0.852548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Chunk 500, overlap 0%</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.837908</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.920370</td>\n",
       "      <td>0.565194</td>\n",
       "      <td>0.837245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Chunk 500, overlap 5%</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.741242</td>\n",
       "      <td>0.847222</td>\n",
       "      <td>0.925000</td>\n",
       "      <td>0.919578</td>\n",
       "      <td>0.625119</td>\n",
       "      <td>0.822194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Chunk 500, overlap 10%</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.744905</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.917581</td>\n",
       "      <td>0.636998</td>\n",
       "      <td>0.829081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Chunk 500, overlap 15%</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.658863</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.912248</td>\n",
       "      <td>0.598280</td>\n",
       "      <td>0.809713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Chunk 500, overlap 20%</td>\n",
       "      <td>0.907143</td>\n",
       "      <td>0.819640</td>\n",
       "      <td>0.891667</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.916020</td>\n",
       "      <td>0.632423</td>\n",
       "      <td>0.850732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Chunk 1000, overlap 0%</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.797138</td>\n",
       "      <td>0.925000</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.917733</td>\n",
       "      <td>0.622977</td>\n",
       "      <td>0.864549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Chunk 1000, overlap 5%</td>\n",
       "      <td>0.982143</td>\n",
       "      <td>0.702075</td>\n",
       "      <td>0.925000</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.918439</td>\n",
       "      <td>0.590830</td>\n",
       "      <td>0.849748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Chunk 1000, overlap 10%</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.781964</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.922650</td>\n",
       "      <td>0.653329</td>\n",
       "      <td>0.878546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Chunk 1000, overlap 15%</td>\n",
       "      <td>0.982143</td>\n",
       "      <td>0.697939</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.920154</td>\n",
       "      <td>0.621692</td>\n",
       "      <td>0.850321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Chunk 1000, overlap 20%</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.889265</td>\n",
       "      <td>0.883333</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.920670</td>\n",
       "      <td>0.609364</td>\n",
       "      <td>0.880439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Chunk 2000, overlap 0%</td>\n",
       "      <td>0.758913</td>\n",
       "      <td>0.825006</td>\n",
       "      <td>0.917361</td>\n",
       "      <td>0.825000</td>\n",
       "      <td>0.862384</td>\n",
       "      <td>0.781092</td>\n",
       "      <td>0.828293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Chunk 2000, overlap 5%</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.732886</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.775000</td>\n",
       "      <td>0.887796</td>\n",
       "      <td>0.547920</td>\n",
       "      <td>0.815600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Chunk 2000, overlap 10%</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.832789</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.780000</td>\n",
       "      <td>0.910568</td>\n",
       "      <td>0.577737</td>\n",
       "      <td>0.841849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Chunk 2000, overlap 15%</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>0.839517</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.775000</td>\n",
       "      <td>0.910192</td>\n",
       "      <td>0.574588</td>\n",
       "      <td>0.834605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Chunk 2000, overlap 20%</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.734692</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.780000</td>\n",
       "      <td>0.894042</td>\n",
       "      <td>0.575451</td>\n",
       "      <td>0.819586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Chunk 3000, overlap 0%</td>\n",
       "      <td>0.732732</td>\n",
       "      <td>0.922064</td>\n",
       "      <td>0.708958</td>\n",
       "      <td>0.970775</td>\n",
       "      <td>0.883030</td>\n",
       "      <td>0.777719</td>\n",
       "      <td>0.832546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Chunk 3000, overlap 5%</td>\n",
       "      <td>0.908051</td>\n",
       "      <td>0.715152</td>\n",
       "      <td>0.924800</td>\n",
       "      <td>0.617445</td>\n",
       "      <td>0.852376</td>\n",
       "      <td>0.791767</td>\n",
       "      <td>0.801599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Chunk 3000, overlap 10%</td>\n",
       "      <td>0.732732</td>\n",
       "      <td>0.920121</td>\n",
       "      <td>0.690971</td>\n",
       "      <td>0.783333</td>\n",
       "      <td>0.875408</td>\n",
       "      <td>0.775585</td>\n",
       "      <td>0.796358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Chunk 3000, overlap 15%</td>\n",
       "      <td>0.729689</td>\n",
       "      <td>0.920638</td>\n",
       "      <td>0.653896</td>\n",
       "      <td>0.837898</td>\n",
       "      <td>0.882022</td>\n",
       "      <td>0.775137</td>\n",
       "      <td>0.799880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Chunk 3000, overlap 20%</td>\n",
       "      <td>0.863351</td>\n",
       "      <td>0.770708</td>\n",
       "      <td>0.865681</td>\n",
       "      <td>0.915524</td>\n",
       "      <td>0.677045</td>\n",
       "      <td>0.846434</td>\n",
       "      <td>0.823124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Chunk size 3000, overlap 20%, K=2</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>0.731547</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.906164</td>\n",
       "      <td>0.523977</td>\n",
       "      <td>0.836670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Chunk size 3000, overlap 20%, K=3</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.640095</td>\n",
       "      <td>0.883333</td>\n",
       "      <td>0.925000</td>\n",
       "      <td>0.916328</td>\n",
       "      <td>0.567948</td>\n",
       "      <td>0.822117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Chunk size 3000, overlap 20%, K=5</td>\n",
       "      <td>0.968254</td>\n",
       "      <td>0.676828</td>\n",
       "      <td>0.903333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.916220</td>\n",
       "      <td>0.603396</td>\n",
       "      <td>0.844672</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               System  Faithfulness  Answer Relevancy  \\\n",
       "0                             GPT-3.5      1.000000          0.375595   \n",
       "1                               GPT-4      0.750000          0.360955   \n",
       "2                               Naive      0.904762          0.773143   \n",
       "3                           Recursive      0.916667          0.772477   \n",
       "4               Chunk 500, overlap 0%      1.000000          0.837908   \n",
       "5               Chunk 500, overlap 5%      0.875000          0.741242   \n",
       "6              Chunk 500, overlap 10%      0.875000          0.744905   \n",
       "7              Chunk 500, overlap 15%      0.888889          0.658863   \n",
       "8              Chunk 500, overlap 20%      0.907143          0.819640   \n",
       "9              Chunk 1000, overlap 0%      0.944444          0.797138   \n",
       "10             Chunk 1000, overlap 5%      0.982143          0.702075   \n",
       "11            Chunk 1000, overlap 10%      1.000000          0.781964   \n",
       "12            Chunk 1000, overlap 15%      0.982143          0.697939   \n",
       "13            Chunk 1000, overlap 20%      1.000000          0.889265   \n",
       "14             Chunk 2000, overlap 0%      0.758913          0.825006   \n",
       "15             Chunk 2000, overlap 5%      1.000000          0.732886   \n",
       "16            Chunk 2000, overlap 10%      1.000000          0.832789   \n",
       "17            Chunk 2000, overlap 15%      0.958333          0.839517   \n",
       "18            Chunk 2000, overlap 20%      1.000000          0.734692   \n",
       "19             Chunk 3000, overlap 0%      0.732732          0.922064   \n",
       "20             Chunk 3000, overlap 5%      0.908051          0.715152   \n",
       "21            Chunk 3000, overlap 10%      0.732732          0.920121   \n",
       "22            Chunk 3000, overlap 15%      0.729689          0.920638   \n",
       "23            Chunk 3000, overlap 20%      0.863351          0.770708   \n",
       "24  Chunk size 3000, overlap 20%, K=2      0.958333          0.731547   \n",
       "25  Chunk size 3000, overlap 20%, K=3      1.000000          0.640095   \n",
       "26  Chunk size 3000, overlap 20%, K=5      0.968254          0.676828   \n",
       "\n",
       "    Context Precision  Context Recall  Answer Similarity  Answer Correctness  \\\n",
       "0                 NaN             NaN           0.847668            0.454060   \n",
       "1                 NaN             NaN           0.835999            0.415325   \n",
       "2            0.900000        0.980000           0.902388            0.599976   \n",
       "3            0.900000        0.980000           0.902388            0.643756   \n",
       "4            0.800000        0.900000           0.920370            0.565194   \n",
       "5            0.847222        0.925000           0.919578            0.625119   \n",
       "6            0.850000        0.950000           0.917581            0.636998   \n",
       "7            0.900000        0.900000           0.912248            0.598280   \n",
       "8            0.891667        0.937500           0.916020            0.632423   \n",
       "9            0.925000        0.980000           0.917733            0.622977   \n",
       "10           0.925000        0.980000           0.918439            0.590830   \n",
       "11           0.933333        0.980000           0.922650            0.653329   \n",
       "12           0.900000        0.980000           0.920154            0.621692   \n",
       "13           0.883333        0.980000           0.920670            0.609364   \n",
       "14           0.917361        0.825000           0.862384            0.781092   \n",
       "15           0.950000        0.775000           0.887796            0.547920   \n",
       "16           0.950000        0.780000           0.910568            0.577737   \n",
       "17           0.950000        0.775000           0.910192            0.574588   \n",
       "18           0.933333        0.780000           0.894042            0.575451   \n",
       "19           0.708958        0.970775           0.883030            0.777719   \n",
       "20           0.924800        0.617445           0.852376            0.791767   \n",
       "21           0.690971        0.783333           0.875408            0.775585   \n",
       "22           0.653896        0.837898           0.882022            0.775137   \n",
       "23           0.865681        0.915524           0.677045            0.846434   \n",
       "24           0.900000        1.000000           0.906164            0.523977   \n",
       "25           0.883333        0.925000           0.916328            0.567948   \n",
       "26           0.903333        1.000000           0.916220            0.603396   \n",
       "\n",
       "     Average  \n",
       "0   0.625387  \n",
       "1   0.550658  \n",
       "2   0.843378  \n",
       "3   0.852548  \n",
       "4   0.837245  \n",
       "5   0.822194  \n",
       "6   0.829081  \n",
       "7   0.809713  \n",
       "8   0.850732  \n",
       "9   0.864549  \n",
       "10  0.849748  \n",
       "11  0.878546  \n",
       "12  0.850321  \n",
       "13  0.880439  \n",
       "14  0.828293  \n",
       "15  0.815600  \n",
       "16  0.841849  \n",
       "17  0.834605  \n",
       "18  0.819586  \n",
       "19  0.832546  \n",
       "20  0.801599  \n",
       "21  0.796358  \n",
       "22  0.799880  \n",
       "23  0.823124  \n",
       "24  0.836670  \n",
       "25  0.822117  \n",
       "26  0.844672  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.to_csv(f\"../news/results/results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "passing column names as 'ground_truths' is deprecated and will be removed in the next version, please use 'ground_truth' instead. Note that `ground_truth` should be of type string and not Sequence[string] like `ground_truths`\n",
      "Evaluating: 100%|██████████| 60/60 [00:08<00:00,  6.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHUNK SIZE 1000, K=2\n",
      "{'faithfulness': 1.0000, 'answer_relevancy': 0.7317, 'context_precision': 0.9000, 'context_recall': 1.0000, 'answer_similarity': 0.9071, 'answer_correctness': 0.5908}\n"
     ]
    }
   ],
   "source": [
    "# retriever_2 = db.as_retriever(search_kwargs={\"k\": 2})\n",
    "# result_2 = run_and_evaluate(\"K=2\",retriever_2, prompt, llm, results_df)\n",
    "# print(\"CHUNK SIZE 1000, K=2\")\n",
    "# print(result_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "passing column names as 'ground_truths' is deprecated and will be removed in the next version, please use 'ground_truth' instead. Note that `ground_truth` should be of type string and not Sequence[string] like `ground_truths`\n",
      "Evaluating: 100%|██████████| 60/60 [00:09<00:00,  6.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHUNK SIZE 1000, K=3\n",
      "{'faithfulness': 1.0000, 'answer_relevancy': 0.7832, 'context_precision': 0.9333, 'context_recall': 0.9250, 'answer_similarity': 0.9326, 'answer_correctness': 0.6117}\n"
     ]
    }
   ],
   "source": [
    "# retriever_3 = db_1000.as_retriever(search_kwargs={\"k\": 3})\n",
    "# result_3 = change_chunk_size(retriever_3)\n",
    "# print(\"CHUNK SIZE 1000, K=3\")\n",
    "# print(result_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "passing column names as 'ground_truths' is deprecated and will be removed in the next version, please use 'ground_truth' instead. Note that `ground_truth` should be of type string and not Sequence[string] like `ground_truths`\n",
      "Evaluating: 100%|██████████| 60/60 [00:14<00:00,  4.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHUNK SIZE 1000, K=5\n",
      "{'faithfulness': 0.9028, 'answer_relevancy': 0.6788, 'context_precision': 0.9333, 'context_recall': 1.0000, 'answer_similarity': 0.9250, 'answer_correctness': 0.6024}\n"
     ]
    }
   ],
   "source": [
    "# retriever_5 = db_1000.as_retriever(search_kwargs={\"k\": 5})\n",
    "# result_5 = change_chunk_size(retriever_5)\n",
    "# print(\"CHUNK SIZE 1000, K=5\")\n",
    "# print(result_5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### look for different retrievers\n",
    "\n",
    "4 chunks was the best score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### parent document retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "passing column names as 'ground_truths' is deprecated and will be removed in the next version, please use 'ground_truth' instead. Note that `ground_truth` should be of type string and not Sequence[string] like `ground_truths`\n",
      "Evaluating: 100%|██████████| 60/60 [00:11<00:00,  5.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average score is: 0.8288468817383213\n",
      "                      System  Faithfulness  Answer Relevancy  \\\n",
      "0  Parent Retriever 1000-200        0.9375          0.738172   \n",
      "\n",
      "   Context Precision  Context Recall  Answer Similarity  Answer Correctness  \\\n",
      "0               0.85             1.0            0.89614            0.551269   \n",
      "\n",
      "    Average  \n",
      "0  0.828847  \n"
     ]
    }
   ],
   "source": [
    "from langchain.retrievers import ParentDocumentRetriever\n",
    "from langchain.storage import InMemoryStore\n",
    "\n",
    "parent_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(chunk_size=1000, chunk_overlap = 200)\n",
    "child_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(chunk_size=200, chunk_overlap = 0)\n",
    "\n",
    "vectorstore = Chroma(collection_name=\"split_parents\",persist_directory = \"../vectordb-edit/parent\", embedding_function=embeddings_client)\n",
    "store = InMemoryStore()\n",
    "parent_document_retriever = ParentDocumentRetriever(\n",
    "    vectorstore=vectorstore,\n",
    "    docstore=store,\n",
    "    child_splitter=child_splitter,\n",
    "    parent_splitter=parent_splitter,\n",
    ")\n",
    "parent_document_retriever.add_documents(documents)\n",
    "result_parent, results_df = run_and_evaluate(f\"Parent Retriever 1000-200\", parent_document_retriever, prompt, llm, results_df)\n",
    "print(result_parent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "passing column names as 'ground_truths' is deprecated and will be removed in the next version, please use 'ground_truth' instead. Note that `ground_truth` should be of type string and not Sequence[string] like `ground_truths`\n",
      "Evaluating:  35%|███▌      | 21/60 [00:05<00:06,  5.58it/s]Runner in Executor raised an exception\n",
      "ValueError: Azure has not provided the response due to a content filter being triggered\n",
      "Evaluating: 100%|██████████| 60/60 [00:11<00:00,  5.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average score is: 0.860574218506804\n",
      "                     System  Faithfulness  Answer Relevancy  \\\n",
      "0  Parent Retriever 500-100      0.705718              0.75   \n",
      "\n",
      "   Context Precision  Context Recall  Answer Similarity  Answer Correctness  \\\n",
      "0           0.952744        0.983333           0.962346            0.809304   \n",
      "\n",
      "    Average  \n",
      "0  0.860574  \n"
     ]
    }
   ],
   "source": [
    "parent_splitter_small = RecursiveCharacterTextSplitter.from_tiktoken_encoder(chunk_size=500, chunk_overlap = 50)\n",
    "child_splitter_small = RecursiveCharacterTextSplitter.from_tiktoken_encoder(chunk_size=100, chunk_overlap = 0)\n",
    "\n",
    "vectorstore = Chroma(collection_name=\"split_parents_small\",persist_directory = \"../vectordb-edit/parent_small\", embedding_function=embeddings_client)\n",
    "store = InMemoryStore()\n",
    "parent_document_retriever_small = ParentDocumentRetriever(\n",
    "    vectorstore=vectorstore,\n",
    "    docstore=store,\n",
    "    child_splitter=child_splitter_small,\n",
    "    parent_splitter=parent_splitter_small,\n",
    ")\n",
    "parent_document_retriever_small.add_documents(documents)\n",
    "result_parent_small, results_df = run_and_evaluate(f\"Parent Retriever 500-100\", parent_document_retriever_small, prompt, llm, results_df)\n",
    "print(result_parent_small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "passing column names as 'ground_truths' is deprecated and will be removed in the next version, please use 'ground_truth' instead. Note that `ground_truth` should be of type string and not Sequence[string] like `ground_truths`\n",
      "Evaluating:  35%|███▌      | 21/60 [00:05<00:06,  5.86it/s]Runner in Executor raised an exception\n",
      "ValueError: Azure has not provided the response due to a content filter being triggered\n",
      "Evaluating: 100%|██████████| 60/60 [00:10<00:00,  5.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average score is: 0.8531451228062102\n",
      "                      System  Faithfulness  Answer Relevancy  \\\n",
      "0  Parent Retriever 1500-200      0.690791          0.718519   \n",
      "\n",
      "   Context Precision  Context Recall  Answer Similarity  Answer Correctness  \\\n",
      "0           0.955095        0.983333           0.961934              0.8092   \n",
      "\n",
      "    Average  \n",
      "0  0.853145  \n"
     ]
    }
   ],
   "source": [
    "parent_splitter_large = RecursiveCharacterTextSplitter.from_tiktoken_encoder(chunk_size=1500, chunk_overlap = 150)\n",
    "child_splitter_large = RecursiveCharacterTextSplitter.from_tiktoken_encoder(chunk_size=200, chunk_overlap = 0)\n",
    "\n",
    "vectorstore = Chroma(collection_name=\"split_parents_large\",persist_directory = \"../vectordb-edit/parent_large\", embedding_function=embeddings_client)\n",
    "store = InMemoryStore()\n",
    "parent_document_retriever_large = ParentDocumentRetriever(\n",
    "    vectorstore=vectorstore,\n",
    "    docstore=store,\n",
    "    child_splitter=child_splitter_large,\n",
    "    parent_splitter=parent_splitter_large,\n",
    ")\n",
    "parent_document_retriever_large.add_documents(documents)\n",
    "result_parent_large , results_df = run_and_evaluate(f\"Parent Retriever 1500-200\", parent_document_retriever_small, prompt, llm, results_df)\n",
    "print(result_parent_large)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>System</th>\n",
       "      <th>Faithfulness</th>\n",
       "      <th>Answer Relevancy</th>\n",
       "      <th>Context Precision</th>\n",
       "      <th>Context Recall</th>\n",
       "      <th>Answer Similarity</th>\n",
       "      <th>Answer Correctness</th>\n",
       "      <th>Average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GPT-3.5</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.375595</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.847668</td>\n",
       "      <td>0.454060</td>\n",
       "      <td>0.625387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GPT-4</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.360955</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.835999</td>\n",
       "      <td>0.415325</td>\n",
       "      <td>0.550658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Naive</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.773143</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.902388</td>\n",
       "      <td>0.599976</td>\n",
       "      <td>0.843378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Recursive</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.772477</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.902388</td>\n",
       "      <td>0.643756</td>\n",
       "      <td>0.852548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Chunk 500, overlap 0%</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.837908</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.920370</td>\n",
       "      <td>0.565194</td>\n",
       "      <td>0.837245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Chunk 500, overlap 5%</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.741242</td>\n",
       "      <td>0.847222</td>\n",
       "      <td>0.925000</td>\n",
       "      <td>0.919578</td>\n",
       "      <td>0.625119</td>\n",
       "      <td>0.822194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Chunk 500, overlap 10%</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.744905</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.917581</td>\n",
       "      <td>0.636998</td>\n",
       "      <td>0.829081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Chunk 500, overlap 15%</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.658863</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.912248</td>\n",
       "      <td>0.598280</td>\n",
       "      <td>0.809713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Chunk 500, overlap 20%</td>\n",
       "      <td>0.907143</td>\n",
       "      <td>0.819640</td>\n",
       "      <td>0.891667</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.916020</td>\n",
       "      <td>0.632423</td>\n",
       "      <td>0.850732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Chunk 1000, overlap 0%</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.797138</td>\n",
       "      <td>0.925000</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.917733</td>\n",
       "      <td>0.622977</td>\n",
       "      <td>0.864549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Chunk 1000, overlap 5%</td>\n",
       "      <td>0.982143</td>\n",
       "      <td>0.702075</td>\n",
       "      <td>0.925000</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.918439</td>\n",
       "      <td>0.590830</td>\n",
       "      <td>0.849748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Chunk 1000, overlap 10%</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.781964</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.922650</td>\n",
       "      <td>0.653329</td>\n",
       "      <td>0.878546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Chunk 1000, overlap 15%</td>\n",
       "      <td>0.982143</td>\n",
       "      <td>0.697939</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.920154</td>\n",
       "      <td>0.621692</td>\n",
       "      <td>0.850321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Chunk 1000, overlap 20%</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.889265</td>\n",
       "      <td>0.883333</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.920670</td>\n",
       "      <td>0.609364</td>\n",
       "      <td>0.880439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Chunk 2000, overlap 0%</td>\n",
       "      <td>0.758913</td>\n",
       "      <td>0.825006</td>\n",
       "      <td>0.917361</td>\n",
       "      <td>0.825000</td>\n",
       "      <td>0.862384</td>\n",
       "      <td>0.781092</td>\n",
       "      <td>0.828293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Chunk 2000, overlap 5%</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.732886</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.775000</td>\n",
       "      <td>0.887796</td>\n",
       "      <td>0.547920</td>\n",
       "      <td>0.815600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Chunk 2000, overlap 10%</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.832789</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.780000</td>\n",
       "      <td>0.910568</td>\n",
       "      <td>0.577737</td>\n",
       "      <td>0.841849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Chunk 2000, overlap 15%</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>0.839517</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.775000</td>\n",
       "      <td>0.910192</td>\n",
       "      <td>0.574588</td>\n",
       "      <td>0.834605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Chunk 2000, overlap 20%</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.734692</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.780000</td>\n",
       "      <td>0.894042</td>\n",
       "      <td>0.575451</td>\n",
       "      <td>0.819586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Chunk 3000, overlap 0%</td>\n",
       "      <td>0.732732</td>\n",
       "      <td>0.922064</td>\n",
       "      <td>0.708958</td>\n",
       "      <td>0.970775</td>\n",
       "      <td>0.883030</td>\n",
       "      <td>0.777719</td>\n",
       "      <td>0.832546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Chunk 3000, overlap 5%</td>\n",
       "      <td>0.908051</td>\n",
       "      <td>0.715152</td>\n",
       "      <td>0.924800</td>\n",
       "      <td>0.617445</td>\n",
       "      <td>0.852376</td>\n",
       "      <td>0.791767</td>\n",
       "      <td>0.801599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Chunk 3000, overlap 10%</td>\n",
       "      <td>0.732732</td>\n",
       "      <td>0.920121</td>\n",
       "      <td>0.690971</td>\n",
       "      <td>0.783333</td>\n",
       "      <td>0.875408</td>\n",
       "      <td>0.775585</td>\n",
       "      <td>0.796358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Chunk 3000, overlap 15%</td>\n",
       "      <td>0.729689</td>\n",
       "      <td>0.920638</td>\n",
       "      <td>0.653896</td>\n",
       "      <td>0.837898</td>\n",
       "      <td>0.882022</td>\n",
       "      <td>0.775137</td>\n",
       "      <td>0.799880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Chunk 3000, overlap 20%</td>\n",
       "      <td>0.863351</td>\n",
       "      <td>0.770708</td>\n",
       "      <td>0.865681</td>\n",
       "      <td>0.915524</td>\n",
       "      <td>0.677045</td>\n",
       "      <td>0.846434</td>\n",
       "      <td>0.823124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Chunk size 3000, overlap 20%, K=2</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>0.731547</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.906164</td>\n",
       "      <td>0.523977</td>\n",
       "      <td>0.836670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Chunk size 3000, overlap 20%, K=3</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.640095</td>\n",
       "      <td>0.883333</td>\n",
       "      <td>0.925000</td>\n",
       "      <td>0.916328</td>\n",
       "      <td>0.567948</td>\n",
       "      <td>0.822117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Chunk size 3000, overlap 20%, K=5</td>\n",
       "      <td>0.968254</td>\n",
       "      <td>0.676828</td>\n",
       "      <td>0.903333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.916220</td>\n",
       "      <td>0.603396</td>\n",
       "      <td>0.844672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Parent Retriever 1000-200</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.738172</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.896140</td>\n",
       "      <td>0.551269</td>\n",
       "      <td>0.828847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Parent Retriever 500-100</td>\n",
       "      <td>0.705718</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.952744</td>\n",
       "      <td>0.983333</td>\n",
       "      <td>0.962346</td>\n",
       "      <td>0.809304</td>\n",
       "      <td>0.860574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Parent Retriever 1500-200</td>\n",
       "      <td>0.690791</td>\n",
       "      <td>0.718519</td>\n",
       "      <td>0.955095</td>\n",
       "      <td>0.983333</td>\n",
       "      <td>0.961934</td>\n",
       "      <td>0.809200</td>\n",
       "      <td>0.853145</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               System  Faithfulness  Answer Relevancy  \\\n",
       "0                             GPT-3.5      1.000000          0.375595   \n",
       "1                               GPT-4      0.750000          0.360955   \n",
       "2                               Naive      0.904762          0.773143   \n",
       "3                           Recursive      0.916667          0.772477   \n",
       "4               Chunk 500, overlap 0%      1.000000          0.837908   \n",
       "5               Chunk 500, overlap 5%      0.875000          0.741242   \n",
       "6              Chunk 500, overlap 10%      0.875000          0.744905   \n",
       "7              Chunk 500, overlap 15%      0.888889          0.658863   \n",
       "8              Chunk 500, overlap 20%      0.907143          0.819640   \n",
       "9              Chunk 1000, overlap 0%      0.944444          0.797138   \n",
       "10             Chunk 1000, overlap 5%      0.982143          0.702075   \n",
       "11            Chunk 1000, overlap 10%      1.000000          0.781964   \n",
       "12            Chunk 1000, overlap 15%      0.982143          0.697939   \n",
       "13            Chunk 1000, overlap 20%      1.000000          0.889265   \n",
       "14             Chunk 2000, overlap 0%      0.758913          0.825006   \n",
       "15             Chunk 2000, overlap 5%      1.000000          0.732886   \n",
       "16            Chunk 2000, overlap 10%      1.000000          0.832789   \n",
       "17            Chunk 2000, overlap 15%      0.958333          0.839517   \n",
       "18            Chunk 2000, overlap 20%      1.000000          0.734692   \n",
       "19             Chunk 3000, overlap 0%      0.732732          0.922064   \n",
       "20             Chunk 3000, overlap 5%      0.908051          0.715152   \n",
       "21            Chunk 3000, overlap 10%      0.732732          0.920121   \n",
       "22            Chunk 3000, overlap 15%      0.729689          0.920638   \n",
       "23            Chunk 3000, overlap 20%      0.863351          0.770708   \n",
       "24  Chunk size 3000, overlap 20%, K=2      0.958333          0.731547   \n",
       "25  Chunk size 3000, overlap 20%, K=3      1.000000          0.640095   \n",
       "26  Chunk size 3000, overlap 20%, K=5      0.968254          0.676828   \n",
       "27          Parent Retriever 1000-200      0.937500          0.738172   \n",
       "28           Parent Retriever 500-100      0.705718          0.750000   \n",
       "29          Parent Retriever 1500-200      0.690791          0.718519   \n",
       "\n",
       "    Context Precision  Context Recall  Answer Similarity  Answer Correctness  \\\n",
       "0                 NaN             NaN           0.847668            0.454060   \n",
       "1                 NaN             NaN           0.835999            0.415325   \n",
       "2            0.900000        0.980000           0.902388            0.599976   \n",
       "3            0.900000        0.980000           0.902388            0.643756   \n",
       "4            0.800000        0.900000           0.920370            0.565194   \n",
       "5            0.847222        0.925000           0.919578            0.625119   \n",
       "6            0.850000        0.950000           0.917581            0.636998   \n",
       "7            0.900000        0.900000           0.912248            0.598280   \n",
       "8            0.891667        0.937500           0.916020            0.632423   \n",
       "9            0.925000        0.980000           0.917733            0.622977   \n",
       "10           0.925000        0.980000           0.918439            0.590830   \n",
       "11           0.933333        0.980000           0.922650            0.653329   \n",
       "12           0.900000        0.980000           0.920154            0.621692   \n",
       "13           0.883333        0.980000           0.920670            0.609364   \n",
       "14           0.917361        0.825000           0.862384            0.781092   \n",
       "15           0.950000        0.775000           0.887796            0.547920   \n",
       "16           0.950000        0.780000           0.910568            0.577737   \n",
       "17           0.950000        0.775000           0.910192            0.574588   \n",
       "18           0.933333        0.780000           0.894042            0.575451   \n",
       "19           0.708958        0.970775           0.883030            0.777719   \n",
       "20           0.924800        0.617445           0.852376            0.791767   \n",
       "21           0.690971        0.783333           0.875408            0.775585   \n",
       "22           0.653896        0.837898           0.882022            0.775137   \n",
       "23           0.865681        0.915524           0.677045            0.846434   \n",
       "24           0.900000        1.000000           0.906164            0.523977   \n",
       "25           0.883333        0.925000           0.916328            0.567948   \n",
       "26           0.903333        1.000000           0.916220            0.603396   \n",
       "27           0.850000        1.000000           0.896140            0.551269   \n",
       "28           0.952744        0.983333           0.962346            0.809304   \n",
       "29           0.955095        0.983333           0.961934            0.809200   \n",
       "\n",
       "     Average  \n",
       "0   0.625387  \n",
       "1   0.550658  \n",
       "2   0.843378  \n",
       "3   0.852548  \n",
       "4   0.837245  \n",
       "5   0.822194  \n",
       "6   0.829081  \n",
       "7   0.809713  \n",
       "8   0.850732  \n",
       "9   0.864549  \n",
       "10  0.849748  \n",
       "11  0.878546  \n",
       "12  0.850321  \n",
       "13  0.880439  \n",
       "14  0.828293  \n",
       "15  0.815600  \n",
       "16  0.841849  \n",
       "17  0.834605  \n",
       "18  0.819586  \n",
       "19  0.832546  \n",
       "20  0.801599  \n",
       "21  0.796358  \n",
       "22  0.799880  \n",
       "23  0.823124  \n",
       "24  0.836670  \n",
       "25  0.822117  \n",
       "26  0.844672  \n",
       "27  0.828847  \n",
       "28  0.860574  \n",
       "29  0.853145  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Maximum marginal relevance retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "passing column names as 'ground_truths' is deprecated and will be removed in the next version, please use 'ground_truth' instead. Note that `ground_truth` should be of type string and not Sequence[string] like `ground_truths`\n",
      "Evaluating: 100%|██████████| 60/60 [00:12<00:00,  4.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average score is: 0.8353660265249804\n",
      "Marginal relevance\n",
      "  System  Faithfulness  Answer Relevancy  Context Precision  Context Recall  \\\n",
      "0    MMR           1.0          0.828457                0.9        0.719048   \n",
      "\n",
      "   Answer Similarity  Answer Correctness   Average  \n",
      "0           0.917804            0.646888  0.835366  \n"
     ]
    }
   ],
   "source": [
    "retriever_mmr = db_k.as_retriever(search_type=\"mmr\")\n",
    "result_mmr, results_df = run_and_evaluate(f\"MMR\", retriever_mmr, prompt, llm, results_df)\n",
    "print(\"Marginal relevance\")\n",
    "print(result_mmr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BM25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "passing column names as 'ground_truths' is deprecated and will be removed in the next version, please use 'ground_truth' instead. Note that `ground_truth` should be of type string and not Sequence[string] like `ground_truths`\n",
      "Evaluating: 100%|██████████| 60/60 [00:09<00:00,  6.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average score is: 0.8412957004801213\n",
      "BM25\n",
      "  System  Faithfulness  Answer Relevancy  Context Precision  Context Recall  \\\n",
      "0   BM25        0.9375          0.790087                0.9        0.922857   \n",
      "\n",
      "   Answer Similarity  Answer Correctness   Average  \n",
      "0           0.914668            0.582662  0.841296  \n"
     ]
    }
   ],
   "source": [
    "from langchain.retrievers import BM25Retriever\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(chunk_size = 1000, chunk_overlap = 200)\n",
    "chunks_1000_200 = text_splitter.split_documents(documents)\n",
    "retriever_bm25 = BM25Retriever.from_documents(chunks_1000_200)\n",
    "result_bm25, results_df = run_and_evaluate(f\"BM25\", retriever_bm25, prompt, llm, results_df)\n",
    "print(\"BM25\")\n",
    "print(result_bm25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ensambler - Hybrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "passing column names as 'ground_truths' is deprecated and will be removed in the next version, please use 'ground_truth' instead. Note that `ground_truth` should be of type string and not Sequence[string] like `ground_truths`\n",
      "Evaluating:  38%|███▊      | 23/60 [00:05<00:06,  5.60it/s]Invalid JSON response. Expected dictionary with key 'question'\n",
      "Evaluating: 100%|██████████| 60/60 [00:09<00:00,  6.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average score is: 0.8344842070383661\n",
      "Ensambler\n",
      "        System  Faithfulness  Answer Relevancy  Context Precision  \\\n",
      "0  Ensambler 1           0.9          0.857714           0.838333   \n",
      "\n",
      "   Context Recall  Answer Similarity  Answer Correctness   Average  \n",
      "0            0.98           0.893071            0.537787  0.834484  \n"
     ]
    }
   ],
   "source": [
    "from langchain.retrievers import EnsembleRetriever\n",
    "ret = db_k.as_retriever()\n",
    "ensemble_retriever_1 = EnsembleRetriever(retrievers=[retriever_bm25, ret], weights=[0.75, 0.25])\n",
    "result_ensemble1, results_df = run_and_evaluate(f\"Ensambler 1\", ensemble_retriever_1, prompt, llm, results_df)\n",
    "print(\"Ensambler\")\n",
    "print(result_ensemble1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "passing column names as 'ground_truths' is deprecated and will be removed in the next version, please use 'ground_truth' instead. Note that `ground_truth` should be of type string and not Sequence[string] like `ground_truths`\n",
      "Evaluating:  37%|███▋      | 22/60 [00:05<00:07,  5.13it/s]Invalid JSON response. Expected dictionary with key 'question'\n",
      "Evaluating: 100%|██████████| 60/60 [00:10<00:00,  5.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average score is: 0.8636336690201237\n",
      "Ensambler\n",
      "        System  Faithfulness  Answer Relevancy  Context Precision  \\\n",
      "0  Ensambler 2           1.0          0.748496           0.916667   \n",
      "\n",
      "   Context Recall  Answer Similarity  Answer Correctness   Average  \n",
      "0            0.98           0.921807            0.614832  0.863634  \n"
     ]
    }
   ],
   "source": [
    "ensemble_retriever_2 = EnsembleRetriever(retrievers=[retriever_bm25, ret], weights=[0.5, 0.5])\n",
    "result_ensemble2, results_df = run_and_evaluate(f\"Ensambler 2\", ensemble_retriever_2, prompt, llm, results_df)\n",
    "print(\"Ensambler\")\n",
    "print(result_ensemble2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "passing column names as 'ground_truths' is deprecated and will be removed in the next version, please use 'ground_truth' instead. Note that `ground_truth` should be of type string and not Sequence[string] like `ground_truths`\n",
      "Evaluating:  33%|███▎      | 20/60 [00:05<00:09,  4.27it/s]Invalid JSON response. Expected dictionary with key 'question'\n",
      "Evaluating: 100%|██████████| 60/60 [00:10<00:00,  5.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average score is: 0.8241221463818186\n",
      "Ensambler\n",
      "        System  Faithfulness  Answer Relevancy  Context Precision  \\\n",
      "0  Ensambler 3          0.93          0.653657               0.92   \n",
      "\n",
      "   Context Recall  Answer Similarity  Answer Correctness   Average  \n",
      "0            0.98           0.917549            0.543527  0.824122  \n"
     ]
    }
   ],
   "source": [
    "ensemble_retriever_3 = EnsembleRetriever(retrievers=[retriever_bm25, ret], weights=[0.25,0.75])\n",
    "result_ensemble3, results_df = run_and_evaluate(f\"Ensambler 3\", ensemble_retriever_3, prompt, llm, results_df)\n",
    "print(\"Ensambler\")\n",
    "print(result_ensemble3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>System</th>\n",
       "      <th>Faithfulness</th>\n",
       "      <th>Answer Relevancy</th>\n",
       "      <th>Context Precision</th>\n",
       "      <th>Context Recall</th>\n",
       "      <th>Answer Similarity</th>\n",
       "      <th>Answer Correctness</th>\n",
       "      <th>Average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GPT-3.5</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.375595</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.847668</td>\n",
       "      <td>0.454060</td>\n",
       "      <td>0.625387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GPT-4</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.360955</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.835999</td>\n",
       "      <td>0.415325</td>\n",
       "      <td>0.550658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Naive</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.773143</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.902388</td>\n",
       "      <td>0.599976</td>\n",
       "      <td>0.843378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Recursive</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.772477</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.902388</td>\n",
       "      <td>0.643756</td>\n",
       "      <td>0.852548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Chunk 500, overlap 0%</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.837908</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.920370</td>\n",
       "      <td>0.565194</td>\n",
       "      <td>0.837245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Chunk 500, overlap 5%</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.741242</td>\n",
       "      <td>0.847222</td>\n",
       "      <td>0.925000</td>\n",
       "      <td>0.919578</td>\n",
       "      <td>0.625119</td>\n",
       "      <td>0.822194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Chunk 500, overlap 10%</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.744905</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.917581</td>\n",
       "      <td>0.636998</td>\n",
       "      <td>0.829081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Chunk 500, overlap 15%</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.658863</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.912248</td>\n",
       "      <td>0.598280</td>\n",
       "      <td>0.809713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Chunk 500, overlap 20%</td>\n",
       "      <td>0.907143</td>\n",
       "      <td>0.819640</td>\n",
       "      <td>0.891667</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.916020</td>\n",
       "      <td>0.632423</td>\n",
       "      <td>0.850732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Chunk 1000, overlap 0%</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.797138</td>\n",
       "      <td>0.925000</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.917733</td>\n",
       "      <td>0.622977</td>\n",
       "      <td>0.864549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Chunk 1000, overlap 5%</td>\n",
       "      <td>0.982143</td>\n",
       "      <td>0.702075</td>\n",
       "      <td>0.925000</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.918439</td>\n",
       "      <td>0.590830</td>\n",
       "      <td>0.849748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Chunk 1000, overlap 10%</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.781964</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.922650</td>\n",
       "      <td>0.653329</td>\n",
       "      <td>0.878546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Chunk 1000, overlap 15%</td>\n",
       "      <td>0.982143</td>\n",
       "      <td>0.697939</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.920154</td>\n",
       "      <td>0.621692</td>\n",
       "      <td>0.850321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Chunk 1000, overlap 20%</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.889265</td>\n",
       "      <td>0.883333</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.920670</td>\n",
       "      <td>0.609364</td>\n",
       "      <td>0.880439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Chunk 2000, overlap 0%</td>\n",
       "      <td>0.758913</td>\n",
       "      <td>0.825006</td>\n",
       "      <td>0.917361</td>\n",
       "      <td>0.825000</td>\n",
       "      <td>0.862384</td>\n",
       "      <td>0.781092</td>\n",
       "      <td>0.828293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Chunk 2000, overlap 5%</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.732886</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.775000</td>\n",
       "      <td>0.887796</td>\n",
       "      <td>0.547920</td>\n",
       "      <td>0.815600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Chunk 2000, overlap 10%</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.832789</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.780000</td>\n",
       "      <td>0.910568</td>\n",
       "      <td>0.577737</td>\n",
       "      <td>0.841849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Chunk 2000, overlap 15%</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>0.839517</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.775000</td>\n",
       "      <td>0.910192</td>\n",
       "      <td>0.574588</td>\n",
       "      <td>0.834605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Chunk 2000, overlap 20%</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.734692</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.780000</td>\n",
       "      <td>0.894042</td>\n",
       "      <td>0.575451</td>\n",
       "      <td>0.819586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Chunk 3000, overlap 0%</td>\n",
       "      <td>0.732732</td>\n",
       "      <td>0.922064</td>\n",
       "      <td>0.708958</td>\n",
       "      <td>0.970775</td>\n",
       "      <td>0.883030</td>\n",
       "      <td>0.777719</td>\n",
       "      <td>0.832546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Chunk 3000, overlap 5%</td>\n",
       "      <td>0.908051</td>\n",
       "      <td>0.715152</td>\n",
       "      <td>0.924800</td>\n",
       "      <td>0.617445</td>\n",
       "      <td>0.852376</td>\n",
       "      <td>0.791767</td>\n",
       "      <td>0.801599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Chunk 3000, overlap 10%</td>\n",
       "      <td>0.732732</td>\n",
       "      <td>0.920121</td>\n",
       "      <td>0.690971</td>\n",
       "      <td>0.783333</td>\n",
       "      <td>0.875408</td>\n",
       "      <td>0.775585</td>\n",
       "      <td>0.796358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Chunk 3000, overlap 15%</td>\n",
       "      <td>0.729689</td>\n",
       "      <td>0.920638</td>\n",
       "      <td>0.653896</td>\n",
       "      <td>0.837898</td>\n",
       "      <td>0.882022</td>\n",
       "      <td>0.775137</td>\n",
       "      <td>0.799880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Chunk 3000, overlap 20%</td>\n",
       "      <td>0.863351</td>\n",
       "      <td>0.770708</td>\n",
       "      <td>0.865681</td>\n",
       "      <td>0.915524</td>\n",
       "      <td>0.677045</td>\n",
       "      <td>0.846434</td>\n",
       "      <td>0.823124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Chunk size 3000, overlap 20%, K=2</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>0.731547</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.906164</td>\n",
       "      <td>0.523977</td>\n",
       "      <td>0.836670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Chunk size 3000, overlap 20%, K=3</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.640095</td>\n",
       "      <td>0.883333</td>\n",
       "      <td>0.925000</td>\n",
       "      <td>0.916328</td>\n",
       "      <td>0.567948</td>\n",
       "      <td>0.822117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Chunk size 3000, overlap 20%, K=5</td>\n",
       "      <td>0.968254</td>\n",
       "      <td>0.676828</td>\n",
       "      <td>0.903333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.916220</td>\n",
       "      <td>0.603396</td>\n",
       "      <td>0.844672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Parent Retriever 1000-200</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.738172</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.896140</td>\n",
       "      <td>0.551269</td>\n",
       "      <td>0.828847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Parent Retriever 500-100</td>\n",
       "      <td>0.705718</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.952744</td>\n",
       "      <td>0.983333</td>\n",
       "      <td>0.962346</td>\n",
       "      <td>0.809304</td>\n",
       "      <td>0.860574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Parent Retriever 1500-200</td>\n",
       "      <td>0.690791</td>\n",
       "      <td>0.718519</td>\n",
       "      <td>0.955095</td>\n",
       "      <td>0.983333</td>\n",
       "      <td>0.961934</td>\n",
       "      <td>0.809200</td>\n",
       "      <td>0.853145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>MMR</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.828457</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.719048</td>\n",
       "      <td>0.917804</td>\n",
       "      <td>0.646888</td>\n",
       "      <td>0.835366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>BM25</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.790087</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.922857</td>\n",
       "      <td>0.914668</td>\n",
       "      <td>0.582662</td>\n",
       "      <td>0.841296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Ensambler 1</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.857714</td>\n",
       "      <td>0.838333</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.893071</td>\n",
       "      <td>0.537787</td>\n",
       "      <td>0.834484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Ensambler 2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.748496</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.921807</td>\n",
       "      <td>0.614832</td>\n",
       "      <td>0.863634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Ensambler 3</td>\n",
       "      <td>0.930000</td>\n",
       "      <td>0.653657</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.917549</td>\n",
       "      <td>0.543527</td>\n",
       "      <td>0.824122</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               System  Faithfulness  Answer Relevancy  \\\n",
       "0                             GPT-3.5      1.000000          0.375595   \n",
       "1                               GPT-4      0.750000          0.360955   \n",
       "2                               Naive      0.904762          0.773143   \n",
       "3                           Recursive      0.916667          0.772477   \n",
       "4               Chunk 500, overlap 0%      1.000000          0.837908   \n",
       "5               Chunk 500, overlap 5%      0.875000          0.741242   \n",
       "6              Chunk 500, overlap 10%      0.875000          0.744905   \n",
       "7              Chunk 500, overlap 15%      0.888889          0.658863   \n",
       "8              Chunk 500, overlap 20%      0.907143          0.819640   \n",
       "9              Chunk 1000, overlap 0%      0.944444          0.797138   \n",
       "10             Chunk 1000, overlap 5%      0.982143          0.702075   \n",
       "11            Chunk 1000, overlap 10%      1.000000          0.781964   \n",
       "12            Chunk 1000, overlap 15%      0.982143          0.697939   \n",
       "13            Chunk 1000, overlap 20%      1.000000          0.889265   \n",
       "14             Chunk 2000, overlap 0%      0.758913          0.825006   \n",
       "15             Chunk 2000, overlap 5%      1.000000          0.732886   \n",
       "16            Chunk 2000, overlap 10%      1.000000          0.832789   \n",
       "17            Chunk 2000, overlap 15%      0.958333          0.839517   \n",
       "18            Chunk 2000, overlap 20%      1.000000          0.734692   \n",
       "19             Chunk 3000, overlap 0%      0.732732          0.922064   \n",
       "20             Chunk 3000, overlap 5%      0.908051          0.715152   \n",
       "21            Chunk 3000, overlap 10%      0.732732          0.920121   \n",
       "22            Chunk 3000, overlap 15%      0.729689          0.920638   \n",
       "23            Chunk 3000, overlap 20%      0.863351          0.770708   \n",
       "24  Chunk size 3000, overlap 20%, K=2      0.958333          0.731547   \n",
       "25  Chunk size 3000, overlap 20%, K=3      1.000000          0.640095   \n",
       "26  Chunk size 3000, overlap 20%, K=5      0.968254          0.676828   \n",
       "27          Parent Retriever 1000-200      0.937500          0.738172   \n",
       "28           Parent Retriever 500-100      0.705718          0.750000   \n",
       "29          Parent Retriever 1500-200      0.690791          0.718519   \n",
       "30                                MMR      1.000000          0.828457   \n",
       "31                               BM25      0.937500          0.790087   \n",
       "32                        Ensambler 1      0.900000          0.857714   \n",
       "33                        Ensambler 2      1.000000          0.748496   \n",
       "34                        Ensambler 3      0.930000          0.653657   \n",
       "\n",
       "    Context Precision  Context Recall  Answer Similarity  Answer Correctness  \\\n",
       "0                 NaN             NaN           0.847668            0.454060   \n",
       "1                 NaN             NaN           0.835999            0.415325   \n",
       "2            0.900000        0.980000           0.902388            0.599976   \n",
       "3            0.900000        0.980000           0.902388            0.643756   \n",
       "4            0.800000        0.900000           0.920370            0.565194   \n",
       "5            0.847222        0.925000           0.919578            0.625119   \n",
       "6            0.850000        0.950000           0.917581            0.636998   \n",
       "7            0.900000        0.900000           0.912248            0.598280   \n",
       "8            0.891667        0.937500           0.916020            0.632423   \n",
       "9            0.925000        0.980000           0.917733            0.622977   \n",
       "10           0.925000        0.980000           0.918439            0.590830   \n",
       "11           0.933333        0.980000           0.922650            0.653329   \n",
       "12           0.900000        0.980000           0.920154            0.621692   \n",
       "13           0.883333        0.980000           0.920670            0.609364   \n",
       "14           0.917361        0.825000           0.862384            0.781092   \n",
       "15           0.950000        0.775000           0.887796            0.547920   \n",
       "16           0.950000        0.780000           0.910568            0.577737   \n",
       "17           0.950000        0.775000           0.910192            0.574588   \n",
       "18           0.933333        0.780000           0.894042            0.575451   \n",
       "19           0.708958        0.970775           0.883030            0.777719   \n",
       "20           0.924800        0.617445           0.852376            0.791767   \n",
       "21           0.690971        0.783333           0.875408            0.775585   \n",
       "22           0.653896        0.837898           0.882022            0.775137   \n",
       "23           0.865681        0.915524           0.677045            0.846434   \n",
       "24           0.900000        1.000000           0.906164            0.523977   \n",
       "25           0.883333        0.925000           0.916328            0.567948   \n",
       "26           0.903333        1.000000           0.916220            0.603396   \n",
       "27           0.850000        1.000000           0.896140            0.551269   \n",
       "28           0.952744        0.983333           0.962346            0.809304   \n",
       "29           0.955095        0.983333           0.961934            0.809200   \n",
       "30           0.900000        0.719048           0.917804            0.646888   \n",
       "31           0.900000        0.922857           0.914668            0.582662   \n",
       "32           0.838333        0.980000           0.893071            0.537787   \n",
       "33           0.916667        0.980000           0.921807            0.614832   \n",
       "34           0.920000        0.980000           0.917549            0.543527   \n",
       "\n",
       "     Average  \n",
       "0   0.625387  \n",
       "1   0.550658  \n",
       "2   0.843378  \n",
       "3   0.852548  \n",
       "4   0.837245  \n",
       "5   0.822194  \n",
       "6   0.829081  \n",
       "7   0.809713  \n",
       "8   0.850732  \n",
       "9   0.864549  \n",
       "10  0.849748  \n",
       "11  0.878546  \n",
       "12  0.850321  \n",
       "13  0.880439  \n",
       "14  0.828293  \n",
       "15  0.815600  \n",
       "16  0.841849  \n",
       "17  0.834605  \n",
       "18  0.819586  \n",
       "19  0.832546  \n",
       "20  0.801599  \n",
       "21  0.796358  \n",
       "22  0.799880  \n",
       "23  0.823124  \n",
       "24  0.836670  \n",
       "25  0.822117  \n",
       "26  0.844672  \n",
       "27  0.828847  \n",
       "28  0.860574  \n",
       "29  0.853145  \n",
       "30  0.835366  \n",
       "31  0.841296  \n",
       "32  0.834484  \n",
       "33  0.863634  \n",
       "34  0.824122  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multi-stage - reranker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade --quiet  cohere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "\n",
    "os.environ[\"COHERE_API_KEY\"] = getpass.getpass(\"Cohere API Key:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: BaseCohere.rerank() takes 1 positional argument but 4 positional arguments (and 2 keyword-only arguments) were givenon the following question: Why did the door blow out of Boeing 737 Max shortly after take-off?\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "BaseCohere.rerank() takes 1 positional argument but 4 positional arguments (and 2 keyword-only arguments) were given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 7\u001b[0m, in \u001b[0;36mrun_and_evaluate\u001b[1;34m(name, retriever, prompt, llm, results_df)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:  \n\u001b[1;32m----> 7\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mretrieval_chain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretriever\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mllm\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mquestion\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;66;03m# Access the response content\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\langchain_core\\runnables\\base.py:2056\u001b[0m, in \u001b[0;36mRunnableSequence.invoke\u001b[1;34m(self, input, config)\u001b[0m\n\u001b[0;32m   2055\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, step \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps):\n\u001b[1;32m-> 2056\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mstep\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2057\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2058\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# mark each step as a child run\u001b[39;49;00m\n\u001b[0;32m   2059\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpatch_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2060\u001b[0m \u001b[43m                \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_child\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseq:step:\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mi\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2061\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2062\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2063\u001b[0m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\langchain_core\\runnables\\base.py:2693\u001b[0m, in \u001b[0;36mRunnableParallel.invoke\u001b[1;34m(self, input, config)\u001b[0m\n\u001b[0;32m   2681\u001b[0m         futures \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m   2682\u001b[0m             executor\u001b[38;5;241m.\u001b[39msubmit(\n\u001b[0;32m   2683\u001b[0m                 step\u001b[38;5;241m.\u001b[39minvoke,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2691\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m key, step \u001b[38;5;129;01min\u001b[39;00m steps\u001b[38;5;241m.\u001b[39mitems()\n\u001b[0;32m   2692\u001b[0m         ]\n\u001b[1;32m-> 2693\u001b[0m         output \u001b[38;5;241m=\u001b[39m \u001b[43m{\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfuture\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msteps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m)\u001b[49m\u001b[43m}\u001b[49m\n\u001b[0;32m   2694\u001b[0m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\langchain_core\\runnables\\base.py:2693\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   2681\u001b[0m         futures \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m   2682\u001b[0m             executor\u001b[38;5;241m.\u001b[39msubmit(\n\u001b[0;32m   2683\u001b[0m                 step\u001b[38;5;241m.\u001b[39minvoke,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2691\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m key, step \u001b[38;5;129;01min\u001b[39;00m steps\u001b[38;5;241m.\u001b[39mitems()\n\u001b[0;32m   2692\u001b[0m         ]\n\u001b[1;32m-> 2693\u001b[0m         output \u001b[38;5;241m=\u001b[39m {key: \u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m key, future \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(steps, futures)}\n\u001b[0;32m   2694\u001b[0m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\concurrent\\futures\\_base.py:456\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    455\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[1;32m--> 456\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    457\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\concurrent\\futures\\_base.py:401\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    400\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 401\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[0;32m    402\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    403\u001b[0m     \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\concurrent\\futures\\thread.py:58\u001b[0m, in \u001b[0;36m_WorkItem.run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 58\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[1;32mc:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\langchain_core\\runnables\\base.py:2056\u001b[0m, in \u001b[0;36mRunnableSequence.invoke\u001b[1;34m(self, input, config)\u001b[0m\n\u001b[0;32m   2055\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, step \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps):\n\u001b[1;32m-> 2056\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mstep\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2057\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2058\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# mark each step as a child run\u001b[39;49;00m\n\u001b[0;32m   2059\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpatch_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2060\u001b[0m \u001b[43m                \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_child\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseq:step:\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mi\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2061\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2062\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2063\u001b[0m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\langchain_core\\retrievers.py:141\u001b[0m, in \u001b[0;36mBaseRetriever.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    140\u001b[0m config \u001b[38;5;241m=\u001b[39m ensure_config(config)\n\u001b[1;32m--> 141\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_relevant_documents\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    142\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    143\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcallbacks\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    144\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtags\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    145\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    146\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrun_name\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    147\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    148\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\langchain_core\\retrievers.py:244\u001b[0m, in \u001b[0;36mBaseRetriever.get_relevant_documents\u001b[1;34m(self, query, callbacks, tags, metadata, run_name, **kwargs)\u001b[0m\n\u001b[0;32m    243\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_retriever_error(e)\n\u001b[1;32m--> 244\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m    245\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\langchain_core\\retrievers.py:237\u001b[0m, in \u001b[0;36mBaseRetriever.get_relevant_documents\u001b[1;34m(self, query, callbacks, tags, metadata, run_name, **kwargs)\u001b[0m\n\u001b[0;32m    236\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_new_arg_supported:\n\u001b[1;32m--> 237\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_relevant_documents\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    238\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m_kwargs\u001b[49m\n\u001b[0;32m    239\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    240\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\langchain\\retrievers\\contextual_compression.py:48\u001b[0m, in \u001b[0;36mContextualCompressionRetriever._get_relevant_documents\u001b[1;34m(self, query, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m docs:\n\u001b[1;32m---> 48\u001b[0m     compressed_docs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbase_compressor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompress_documents\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     49\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdocs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     50\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(compressed_docs)\n",
      "File \u001b[1;32mc:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\langchain\\retrievers\\document_compressors\\cohere_rerank.py:107\u001b[0m, in \u001b[0;36mCohereRerank.compress_documents\u001b[1;34m(self, documents, query, callbacks)\u001b[0m\n\u001b[0;32m    106\u001b[0m compressed \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m--> 107\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrerank\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    108\u001b[0m     doc \u001b[38;5;241m=\u001b[39m documents[res[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m]]\n",
      "File \u001b[1;32mc:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\langchain\\retrievers\\document_compressors\\cohere_rerank.py:79\u001b[0m, in \u001b[0;36mCohereRerank.rerank\u001b[1;34m(self, documents, query, model, top_n, max_chunks_per_doc)\u001b[0m\n\u001b[0;32m     78\u001b[0m top_n \u001b[38;5;241m=\u001b[39m top_n \u001b[38;5;28;01mif\u001b[39;00m (top_n \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m top_n \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtop_n\n\u001b[1;32m---> 79\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrerank\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     80\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdocs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_n\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtop_n\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_chunks_per_doc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_chunks_per_doc\u001b[49m\n\u001b[0;32m     81\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     82\u001b[0m result_dicts \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[1;31mTypeError\u001b[0m: BaseCohere.rerank() takes 1 positional argument but 4 positional arguments (and 2 keyword-only arguments) were given",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[67], line 10\u001b[0m\n\u001b[0;32m      5\u001b[0m compressor \u001b[38;5;241m=\u001b[39m CohereRerank()\n\u001b[0;32m      6\u001b[0m compression_retriever \u001b[38;5;241m=\u001b[39m ContextualCompressionRetriever(\n\u001b[0;32m      7\u001b[0m     base_compressor\u001b[38;5;241m=\u001b[39mcompressor, base_retriever\u001b[38;5;241m=\u001b[39mretriever_context\n\u001b[0;32m      8\u001b[0m )\n\u001b[1;32m---> 10\u001b[0m result_compression, results_df \u001b[38;5;241m=\u001b[39m \u001b[43mrun_and_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mCohere reranker\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompression_retriever\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mllm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresults_df\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReranker\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(result_compression)\n",
      "Cell \u001b[1;32mIn[23], line 16\u001b[0m, in \u001b[0;36mrun_and_evaluate\u001b[1;34m(name, retriever, prompt, llm, results_df)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWarning: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon the following question: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m query)  \n\u001b[0;32m     15\u001b[0m answers\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo answer\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 16\u001b[0m context_full \u001b[38;5;241m=\u001b[39m \u001b[43mretriever\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_relevant_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m context_content \u001b[38;5;241m=\u001b[39m [context\u001b[38;5;241m.\u001b[39mpage_content \u001b[38;5;28;01mfor\u001b[39;00m context \u001b[38;5;129;01min\u001b[39;00m context_full]\n\u001b[0;32m     18\u001b[0m contexts_extra\u001b[38;5;241m.\u001b[39mappend(context_content)\n",
      "File \u001b[1;32mc:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\langchain_core\\retrievers.py:244\u001b[0m, in \u001b[0;36mBaseRetriever.get_relevant_documents\u001b[1;34m(self, query, callbacks, tags, metadata, run_name, **kwargs)\u001b[0m\n\u001b[0;32m    242\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    243\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_retriever_error(e)\n\u001b[1;32m--> 244\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m    245\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    246\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_retriever_end(\n\u001b[0;32m    247\u001b[0m         result,\n\u001b[0;32m    248\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\langchain_core\\retrievers.py:237\u001b[0m, in \u001b[0;36mBaseRetriever.get_relevant_documents\u001b[1;34m(self, query, callbacks, tags, metadata, run_name, **kwargs)\u001b[0m\n\u001b[0;32m    235\u001b[0m _kwargs \u001b[38;5;241m=\u001b[39m kwargs \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expects_other_args \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[0;32m    236\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_new_arg_supported:\n\u001b[1;32m--> 237\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_relevant_documents\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    238\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m_kwargs\u001b[49m\n\u001b[0;32m    239\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    240\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    241\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_relevant_documents(query, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m_kwargs)\n",
      "File \u001b[1;32mc:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\langchain\\retrievers\\contextual_compression.py:48\u001b[0m, in \u001b[0;36mContextualCompressionRetriever._get_relevant_documents\u001b[1;34m(self, query, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m     44\u001b[0m docs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbase_retriever\u001b[38;5;241m.\u001b[39mget_relevant_documents(\n\u001b[0;32m     45\u001b[0m     query, callbacks\u001b[38;5;241m=\u001b[39mrun_manager\u001b[38;5;241m.\u001b[39mget_child(), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m     46\u001b[0m )\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m docs:\n\u001b[1;32m---> 48\u001b[0m     compressed_docs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbase_compressor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompress_documents\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     49\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdocs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     50\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(compressed_docs)\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\langchain\\retrievers\\document_compressors\\cohere_rerank.py:107\u001b[0m, in \u001b[0;36mCohereRerank.compress_documents\u001b[1;34m(self, documents, query, callbacks)\u001b[0m\n\u001b[0;32m     95\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     96\u001b[0m \u001b[38;5;124;03mCompress documents using Cohere's rerank API.\u001b[39;00m\n\u001b[0;32m     97\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[38;5;124;03m    A sequence of compressed documents.\u001b[39;00m\n\u001b[0;32m    105\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    106\u001b[0m compressed \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m--> 107\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrerank\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    108\u001b[0m     doc \u001b[38;5;241m=\u001b[39m documents[res[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m]]\n\u001b[0;32m    109\u001b[0m     doc_copy \u001b[38;5;241m=\u001b[39m Document(doc\u001b[38;5;241m.\u001b[39mpage_content, metadata\u001b[38;5;241m=\u001b[39mdeepcopy(doc\u001b[38;5;241m.\u001b[39mmetadata))\n",
      "File \u001b[1;32mc:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\langchain\\retrievers\\document_compressors\\cohere_rerank.py:79\u001b[0m, in \u001b[0;36mCohereRerank.rerank\u001b[1;34m(self, documents, query, model, top_n, max_chunks_per_doc)\u001b[0m\n\u001b[0;32m     77\u001b[0m model \u001b[38;5;241m=\u001b[39m model \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\n\u001b[0;32m     78\u001b[0m top_n \u001b[38;5;241m=\u001b[39m top_n \u001b[38;5;28;01mif\u001b[39;00m (top_n \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m top_n \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtop_n\n\u001b[1;32m---> 79\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrerank\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     80\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdocs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_n\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtop_n\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_chunks_per_doc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_chunks_per_doc\u001b[49m\n\u001b[0;32m     81\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     82\u001b[0m result_dicts \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     83\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results:\n",
      "\u001b[1;31mTypeError\u001b[0m: BaseCohere.rerank() takes 1 positional argument but 4 positional arguments (and 2 keyword-only arguments) were given"
     ]
    }
   ],
   "source": [
    "from langchain.retrievers.document_compressors import CohereRerank\n",
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "\n",
    "retriever_context = ret\n",
    "compressor = CohereRerank()\n",
    "compression_retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=compressor, \n",
    "    base_retriever=retriever_context\n",
    ")\n",
    "\n",
    "result_compression, results_df = run_and_evaluate(f\"Cohere reranker\", compression_retriever, prompt, llm, results_df)\n",
    "print(\"Reranker\")\n",
    "print(result_compression)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### creating context by remaking the query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "template_context = \"Generate a search query to fetch the relevant documents using the user's {question}. Craft a query that specifically targets the keywords in the question. In the answer provide only the query.\"\n",
    "prompt_context = ChatPromptTemplate.from_template(template_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "passing column names as 'ground_truths' is deprecated and will be removed in the next version, please use 'ground_truth' instead. Note that `ground_truth` should be of type string and not Sequence[string] like `ground_truths`\n",
      "Evaluating: 100%|██████████| 60/60 [00:09<00:00,  6.57it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'faithfulness': 0.9524, 'answer_relevancy': 0.6399, 'context_precision': 0.8833, 'context_recall': 0.9800, 'answer_similarity': 0.9106, 'answer_correctness': 0.5443}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers_final = []\n",
    "contexts_final = []\n",
    "# retriever_context_q = EnsembleRetriever(retrievers=[retriever_bm25, retriever_3], weights=[0.5, 0.5])\n",
    "llm_for_context =(\n",
    "    { \"question\": itemgetter(\"question\")}\n",
    "    | RunnablePassthrough()\n",
    "    | {\"response\": prompt_context | llm}\n",
    ")\n",
    "for query in questions:\n",
    "    response_check = llm_for_context.invoke({\"question\": query})\n",
    "    search_query = response_check[\"response\"].content\n",
    "    retrieval_augmented_qa_chain = (\n",
    "        {\"context\": itemgetter(\"context\"), \"question\": itemgetter(\"question\")}\n",
    "        | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
    "        | {\"response\": prompt | llm, \"context\": itemgetter(\"context\")}\n",
    ")\n",
    "    docs = ret.get_relevant_documents(search_query)\n",
    "    formatted_docs = []\n",
    "    for doc in docs:\n",
    "        resulting_doc = doc.page_content\n",
    "        formatted_docs.append(resulting_doc)\n",
    "    try:  \n",
    "            response = retrieval_augmented_qa_chain.invoke({\"context\": formatted_docs, \"question\": query})\n",
    "            # Access the response content\n",
    "            answers_final.append(response[\"response\"].content)\n",
    "            contexts_final.append(formatted_docs)  \n",
    "    except Exception as e:  \n",
    "            print(f\"Warning: {e}\" + \"on the following question: \" + query)  \n",
    "            answers_final.append(\"No answer\")\n",
    "            contexts_final.append(formatted_docs)\n",
    "\n",
    "\n",
    "result_search_query = evaluation_rag(questions, answers_final, contexts_final, ground_truths)\n",
    "result_search_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average score is: 0.8184278479648288\n"
     ]
    }
   ],
   "source": [
    "average = dictionary(result_search_query)\n",
    "    # Create a dictionary to store the results\n",
    "system_results = {\n",
    "        \"System\": \"Search query\",\n",
    "        \"Faithfulness\": result_search_query[\"faithfulness\"],\n",
    "        \"Answer Relevancy\": result_search_query[\"answer_relevancy\"],\n",
    "        \"Context Precision\": result_search_query[\"context_precision\"],\n",
    "        \"Context Recall\": result_search_query[\"context_recall\"],\n",
    "        \"Answer Similarity\": result_search_query[\"answer_similarity\"],\n",
    "        \"Answer Correctness\": result_search_query[\"answer_correctness\"],\n",
    "        \"Average\": average\n",
    "    }\n",
    "df_result_search_query = pd.DataFrame([system_results])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>System</th>\n",
       "      <th>Faithfulness</th>\n",
       "      <th>Answer Relevancy</th>\n",
       "      <th>Context Precision</th>\n",
       "      <th>Context Recall</th>\n",
       "      <th>Answer Similarity</th>\n",
       "      <th>Answer Correctness</th>\n",
       "      <th>Average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GPT-3.5</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.375595</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.847668</td>\n",
       "      <td>0.454060</td>\n",
       "      <td>0.625387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GPT-4</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.360955</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.835999</td>\n",
       "      <td>0.415325</td>\n",
       "      <td>0.550658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Naive</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.773143</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.902388</td>\n",
       "      <td>0.599976</td>\n",
       "      <td>0.843378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Recursive</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.772477</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.902388</td>\n",
       "      <td>0.643756</td>\n",
       "      <td>0.852548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Chunk 500, overlap 0%</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.837908</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.920370</td>\n",
       "      <td>0.565194</td>\n",
       "      <td>0.837245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Chunk 500, overlap 5%</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.741242</td>\n",
       "      <td>0.847222</td>\n",
       "      <td>0.925000</td>\n",
       "      <td>0.919578</td>\n",
       "      <td>0.625119</td>\n",
       "      <td>0.822194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Chunk 500, overlap 10%</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.744905</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.917581</td>\n",
       "      <td>0.636998</td>\n",
       "      <td>0.829081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Chunk 500, overlap 15%</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.658863</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.912248</td>\n",
       "      <td>0.598280</td>\n",
       "      <td>0.809713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Chunk 500, overlap 20%</td>\n",
       "      <td>0.907143</td>\n",
       "      <td>0.819640</td>\n",
       "      <td>0.891667</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.916020</td>\n",
       "      <td>0.632423</td>\n",
       "      <td>0.850732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Chunk 1000, overlap 0%</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.797138</td>\n",
       "      <td>0.925000</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.917733</td>\n",
       "      <td>0.622977</td>\n",
       "      <td>0.864549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Chunk 1000, overlap 5%</td>\n",
       "      <td>0.982143</td>\n",
       "      <td>0.702075</td>\n",
       "      <td>0.925000</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.918439</td>\n",
       "      <td>0.590830</td>\n",
       "      <td>0.849748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Chunk 1000, overlap 10%</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.781964</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.922650</td>\n",
       "      <td>0.653329</td>\n",
       "      <td>0.878546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Chunk 1000, overlap 15%</td>\n",
       "      <td>0.982143</td>\n",
       "      <td>0.697939</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.920154</td>\n",
       "      <td>0.621692</td>\n",
       "      <td>0.850321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Chunk 1000, overlap 20%</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.889265</td>\n",
       "      <td>0.883333</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.920670</td>\n",
       "      <td>0.609364</td>\n",
       "      <td>0.880439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Chunk 2000, overlap 0%</td>\n",
       "      <td>0.758913</td>\n",
       "      <td>0.825006</td>\n",
       "      <td>0.917361</td>\n",
       "      <td>0.825000</td>\n",
       "      <td>0.862384</td>\n",
       "      <td>0.781092</td>\n",
       "      <td>0.828293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Chunk 2000, overlap 5%</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.732886</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.775000</td>\n",
       "      <td>0.887796</td>\n",
       "      <td>0.547920</td>\n",
       "      <td>0.815600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Chunk 2000, overlap 10%</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.832789</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.780000</td>\n",
       "      <td>0.910568</td>\n",
       "      <td>0.577737</td>\n",
       "      <td>0.841849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Chunk 2000, overlap 15%</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>0.839517</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.775000</td>\n",
       "      <td>0.910192</td>\n",
       "      <td>0.574588</td>\n",
       "      <td>0.834605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Chunk 2000, overlap 20%</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.734692</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.780000</td>\n",
       "      <td>0.894042</td>\n",
       "      <td>0.575451</td>\n",
       "      <td>0.819586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Chunk 3000, overlap 0%</td>\n",
       "      <td>0.732732</td>\n",
       "      <td>0.922064</td>\n",
       "      <td>0.708958</td>\n",
       "      <td>0.970775</td>\n",
       "      <td>0.883030</td>\n",
       "      <td>0.777719</td>\n",
       "      <td>0.832546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Chunk 3000, overlap 5%</td>\n",
       "      <td>0.908051</td>\n",
       "      <td>0.715152</td>\n",
       "      <td>0.924800</td>\n",
       "      <td>0.617445</td>\n",
       "      <td>0.852376</td>\n",
       "      <td>0.791767</td>\n",
       "      <td>0.801599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Chunk 3000, overlap 10%</td>\n",
       "      <td>0.732732</td>\n",
       "      <td>0.920121</td>\n",
       "      <td>0.690971</td>\n",
       "      <td>0.783333</td>\n",
       "      <td>0.875408</td>\n",
       "      <td>0.775585</td>\n",
       "      <td>0.796358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Chunk 3000, overlap 15%</td>\n",
       "      <td>0.729689</td>\n",
       "      <td>0.920638</td>\n",
       "      <td>0.653896</td>\n",
       "      <td>0.837898</td>\n",
       "      <td>0.882022</td>\n",
       "      <td>0.775137</td>\n",
       "      <td>0.799880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Chunk 3000, overlap 20%</td>\n",
       "      <td>0.863351</td>\n",
       "      <td>0.770708</td>\n",
       "      <td>0.865681</td>\n",
       "      <td>0.915524</td>\n",
       "      <td>0.677045</td>\n",
       "      <td>0.846434</td>\n",
       "      <td>0.823124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Chunk size 3000, overlap 20%, K=2</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>0.731547</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.906164</td>\n",
       "      <td>0.523977</td>\n",
       "      <td>0.836670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Chunk size 3000, overlap 20%, K=3</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.640095</td>\n",
       "      <td>0.883333</td>\n",
       "      <td>0.925000</td>\n",
       "      <td>0.916328</td>\n",
       "      <td>0.567948</td>\n",
       "      <td>0.822117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Chunk size 3000, overlap 20%, K=5</td>\n",
       "      <td>0.968254</td>\n",
       "      <td>0.676828</td>\n",
       "      <td>0.903333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.916220</td>\n",
       "      <td>0.603396</td>\n",
       "      <td>0.844672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Parent Retriever 1000-200</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.738172</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.896140</td>\n",
       "      <td>0.551269</td>\n",
       "      <td>0.828847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Parent Retriever 500-100</td>\n",
       "      <td>0.705718</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.952744</td>\n",
       "      <td>0.983333</td>\n",
       "      <td>0.962346</td>\n",
       "      <td>0.809304</td>\n",
       "      <td>0.860574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Parent Retriever 1500-200</td>\n",
       "      <td>0.690791</td>\n",
       "      <td>0.718519</td>\n",
       "      <td>0.955095</td>\n",
       "      <td>0.983333</td>\n",
       "      <td>0.961934</td>\n",
       "      <td>0.809200</td>\n",
       "      <td>0.853145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>MMR</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.828457</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.719048</td>\n",
       "      <td>0.917804</td>\n",
       "      <td>0.646888</td>\n",
       "      <td>0.835366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>BM25</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.790087</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.922857</td>\n",
       "      <td>0.914668</td>\n",
       "      <td>0.582662</td>\n",
       "      <td>0.841296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Ensambler 1</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.857714</td>\n",
       "      <td>0.838333</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.893071</td>\n",
       "      <td>0.537787</td>\n",
       "      <td>0.834484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Ensambler 2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.748496</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.921807</td>\n",
       "      <td>0.614832</td>\n",
       "      <td>0.863634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Ensambler 3</td>\n",
       "      <td>0.930000</td>\n",
       "      <td>0.653657</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.917549</td>\n",
       "      <td>0.543527</td>\n",
       "      <td>0.824122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Chunk 1000, overlap 20%, GPT-4</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.711227</td>\n",
       "      <td>0.883333</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.925291</td>\n",
       "      <td>0.676095</td>\n",
       "      <td>0.862658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Search query</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.639922</td>\n",
       "      <td>0.883333</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.910644</td>\n",
       "      <td>0.544286</td>\n",
       "      <td>0.818428</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               System  Faithfulness  Answer Relevancy  \\\n",
       "0                             GPT-3.5      1.000000          0.375595   \n",
       "1                               GPT-4      0.750000          0.360955   \n",
       "2                               Naive      0.904762          0.773143   \n",
       "3                           Recursive      0.916667          0.772477   \n",
       "4               Chunk 500, overlap 0%      1.000000          0.837908   \n",
       "5               Chunk 500, overlap 5%      0.875000          0.741242   \n",
       "6              Chunk 500, overlap 10%      0.875000          0.744905   \n",
       "7              Chunk 500, overlap 15%      0.888889          0.658863   \n",
       "8              Chunk 500, overlap 20%      0.907143          0.819640   \n",
       "9              Chunk 1000, overlap 0%      0.944444          0.797138   \n",
       "10             Chunk 1000, overlap 5%      0.982143          0.702075   \n",
       "11            Chunk 1000, overlap 10%      1.000000          0.781964   \n",
       "12            Chunk 1000, overlap 15%      0.982143          0.697939   \n",
       "13            Chunk 1000, overlap 20%      1.000000          0.889265   \n",
       "14             Chunk 2000, overlap 0%      0.758913          0.825006   \n",
       "15             Chunk 2000, overlap 5%      1.000000          0.732886   \n",
       "16            Chunk 2000, overlap 10%      1.000000          0.832789   \n",
       "17            Chunk 2000, overlap 15%      0.958333          0.839517   \n",
       "18            Chunk 2000, overlap 20%      1.000000          0.734692   \n",
       "19             Chunk 3000, overlap 0%      0.732732          0.922064   \n",
       "20             Chunk 3000, overlap 5%      0.908051          0.715152   \n",
       "21            Chunk 3000, overlap 10%      0.732732          0.920121   \n",
       "22            Chunk 3000, overlap 15%      0.729689          0.920638   \n",
       "23            Chunk 3000, overlap 20%      0.863351          0.770708   \n",
       "24  Chunk size 3000, overlap 20%, K=2      0.958333          0.731547   \n",
       "25  Chunk size 3000, overlap 20%, K=3      1.000000          0.640095   \n",
       "26  Chunk size 3000, overlap 20%, K=5      0.968254          0.676828   \n",
       "27          Parent Retriever 1000-200      0.937500          0.738172   \n",
       "28           Parent Retriever 500-100      0.705718          0.750000   \n",
       "29          Parent Retriever 1500-200      0.690791          0.718519   \n",
       "30                                MMR      1.000000          0.828457   \n",
       "31                               BM25      0.937500          0.790087   \n",
       "32                        Ensambler 1      0.900000          0.857714   \n",
       "33                        Ensambler 2      1.000000          0.748496   \n",
       "34                        Ensambler 3      0.930000          0.653657   \n",
       "35     Chunk 1000, overlap 20%, GPT-4      1.000000          0.711227   \n",
       "36                       Search query      0.952381          0.639922   \n",
       "\n",
       "    Context Precision  Context Recall  Answer Similarity  Answer Correctness  \\\n",
       "0                 NaN             NaN           0.847668            0.454060   \n",
       "1                 NaN             NaN           0.835999            0.415325   \n",
       "2            0.900000        0.980000           0.902388            0.599976   \n",
       "3            0.900000        0.980000           0.902388            0.643756   \n",
       "4            0.800000        0.900000           0.920370            0.565194   \n",
       "5            0.847222        0.925000           0.919578            0.625119   \n",
       "6            0.850000        0.950000           0.917581            0.636998   \n",
       "7            0.900000        0.900000           0.912248            0.598280   \n",
       "8            0.891667        0.937500           0.916020            0.632423   \n",
       "9            0.925000        0.980000           0.917733            0.622977   \n",
       "10           0.925000        0.980000           0.918439            0.590830   \n",
       "11           0.933333        0.980000           0.922650            0.653329   \n",
       "12           0.900000        0.980000           0.920154            0.621692   \n",
       "13           0.883333        0.980000           0.920670            0.609364   \n",
       "14           0.917361        0.825000           0.862384            0.781092   \n",
       "15           0.950000        0.775000           0.887796            0.547920   \n",
       "16           0.950000        0.780000           0.910568            0.577737   \n",
       "17           0.950000        0.775000           0.910192            0.574588   \n",
       "18           0.933333        0.780000           0.894042            0.575451   \n",
       "19           0.708958        0.970775           0.883030            0.777719   \n",
       "20           0.924800        0.617445           0.852376            0.791767   \n",
       "21           0.690971        0.783333           0.875408            0.775585   \n",
       "22           0.653896        0.837898           0.882022            0.775137   \n",
       "23           0.865681        0.915524           0.677045            0.846434   \n",
       "24           0.900000        1.000000           0.906164            0.523977   \n",
       "25           0.883333        0.925000           0.916328            0.567948   \n",
       "26           0.903333        1.000000           0.916220            0.603396   \n",
       "27           0.850000        1.000000           0.896140            0.551269   \n",
       "28           0.952744        0.983333           0.962346            0.809304   \n",
       "29           0.955095        0.983333           0.961934            0.809200   \n",
       "30           0.900000        0.719048           0.917804            0.646888   \n",
       "31           0.900000        0.922857           0.914668            0.582662   \n",
       "32           0.838333        0.980000           0.893071            0.537787   \n",
       "33           0.916667        0.980000           0.921807            0.614832   \n",
       "34           0.920000        0.980000           0.917549            0.543527   \n",
       "35           0.883333        0.980000           0.925291            0.676095   \n",
       "36           0.883333        0.980000           0.910644            0.544286   \n",
       "\n",
       "     Average  \n",
       "0   0.625387  \n",
       "1   0.550658  \n",
       "2   0.843378  \n",
       "3   0.852548  \n",
       "4   0.837245  \n",
       "5   0.822194  \n",
       "6   0.829081  \n",
       "7   0.809713  \n",
       "8   0.850732  \n",
       "9   0.864549  \n",
       "10  0.849748  \n",
       "11  0.878546  \n",
       "12  0.850321  \n",
       "13  0.880439  \n",
       "14  0.828293  \n",
       "15  0.815600  \n",
       "16  0.841849  \n",
       "17  0.834605  \n",
       "18  0.819586  \n",
       "19  0.832546  \n",
       "20  0.801599  \n",
       "21  0.796358  \n",
       "22  0.799880  \n",
       "23  0.823124  \n",
       "24  0.836670  \n",
       "25  0.822117  \n",
       "26  0.844672  \n",
       "27  0.828847  \n",
       "28  0.860574  \n",
       "29  0.853145  \n",
       "30  0.835366  \n",
       "31  0.841296  \n",
       "32  0.834484  \n",
       "33  0.863634  \n",
       "34  0.824122  \n",
       "35  0.862658  \n",
       "36  0.818428  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df = pd.concat([results_df, df_result_search_query], ignore_index=True)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### change model to GPT-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_gpt4 = AzureChatOpenAI(model_name=OPENAI_MODEL_GPT4, azure_deployment=OPENAI_DEPLOYMENT_GPT4,temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>System</th>\n",
       "      <th>Faithfulness</th>\n",
       "      <th>Answer Relevancy</th>\n",
       "      <th>Context Precision</th>\n",
       "      <th>Context Recall</th>\n",
       "      <th>Answer Similarity</th>\n",
       "      <th>Answer Correctness</th>\n",
       "      <th>Average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GPT-3.5</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.375595</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.847668</td>\n",
       "      <td>0.454060</td>\n",
       "      <td>0.625387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GPT-4</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.360955</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.835999</td>\n",
       "      <td>0.415325</td>\n",
       "      <td>0.550658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Naive</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.773143</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.902388</td>\n",
       "      <td>0.599976</td>\n",
       "      <td>0.843378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Recursive</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.772477</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.902388</td>\n",
       "      <td>0.643756</td>\n",
       "      <td>0.852548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Chunk 500, overlap 0%</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.837908</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.920370</td>\n",
       "      <td>0.565194</td>\n",
       "      <td>0.837245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Chunk 500, overlap 5%</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.741242</td>\n",
       "      <td>0.847222</td>\n",
       "      <td>0.925000</td>\n",
       "      <td>0.919578</td>\n",
       "      <td>0.625119</td>\n",
       "      <td>0.822194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Chunk 500, overlap 10%</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.744905</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.917581</td>\n",
       "      <td>0.636998</td>\n",
       "      <td>0.829081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Chunk 500, overlap 15%</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.658863</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.912248</td>\n",
       "      <td>0.598280</td>\n",
       "      <td>0.809713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Chunk 500, overlap 20%</td>\n",
       "      <td>0.907143</td>\n",
       "      <td>0.819640</td>\n",
       "      <td>0.891667</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.916020</td>\n",
       "      <td>0.632423</td>\n",
       "      <td>0.850732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Chunk 1000, overlap 0%</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.797138</td>\n",
       "      <td>0.925000</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.917733</td>\n",
       "      <td>0.622977</td>\n",
       "      <td>0.864549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Chunk 1000, overlap 5%</td>\n",
       "      <td>0.982143</td>\n",
       "      <td>0.702075</td>\n",
       "      <td>0.925000</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.918439</td>\n",
       "      <td>0.590830</td>\n",
       "      <td>0.849748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Chunk 1000, overlap 10%</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.781964</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.922650</td>\n",
       "      <td>0.653329</td>\n",
       "      <td>0.878546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Chunk 1000, overlap 15%</td>\n",
       "      <td>0.982143</td>\n",
       "      <td>0.697939</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.920154</td>\n",
       "      <td>0.621692</td>\n",
       "      <td>0.850321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Chunk 1000, overlap 20%</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.889265</td>\n",
       "      <td>0.883333</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.920670</td>\n",
       "      <td>0.609364</td>\n",
       "      <td>0.880439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Chunk 2000, overlap 0%</td>\n",
       "      <td>0.758913</td>\n",
       "      <td>0.825006</td>\n",
       "      <td>0.917361</td>\n",
       "      <td>0.825000</td>\n",
       "      <td>0.862384</td>\n",
       "      <td>0.781092</td>\n",
       "      <td>0.828293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Chunk 2000, overlap 5%</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.732886</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.775000</td>\n",
       "      <td>0.887796</td>\n",
       "      <td>0.547920</td>\n",
       "      <td>0.815600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Chunk 2000, overlap 10%</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.832789</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.780000</td>\n",
       "      <td>0.910568</td>\n",
       "      <td>0.577737</td>\n",
       "      <td>0.841849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Chunk 2000, overlap 15%</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>0.839517</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.775000</td>\n",
       "      <td>0.910192</td>\n",
       "      <td>0.574588</td>\n",
       "      <td>0.834605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Chunk 2000, overlap 20%</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.734692</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.780000</td>\n",
       "      <td>0.894042</td>\n",
       "      <td>0.575451</td>\n",
       "      <td>0.819586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Chunk 3000, overlap 0%</td>\n",
       "      <td>0.732732</td>\n",
       "      <td>0.922064</td>\n",
       "      <td>0.708958</td>\n",
       "      <td>0.970775</td>\n",
       "      <td>0.883030</td>\n",
       "      <td>0.777719</td>\n",
       "      <td>0.832546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Chunk 3000, overlap 5%</td>\n",
       "      <td>0.908051</td>\n",
       "      <td>0.715152</td>\n",
       "      <td>0.924800</td>\n",
       "      <td>0.617445</td>\n",
       "      <td>0.852376</td>\n",
       "      <td>0.791767</td>\n",
       "      <td>0.801599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Chunk 3000, overlap 10%</td>\n",
       "      <td>0.732732</td>\n",
       "      <td>0.920121</td>\n",
       "      <td>0.690971</td>\n",
       "      <td>0.783333</td>\n",
       "      <td>0.875408</td>\n",
       "      <td>0.775585</td>\n",
       "      <td>0.796358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Chunk 3000, overlap 15%</td>\n",
       "      <td>0.729689</td>\n",
       "      <td>0.920638</td>\n",
       "      <td>0.653896</td>\n",
       "      <td>0.837898</td>\n",
       "      <td>0.882022</td>\n",
       "      <td>0.775137</td>\n",
       "      <td>0.799880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Chunk 3000, overlap 20%</td>\n",
       "      <td>0.863351</td>\n",
       "      <td>0.770708</td>\n",
       "      <td>0.865681</td>\n",
       "      <td>0.915524</td>\n",
       "      <td>0.677045</td>\n",
       "      <td>0.846434</td>\n",
       "      <td>0.823124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Chunk size 3000, overlap 20%, K=2</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>0.731547</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.906164</td>\n",
       "      <td>0.523977</td>\n",
       "      <td>0.836670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Chunk size 3000, overlap 20%, K=3</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.640095</td>\n",
       "      <td>0.883333</td>\n",
       "      <td>0.925000</td>\n",
       "      <td>0.916328</td>\n",
       "      <td>0.567948</td>\n",
       "      <td>0.822117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Chunk size 3000, overlap 20%, K=5</td>\n",
       "      <td>0.968254</td>\n",
       "      <td>0.676828</td>\n",
       "      <td>0.903333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.916220</td>\n",
       "      <td>0.603396</td>\n",
       "      <td>0.844672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Parent Retriever 1000-200</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.738172</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.896140</td>\n",
       "      <td>0.551269</td>\n",
       "      <td>0.828847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Parent Retriever 500-100</td>\n",
       "      <td>0.705718</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.952744</td>\n",
       "      <td>0.983333</td>\n",
       "      <td>0.962346</td>\n",
       "      <td>0.809304</td>\n",
       "      <td>0.860574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Parent Retriever 1500-200</td>\n",
       "      <td>0.690791</td>\n",
       "      <td>0.718519</td>\n",
       "      <td>0.955095</td>\n",
       "      <td>0.983333</td>\n",
       "      <td>0.961934</td>\n",
       "      <td>0.809200</td>\n",
       "      <td>0.853145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>MMR</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.828457</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.719048</td>\n",
       "      <td>0.917804</td>\n",
       "      <td>0.646888</td>\n",
       "      <td>0.835366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>BM25</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.790087</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.922857</td>\n",
       "      <td>0.914668</td>\n",
       "      <td>0.582662</td>\n",
       "      <td>0.841296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Ensambler 1</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.857714</td>\n",
       "      <td>0.838333</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.893071</td>\n",
       "      <td>0.537787</td>\n",
       "      <td>0.834484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Ensambler 2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.748496</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.921807</td>\n",
       "      <td>0.614832</td>\n",
       "      <td>0.863634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Ensambler 3</td>\n",
       "      <td>0.930000</td>\n",
       "      <td>0.653657</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.917549</td>\n",
       "      <td>0.543527</td>\n",
       "      <td>0.824122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Updated search query</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.890533</td>\n",
       "      <td>0.883333</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.921927</td>\n",
       "      <td>0.593488</td>\n",
       "      <td>0.878214</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               System  Faithfulness  Answer Relevancy  \\\n",
       "0                             GPT-3.5      1.000000          0.375595   \n",
       "1                               GPT-4      0.750000          0.360955   \n",
       "2                               Naive      0.904762          0.773143   \n",
       "3                           Recursive      0.916667          0.772477   \n",
       "4               Chunk 500, overlap 0%      1.000000          0.837908   \n",
       "5               Chunk 500, overlap 5%      0.875000          0.741242   \n",
       "6              Chunk 500, overlap 10%      0.875000          0.744905   \n",
       "7              Chunk 500, overlap 15%      0.888889          0.658863   \n",
       "8              Chunk 500, overlap 20%      0.907143          0.819640   \n",
       "9              Chunk 1000, overlap 0%      0.944444          0.797138   \n",
       "10             Chunk 1000, overlap 5%      0.982143          0.702075   \n",
       "11            Chunk 1000, overlap 10%      1.000000          0.781964   \n",
       "12            Chunk 1000, overlap 15%      0.982143          0.697939   \n",
       "13            Chunk 1000, overlap 20%      1.000000          0.889265   \n",
       "14             Chunk 2000, overlap 0%      0.758913          0.825006   \n",
       "15             Chunk 2000, overlap 5%      1.000000          0.732886   \n",
       "16            Chunk 2000, overlap 10%      1.000000          0.832789   \n",
       "17            Chunk 2000, overlap 15%      0.958333          0.839517   \n",
       "18            Chunk 2000, overlap 20%      1.000000          0.734692   \n",
       "19             Chunk 3000, overlap 0%      0.732732          0.922064   \n",
       "20             Chunk 3000, overlap 5%      0.908051          0.715152   \n",
       "21            Chunk 3000, overlap 10%      0.732732          0.920121   \n",
       "22            Chunk 3000, overlap 15%      0.729689          0.920638   \n",
       "23            Chunk 3000, overlap 20%      0.863351          0.770708   \n",
       "24  Chunk size 3000, overlap 20%, K=2      0.958333          0.731547   \n",
       "25  Chunk size 3000, overlap 20%, K=3      1.000000          0.640095   \n",
       "26  Chunk size 3000, overlap 20%, K=5      0.968254          0.676828   \n",
       "27          Parent Retriever 1000-200      0.937500          0.738172   \n",
       "28           Parent Retriever 500-100      0.705718          0.750000   \n",
       "29          Parent Retriever 1500-200      0.690791          0.718519   \n",
       "30                                MMR      1.000000          0.828457   \n",
       "31                               BM25      0.937500          0.790087   \n",
       "32                        Ensambler 1      0.900000          0.857714   \n",
       "33                        Ensambler 2      1.000000          0.748496   \n",
       "34                        Ensambler 3      0.930000          0.653657   \n",
       "35               Updated search query      1.000000          0.890533   \n",
       "\n",
       "    Context Precision  Context Recall  Answer Similarity  Answer Correctness  \\\n",
       "0                 NaN             NaN           0.847668            0.454060   \n",
       "1                 NaN             NaN           0.835999            0.415325   \n",
       "2            0.900000        0.980000           0.902388            0.599976   \n",
       "3            0.900000        0.980000           0.902388            0.643756   \n",
       "4            0.800000        0.900000           0.920370            0.565194   \n",
       "5            0.847222        0.925000           0.919578            0.625119   \n",
       "6            0.850000        0.950000           0.917581            0.636998   \n",
       "7            0.900000        0.900000           0.912248            0.598280   \n",
       "8            0.891667        0.937500           0.916020            0.632423   \n",
       "9            0.925000        0.980000           0.917733            0.622977   \n",
       "10           0.925000        0.980000           0.918439            0.590830   \n",
       "11           0.933333        0.980000           0.922650            0.653329   \n",
       "12           0.900000        0.980000           0.920154            0.621692   \n",
       "13           0.883333        0.980000           0.920670            0.609364   \n",
       "14           0.917361        0.825000           0.862384            0.781092   \n",
       "15           0.950000        0.775000           0.887796            0.547920   \n",
       "16           0.950000        0.780000           0.910568            0.577737   \n",
       "17           0.950000        0.775000           0.910192            0.574588   \n",
       "18           0.933333        0.780000           0.894042            0.575451   \n",
       "19           0.708958        0.970775           0.883030            0.777719   \n",
       "20           0.924800        0.617445           0.852376            0.791767   \n",
       "21           0.690971        0.783333           0.875408            0.775585   \n",
       "22           0.653896        0.837898           0.882022            0.775137   \n",
       "23           0.865681        0.915524           0.677045            0.846434   \n",
       "24           0.900000        1.000000           0.906164            0.523977   \n",
       "25           0.883333        0.925000           0.916328            0.567948   \n",
       "26           0.903333        1.000000           0.916220            0.603396   \n",
       "27           0.850000        1.000000           0.896140            0.551269   \n",
       "28           0.952744        0.983333           0.962346            0.809304   \n",
       "29           0.955095        0.983333           0.961934            0.809200   \n",
       "30           0.900000        0.719048           0.917804            0.646888   \n",
       "31           0.900000        0.922857           0.914668            0.582662   \n",
       "32           0.838333        0.980000           0.893071            0.537787   \n",
       "33           0.916667        0.980000           0.921807            0.614832   \n",
       "34           0.920000        0.980000           0.917549            0.543527   \n",
       "35           0.883333        0.980000           0.921927            0.593488   \n",
       "\n",
       "     Average  \n",
       "0   0.625387  \n",
       "1   0.550658  \n",
       "2   0.843378  \n",
       "3   0.852548  \n",
       "4   0.837245  \n",
       "5   0.822194  \n",
       "6   0.829081  \n",
       "7   0.809713  \n",
       "8   0.850732  \n",
       "9   0.864549  \n",
       "10  0.849748  \n",
       "11  0.878546  \n",
       "12  0.850321  \n",
       "13  0.880439  \n",
       "14  0.828293  \n",
       "15  0.815600  \n",
       "16  0.841849  \n",
       "17  0.834605  \n",
       "18  0.819586  \n",
       "19  0.832546  \n",
       "20  0.801599  \n",
       "21  0.796358  \n",
       "22  0.799880  \n",
       "23  0.823124  \n",
       "24  0.836670  \n",
       "25  0.822117  \n",
       "26  0.844672  \n",
       "27  0.828847  \n",
       "28  0.860574  \n",
       "29  0.853145  \n",
       "30  0.835366  \n",
       "31  0.841296  \n",
       "32  0.834484  \n",
       "33  0.863634  \n",
       "34  0.824122  \n",
       "35  0.878214  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "passing column names as 'ground_truths' is deprecated and will be removed in the next version, please use 'ground_truth' instead. Note that `ground_truth` should be of type string and not Sequence[string] like `ground_truths`\n",
      "Evaluating: 100%|██████████| 60/60 [00:12<00:00,  4.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average score is: 0.8626577082002025\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>System</th>\n",
       "      <th>Faithfulness</th>\n",
       "      <th>Answer Relevancy</th>\n",
       "      <th>Context Precision</th>\n",
       "      <th>Context Recall</th>\n",
       "      <th>Answer Similarity</th>\n",
       "      <th>Answer Correctness</th>\n",
       "      <th>Average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Chunk 1000, overlap 20%, GPT-4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.711227</td>\n",
       "      <td>0.883333</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.925291</td>\n",
       "      <td>0.676095</td>\n",
       "      <td>0.862658</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           System  Faithfulness  Answer Relevancy  \\\n",
       "0  Chunk 1000, overlap 20%, GPT-4           1.0          0.711227   \n",
       "\n",
       "   Context Precision  Context Recall  Answer Similarity  Answer Correctness  \\\n",
       "0           0.883333            0.98           0.925291            0.676095   \n",
       "\n",
       "    Average  \n",
       "0  0.862658  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_gpt4_1000_20, results_df = run_and_evaluate(f\"Chunk 1000, overlap 20%, GPT-4\", ret, prompt, llm_gpt4, results_df)\n",
    "result_gpt4_1000_20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>System</th>\n",
       "      <th>Faithfulness</th>\n",
       "      <th>Answer Relevancy</th>\n",
       "      <th>Context Precision</th>\n",
       "      <th>Context Recall</th>\n",
       "      <th>Answer Similarity</th>\n",
       "      <th>Answer Correctness</th>\n",
       "      <th>Average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Chunk 1000, overlap 20%</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.889265</td>\n",
       "      <td>0.883333</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.920670</td>\n",
       "      <td>0.609364</td>\n",
       "      <td>0.880439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Chunk 1000, overlap 10%</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.781964</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.922650</td>\n",
       "      <td>0.653329</td>\n",
       "      <td>0.878546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Chunk 1000, overlap 0%</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.797138</td>\n",
       "      <td>0.925000</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.917733</td>\n",
       "      <td>0.622977</td>\n",
       "      <td>0.864549</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     System  Faithfulness  Answer Relevancy  \\\n",
       "13  Chunk 1000, overlap 20%      1.000000          0.889265   \n",
       "11  Chunk 1000, overlap 10%      1.000000          0.781964   \n",
       "9    Chunk 1000, overlap 0%      0.944444          0.797138   \n",
       "\n",
       "    Context Precision  Context Recall  Answer Similarity  Answer Correctness  \\\n",
       "13           0.883333            0.98           0.920670            0.609364   \n",
       "11           0.933333            0.98           0.922650            0.653329   \n",
       "9            0.925000            0.98           0.917733            0.622977   \n",
       "\n",
       "     Average  \n",
       "13  0.880439  \n",
       "11  0.878546  \n",
       "9   0.864549  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_3_highest = results_df.nlargest(3, \"Average\")\n",
    "top_3_highest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "passing column names as 'ground_truths' is deprecated and will be removed in the next version, please use 'ground_truth' instead. Note that `ground_truth` should be of type string and not Sequence[string] like `ground_truths`\n",
      "Evaluating: 100%|██████████| 60/60 [00:09<00:00,  6.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average score is: 0.8810247743091507\n",
      "This is the new best value!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>System</th>\n",
       "      <th>Faithfulness</th>\n",
       "      <th>Answer Relevancy</th>\n",
       "      <th>Context Precision</th>\n",
       "      <th>Context Recall</th>\n",
       "      <th>Answer Similarity</th>\n",
       "      <th>Answer Correctness</th>\n",
       "      <th>Average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Chunk 1000, overlap 0%, GPT-4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.80883</td>\n",
       "      <td>0.925</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.92286</td>\n",
       "      <td>0.649458</td>\n",
       "      <td>0.881025</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          System  Faithfulness  Answer Relevancy  \\\n",
       "0  Chunk 1000, overlap 0%, GPT-4           1.0           0.80883   \n",
       "\n",
       "   Context Precision  Context Recall  Answer Similarity  Answer Correctness  \\\n",
       "0              0.925            0.98            0.92286            0.649458   \n",
       "\n",
       "    Average  \n",
       "0  0.881025  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db_0 = Chroma(persist_directory = \"../news/vectordb-edit/chunking_1000_0\", embedding_function=embeddings_client)\n",
    "ret_0 = db_0.as_retriever()\n",
    "result_search_query_gpt4, results_df = run_and_evaluate(f\"Chunk 1000, overlap 0%, GPT-4\", ret_0, prompt, llm_gpt4, results_df)\n",
    "result_search_query_gpt4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "passing column names as 'ground_truths' is deprecated and will be removed in the next version, please use 'ground_truth' instead. Note that `ground_truth` should be of type string and not Sequence[string] like `ground_truths`\n",
      "Evaluating:  38%|███▊      | 23/60 [00:04<00:05,  6.52it/s]Runner in Executor raised an exception\n",
      "ValueError: Azure has not provided the response due to a content filter being triggered\n",
      "Evaluating: 100%|██████████| 60/60 [00:12<00:00,  4.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average score is: 0.8557522471755882\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>System</th>\n",
       "      <th>Faithfulness</th>\n",
       "      <th>Answer Relevancy</th>\n",
       "      <th>Context Precision</th>\n",
       "      <th>Context Recall</th>\n",
       "      <th>Answer Similarity</th>\n",
       "      <th>Answer Correctness</th>\n",
       "      <th>Average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Chunk 1000, overlap 10%, GPT-4</td>\n",
       "      <td>0.688379</td>\n",
       "      <td>0.805449</td>\n",
       "      <td>0.832043</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.955418</td>\n",
       "      <td>0.853223</td>\n",
       "      <td>0.855752</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           System  Faithfulness  Answer Relevancy  \\\n",
       "0  Chunk 1000, overlap 10%, GPT-4      0.688379          0.805449   \n",
       "\n",
       "   Context Precision  Context Recall  Answer Similarity  Answer Correctness  \\\n",
       "0           0.832043             1.0           0.955418            0.853223   \n",
       "\n",
       "    Average  \n",
       "0  0.855752  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db_10 = Chroma(persist_directory = \"../news/vectordb-edit/chunking_1000_10\", embedding_function=embeddings_client)\n",
    "ret_10 = db_10.as_retriever()\n",
    "result_search_query_gpt4, results_df = run_and_evaluate(f\"Chunk 1000, overlap 10%, GPT-4\", ret_10, prompt, llm_gpt4, results_df)\n",
    "result_search_query_gpt4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.to_csv(f\"../news/results/results_qa_news.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
