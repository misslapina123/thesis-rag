{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import dotenv\n",
    "from langchain.text_splitter import CharacterTextSplitter, RecursiveCharacterTextSplitter\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.document_loaders import DirectoryLoader\n",
    "from langchain_openai import AzureOpenAIEmbeddings\n",
    "dotenv.load_dotenv()\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from ragas import evaluate\n",
    "from ragas.metrics import (\n",
    "    faithfulness,\n",
    "    answer_relevancy,\n",
    "    context_recall,\n",
    "    context_precision,\n",
    "    answer_similarity,\n",
    "    answer_correctness,\n",
    ")\n",
    "from datasets import Dataset\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "from operator import itemgetter\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "import os\n",
    "from langchain.retrievers import BM25Retriever\n",
    "from langchain.retrievers import EnsembleRetriever\n",
    "import getpass\n",
    "from langchain.retrievers.document_compressors import CohereRerank\n",
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "import sys\n",
    "sys.tracebacklimit = 0\n",
    "from langchain.retrievers import ParentDocumentRetriever\n",
    "from langchain.storage import InMemoryStore\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_API_KEY = os.environ.get(\"OPENAI_API_KEY\")\n",
    "OPENAI_API_VERSION = os.environ.get(\"OPENAI_API_VERSION\")\n",
    "AZURE_OPENAI_ENDPOINT = os.environ.get(\"AZURE_OPENAI_ENDPOINT\")\n",
    "OPENAI_MODEL = os.environ.get(\"OPENAI_MODEL\")\n",
    "OPENAI_DEPLOYMENT = os.environ.get(\"OPENAI_DEPLOYMENT\")\n",
    "EMBEDDING_MODEL = os.environ.get(\"EMBEDDING_MODEL\")\n",
    "EMBEDDING_DEPLOYMENT = os.environ.get(\"EMBEDDING_DEPLOYMENT\")\n",
    "OPENAI_MODEL_GPT4 = os.environ.get(\"OPENAI_MODEL_GPT4\")\n",
    "OPENAI_DEPLOYMENT_GPT4 = os.environ.get(\"OPENAI_DEPLOYMENT_GPT4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_client = AzureOpenAIEmbeddings(\n",
    "    azure_deployment=EMBEDDING_DEPLOYMENT,\n",
    "    openai_api_version=OPENAI_API_VERSION)\n",
    "llm = AzureChatOpenAI(model_name=OPENAI_MODEL, azure_deployment=OPENAI_DEPLOYMENT,temperature=0)\n",
    "llm_gpt4 = AzureChatOpenAI(model_name=OPENAI_MODEL_GPT4, azure_deployment=OPENAI_DEPLOYMENT_GPT4,temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation_llm(questions, answers, contexts, ground_truths):\n",
    "    data = {\n",
    "        \"question\": questions,\n",
    "        \"answer\": answers,\n",
    "        \"contexts\": contexts,\n",
    "        \"ground_truths\": ground_truths\n",
    "    }\n",
    "    dataset = Dataset.from_dict(data)\n",
    "    azure_configs = {\n",
    "        \"base_url\": AZURE_OPENAI_ENDPOINT,\n",
    "        \"model_deployment\": OPENAI_DEPLOYMENT,\n",
    "        \"model_name\": OPENAI_MODEL,\n",
    "        \"embedding_deployment\": EMBEDDING_DEPLOYMENT,\n",
    "        \"embedding_name\": EMBEDDING_MODEL,  \n",
    "    }\n",
    "\n",
    "    azure_model = AzureChatOpenAI(\n",
    "        openai_api_version=OPENAI_API_VERSION,\n",
    "        azure_endpoint=azure_configs[\"base_url\"],\n",
    "        azure_deployment=azure_configs[\"model_deployment\"],\n",
    "        model=azure_configs[\"model_name\"],\n",
    "        validate_base_url=False,\n",
    "    )\n",
    "\n",
    "    azure_embeddings = AzureOpenAIEmbeddings(\n",
    "        openai_api_version=OPENAI_API_VERSION,\n",
    "        azure_endpoint=azure_configs[\"base_url\"],\n",
    "        azure_deployment=azure_configs[\"embedding_deployment\"],\n",
    "        model=azure_configs[\"embedding_name\"],\n",
    "    )\n",
    "    result = evaluate(\n",
    "        dataset = dataset, \n",
    "        metrics=[\n",
    "            faithfulness,\n",
    "            answer_relevancy,\n",
    "            answer_similarity,\n",
    "            answer_correctness,\n",
    "        ], \n",
    "        llm=azure_model, \n",
    "        embeddings=azure_embeddings,\n",
    "    )\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation_rag(questions, answers, contexts, ground_truths):\n",
    "    data = {\n",
    "        \"question\": questions,\n",
    "        \"answer\": answers,\n",
    "        \"contexts\": contexts,\n",
    "        \"ground_truths\": ground_truths\n",
    "    }\n",
    "    dataset = Dataset.from_dict(data)\n",
    "    azure_configs = {\n",
    "        \"base_url\": AZURE_OPENAI_ENDPOINT,\n",
    "        \"model_deployment\": OPENAI_DEPLOYMENT,\n",
    "        \"model_name\": OPENAI_MODEL,\n",
    "        \"embedding_deployment\": EMBEDDING_DEPLOYMENT,\n",
    "        \"embedding_name\": EMBEDDING_MODEL,  # most likely\n",
    "    }\n",
    "\n",
    "    azure_model = AzureChatOpenAI(\n",
    "        openai_api_version=OPENAI_API_VERSION,\n",
    "        azure_endpoint=azure_configs[\"base_url\"],\n",
    "        azure_deployment=azure_configs[\"model_deployment\"],\n",
    "        model=azure_configs[\"model_name\"],\n",
    "        validate_base_url=False,\n",
    "    )\n",
    "\n",
    "    azure_embeddings = AzureOpenAIEmbeddings(\n",
    "        openai_api_version=OPENAI_API_VERSION,\n",
    "        azure_endpoint=azure_configs[\"base_url\"],\n",
    "        azure_deployment=azure_configs[\"embedding_deployment\"],\n",
    "        model=azure_configs[\"embedding_name\"],\n",
    "    )\n",
    "    result = evaluate(\n",
    "        dataset = dataset, \n",
    "        metrics=[\n",
    "            faithfulness,\n",
    "            answer_relevancy,\n",
    "            context_precision,\n",
    "            context_recall,\n",
    "            answer_similarity,\n",
    "            answer_correctness,\n",
    "        ], \n",
    "        llm=azure_model, \n",
    "        embeddings=azure_embeddings,\n",
    "        raise_exceptions=False,\n",
    "    )\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = [\n",
    "    \"Analyze the following quote from Dr. Volumnia Gaul from 'Ballad of Songbirds and Snakes': 'There is a point to everything or nothing at all, depending on your worldview.'\",\n",
    "    \"Analyze the following quote from 'Ballad of Songbirds and Snakes': 'He'd loved the unfamiliar sense of safety that their defeat had brought. The security that could only come with power. The ability to control things. Yes, that was what he'd loved best of all.'\",\n",
    "    \"Analyze this quote from 'Ballad of Songbirds and Snakes': 'Snow lands on top.'\",\n",
    "    \"Analyze this quote from 'Ballad of Songbirds and Snakes': '...at eighteen, the heir to the once-great house of Snow had nothing to live on but his wits.'\",\n",
    "    \"Analyze this quote from 'Ballad of Songbirds and Snakes': 'Bombs and blood. That was how the rebels had killed his mother. He wondered if they had killed Lucy Gray's, too. 'Just like her pearly white bones.' She seemed to have no love for District 12, always separating herself from it, saying she was, what was it . . . Covey?'\",\n",
    "    \"Analyze this quote from 'Ballad of Songbirds and Snakes': 'All right, so he'd dropped the handkerchief with Lucy Gray's scent - the one from the outside pocket of his book bag - into the snake tank. He'd done it so they would not bite her as they had Clemensia. So they would not kill her. Because he cared about her. Because he cared about her? Or because he wanted to win the Hunger Games so that he could secure the Plinth Prize. If it was the latter, he had cheated to win, and that was that.'\",\n",
    "    \"Analyze this quote from 'Ballad of Songbirds and Snakes': 'The Hunger Games are an unnatural, vicious punishment. How could a good person like you be expected to go along with them?'\",\n",
    "    \"Analyze this quote from 'Ballad of Songbirds and Snakes': 'If I'm helping to kill people in the districts, how is it any better than helping to kill them in the Hunger Games?'\",\n",
    "    \"Analyze this quote from 'Ballad of Songbirds and Snakes': 'You don't think I've invested all this time in you to hand you off to those imbeciles in the districts, do you?'\"\n",
    "]\n",
    "\n",
    "\n",
    "ground_truths = [\n",
    "    [\"Throughout The Ballad, Dr. Gaul presents Coryo and the other students with items of political philosophy, often in order to explain her own views of power and control. Here, her contrast between a 'point' and 'nothing' plays into a few of her larger ideas. Authoritarian though she is, Dr. Gaul sees the power of the Capitol as serving a useful point in rescuing Panem from chaos. On another level, the situation that provokes this comment - Coryo and Clemensia observing Dr. Gaul's multicolored snakes and wondering if there is a 'point' to the coloration - reveals that the idea of purpose extends well beyond vast political constructs in the novel. Dr. Gaul's rainbow snakes serve a direct point in making the Hunger Games a stark spectacle, and they serve a narrative point in connecting Lucy with one of her symbolic animals in the arena. It is clear what worldview Dr. Gaul would endorse.\"],\n",
    "    [\"Here, Coryo is completing an assignment for Dr. Gaul on the rather twisted topic of what he liked about the war, and he is proving just how compatible Dr. Gaul's authoritarian worldview is with his own. Of course, Coryo's reasons for disliking the Districts are not purely sociopathic. The warfare caused his family real suffering and gave him the impression that, despite his apparent intelligence and his potential for decency, he was, for a time, fundamentally helpless. Still, is it reassuring 'security' or maniacal 'power' that really appeals to Coriolanus? On the basis of the later events of his life, his desire for control and power becomes twisted beyond understandable self-preservation and into open villainy.\"],\n",
    "    [\"This is something of a Snow family motto for Tigris and Coryo: the 'saying that had gotten them through the war' (Ballad, 9), as the two cousins recollect early in the novel. Though loaded with reassurance and a pleasing sense of inevitability, this mantra varies in tone, context, and implication as The Ballad of Songbirds and Snakes progresses. 'Snow lands on top' appears early on, when Tigris is contemplating her family's poverty and Snow is eager to excel as a mentor. These are inspiring words for difficult circumstances, but by the final time the motto appears—in the Epilogue, with Coryo victorious and increasingly vicious—a Snow has in fact landed on top and has succeeded in crushing plenty of other people.\"],\n",
    "    [\"Here, we are told that Snow is only eighteen, and we are led to contemplate the differences between the wealthy dictator of the later Hunger Games trilogy and the earnest young Coryo we see here. His kindly mother and his domineering father are dead, and he doesn't have their fortune—or any fortune—to benefit him, since his family's resources were lost in the rebellion with the presumed destruction of District 13. Now, Snow must use his wits and cunning to escape his situation. Thus, the book sets up Coryo's need to restore his family's name as one of the character's central motivations. Readers of the final trilogy may know the end result of Snow's life, but the task of connecting this impoverished young man to the well-heeled, sociopathic President Snow offers plenty of intrigue.\"],\n",
    "    [\"Is the bond between Snow and Lucy mainly based on self-interest or on genuine affection? While a romance between an aristocrat from the Capitol and a wandering musician may seem to have a shaky foundation, Snow's early reflections indicate that he feels some sympathy for Lucy. Their shared experience of the war is one of loneliness and displacement. Still, as Snow's need to excel takes precedence, his connection to Lucy becomes more complicated. The idea that Lucy has 'no love for District 12,' for instance, will later be deployed by Snow in discussions and interviews meant to appeal to Capitol sponsors. Of course, construing Lucy as non-District may help her popularity and her odds of winning, but it is impossible to separate Snow's bond with Lucy from his own determination to improve his life.\"],\n",
    "    [\"The narration of The Ballad is by no means indirect about the moral dilemmas that Coryo encounters. Here, the narrative explicitly raises the question of whether he desires Lucy's safety or a personal win more, underscoring this theme with sentences that are identical but for a single unit of punctuation: 'Because he cared about her. Because he cared about her?' At this point in the novel, it is possible to read a single action as doubled-sided and Coryo's confusion as genuine. By the end, however, he will decisively choose his future over Lucy, reaching a level of self-interest that he doesn't definitively attain in this scene.\"],\n",
    "    [\"There are a few Capitol citizens who object to the Hunger Games in a principled manner, though not all of them speak out as sharply as Sejanus Plinth does. Among the mentors, Lysistrata Vickers seems to harbor real compassion for her tribute, and Coriolanus himself is troubled - at least for a time - by the fact that he kills a tribute while escaping the arena. Tigris's own objections are, from one perspective, surprising. Though related to a Capitol loyalist (her grandmother) and a future authoritarian (her cousin), she finds the games miserable and believes that Coryo does the same. Her judgment of Coriolanus may be flawed and her idea may not quite fit her family's sympathies.\"],\n",
    "    [\"In part, Sejanus's decision to become a Peacekeeper was meant to remove him from a Capitol milieu that he never found appealing. Nonetheless, this quotation reveals that Sejanus is in an impossible position. If becoming a Peacekeeper - ideally, a Peacekeeper doctor or medic - was meant as a form of escape and a route to atonement, then Sejanus's new approach has led him down the wrong path. He is forced to help an institution that executes rebels without trial and that, for the most part, is willing to let the Districts remain in disrepair - beyond providing the Capitol with resources, that is.\"],\n",
    "    [\"Here, Dr. Gaul reveals that, in her own supremely self-interested way, she holds Coriolanus in high regard. He is a fantastic investment, and his time in District 12 has proven that he can thrive even in conditions of deprivation and uncertainty despite his Capitol pedigree. Dr. Gaul's own Capitol elitism is on display in her reference to the 'imbeciles' from the Districts. How much, however, did Coryo really learn from his time in the Districts? His stint as a Peacemaker is construed as a necessary toughening in The Ballad, but the events of the later Hunger Games trilogy suggest that Coriolanus comes to underestimate those District 'imbeciles' at his own peril.\"]\n",
    "   ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\"System\", \"Faithfulness\", \"Answer Relevancy\", \"Context Precision\", \"Context Recall\", \"Answer Similarity\", \"Answer Correctness\"]\n",
    "results_df = pd.DataFrame(columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_average = 0\n",
    "def find_highest(average_score):\n",
    "    global max_average\n",
    "    if average_score > max_average:\n",
    "        max_average = average_score\n",
    "        print(\"This is the new best value!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dictionary(result):\n",
    "    dict_result = dict(result)\n",
    "    average_score = sum(dict_result.values()) / len(dict_result)\n",
    "    print(f\"The average score is: {average_score}\")\n",
    "    find_highest(average_score)\n",
    "    return average_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_system(system_name, questions, answers, contexts, ground_truths):\n",
    "    result = evaluation_rag(questions, answers, contexts, ground_truths)\n",
    "    average = dictionary(result)\n",
    "    # Create a dictionary to store the results\n",
    "    system_results = {\n",
    "        \"System\": system_name,\n",
    "        \"Faithfulness\": result[\"faithfulness\"],\n",
    "        \"Answer Relevancy\": result[\"answer_relevancy\"],\n",
    "        \"Context Precision\": result[\"context_precision\"],\n",
    "        \"Context Recall\": result[\"context_recall\"],\n",
    "        \"Answer Similarity\": result[\"answer_similarity\"],\n",
    "        \"Answer Correctness\": result[\"answer_correctness\"],\n",
    "        \"Average\": average\n",
    "    }\n",
    "    df_system_results = pd.DataFrame([system_results])\n",
    "    return df_system_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_LLM(system_name, questions, answers, contexts, ground_truths):\n",
    "    result = evaluation_llm(questions, answers, contexts, ground_truths)\n",
    "    average = dictionary(result)\n",
    "    # Create a dictionary to store the results\n",
    "    system_results = {\n",
    "        \"System\": system_name,\n",
    "        \"Faithfulness\": result[\"faithfulness\"],\n",
    "        \"Answer Relevancy\": result[\"answer_relevancy\"],\n",
    "        \"Context Precision\": np.nan,\n",
    "        \"Context Recall\": np.nan,\n",
    "        \"Answer Similarity\": result[\"answer_similarity\"],\n",
    "        \"Answer Correctness\": result[\"answer_correctness\"],\n",
    "        \"Average\": average\n",
    "    }\n",
    "    df_llm_results = pd.DataFrame([system_results])\n",
    "    return df_llm_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General answer by LLMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"{question}\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_chain =(\n",
    "    { \"question\": itemgetter(\"question\")}\n",
    "    | RunnablePassthrough()\n",
    "    | {\"response\": prompt | llm}\n",
    ")\n",
    "llm_chain_gpt4 =(\n",
    "    { \"question\": itemgetter(\"question\")}\n",
    "    | RunnablePassthrough()\n",
    "    | {\"response\": prompt | llm_gpt4}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "answers_llm = []\n",
    "contexts_llm = [[\"\"],[\"\"],[\"\"],[\"\"],[\"\"],[\"\"],[\"\"],[\"\"],[\"\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for query in questions:\n",
    "    response = llm_chain.invoke({\"question\": query})\n",
    "    answers_llm.append(response[\"response\"].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "passing column names as 'ground_truths' is deprecated and will be removed in the next version, please use 'ground_truth' instead. Note that `ground_truth` should be of type string and not Sequence[string] like `ground_truths`\n",
      "Evaluating:  56%|█████▌    | 20/36 [00:03<00:01,  9.56it/s]Invalid JSON response. Expected dictionary with key 'question'\n",
      "Evaluating: 100%|██████████| 36/36 [00:06<00:00,  5.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average score is: 0.810784095434097\n",
      "    System  Faithfulness  Answer Relevancy  Context Precision  Context Recall  \\\n",
      "0  GPT-3.5      0.971429          0.745413                NaN             NaN   \n",
      "\n",
      "   Answer Similarity  Answer Correctness   Average  \n",
      "0           0.866096            0.660199  0.810784  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sigitalapina\\AppData\\Local\\Temp\\ipykernel_18920\\800954320.py:2: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  results_df = pd.concat([results_df, llm_results], ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "llm_results = evaluate_LLM(\"GPT-3.5\", questions, answers_llm, contexts_llm, ground_truths)\n",
    "results_df = pd.concat([results_df, llm_results], ignore_index=True)\n",
    "print(llm_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "passing column names as 'ground_truths' is deprecated and will be removed in the next version, please use 'ground_truth' instead. Note that `ground_truth` should be of type string and not Sequence[string] like `ground_truths`\n",
      "Evaluating: 100%|██████████| 36/36 [00:06<00:00,  5.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average score is: 0.8307891316627263\n",
      "  System  Faithfulness  Answer Relevancy  Context Precision  Context Recall  \\\n",
      "0  GPT-4           1.0          0.783206                NaN             NaN   \n",
      "\n",
      "   Answer Similarity  Answer Correctness   Average  \n",
      "0           0.861252            0.678698  0.830789  \n"
     ]
    }
   ],
   "source": [
    "answers_llm_gpt4 = []\n",
    "for query in questions:\n",
    "    response = llm_chain_gpt4.invoke({\"question\": query})\n",
    "    answers_llm_gpt4.append(response[\"response\"].content)\n",
    "llm_results_gpt4 = evaluate_LLM(\"GPT-4\",questions, answers_llm_gpt4, contexts_llm, ground_truths)\n",
    "results_df = pd.concat([results_df, llm_results_gpt4], ignore_index=True)\n",
    "print(llm_results_gpt4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieval_chain(prompt, retriever, llm):\n",
    "    retrieval_augmented_qa_chain = (\n",
    "        {\"context\": itemgetter(\"question\") | retriever, \"question\": itemgetter(\"question\")}\n",
    "        | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
    "        | {\"response\": prompt | llm, \"context\": itemgetter(\"context\")}\n",
    "    )\n",
    "    return retrieval_augmented_qa_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = PyPDFLoader(r\"..\\ballad\\the_ballad_of_songbirds_and_snakes.pdf\")\n",
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THE FIRST TIME RUN THIS, AFTER RUN THE NEXT CELL\n",
    "text_splitter = CharacterTextSplitter()\n",
    "chunks = text_splitter.split_documents(documents)\n",
    "db_naive = Chroma.from_documents(chunks, embeddings_client, persist_directory = \"../ballad/vectordb/naive\")\n",
    "db_naive.persist()\n",
    "retriever_naive = db_naive.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_naive = Chroma(persist_directory = \"../ballad/vectordb-edit/naive\", embedding_function=embeddings_client)\n",
    "retriever_naive = db_naive.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"User input {question}. \n",
    "Context {context}.\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400, 'innererror': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_result': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'low'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': True, 'severity': 'medium'}}}}}on the following question: Analyze this quote from 'Ballad of Songbirds and Snakes': 'All right, so he'd dropped the handkerchief with Lucy Gray's scent - the one from the outside pocket of his book bag - into the snake tank. He'd done it so they would not bite her as they had Clemensia. So they would not kill her. Because he cared about her. Because he cared about her? Or because he wanted to win the Hunger Games so that he could secure the Plinth Prize. If it was the latter, he had cheated to win, and that was that.'\n"
     ]
    }
   ],
   "source": [
    "answers_naive = []\n",
    "contexts_naive = []\n",
    "for query in questions:\n",
    "    try:  \n",
    "        response = retrieval_chain(prompt, retriever_naive, llm).invoke({\"question\": query})\n",
    "        # Access the response content\n",
    "        answers_naive.append(response[\"response\"].content)\n",
    "        # Access the context content\n",
    "        context_content = [context.page_content for context in response[\"context\"]]\n",
    "        contexts_naive.append(context_content)  \n",
    "    except Exception as e:  \n",
    "        print(f\"Warning: {e}\" + \"on the following question: \" + query)  \n",
    "        answers_naive.append(\"No answer\")\n",
    "        context_full = retriever_naive.get_relevant_documents(query)\n",
    "        context_content = [context.page_content for context in context_full]\n",
    "        contexts_naive.append(context_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "passing column names as 'ground_truths' is deprecated and will be removed in the next version, please use 'ground_truth' instead. Note that `ground_truth` should be of type string and not Sequence[string] like `ground_truths`\n",
      "Evaluating:   0%|          | 0/54 [00:00<?, ?it/s]Runner in Executor raised an exception\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400, 'innererror': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_result': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': True, 'severity': 'medium'}}}}}\n",
      "Evaluating:  20%|██        | 11/54 [00:03<00:11,  3.81it/s]Runner in Executor raised an exception\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400, 'innererror': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_result': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': True, 'severity': 'medium'}}}}}\n",
      "Evaluating: 100%|██████████| 54/54 [00:07<00:00,  6.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average score is: 0.7021937943559574\n",
      "  System  Faithfulness  Answer Relevancy  Context Precision  Context Recall  \\\n",
      "0  Naive      0.881621          0.726491             0.5125        0.693275   \n",
      "\n",
      "   Answer Similarity  Answer Correctness   Average  \n",
      "0           0.683565             0.71571  0.702194  \n"
     ]
    }
   ],
   "source": [
    "result_naive_rag = evaluate_system(\"Naive\", questions, answers_naive, contexts_naive, ground_truths)\n",
    "results_df = pd.concat([results_df, result_naive_rag], ignore_index=True)\n",
    "print(result_naive_rag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### recursive splitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THE FIRST TIME RUN THIS, AFTER RUN THE NEXT CELL\n",
    "text_splitter = text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder()\n",
    "chunks_r = text_splitter.split_documents(documents)\n",
    "db_basic = Chroma.from_documents(chunks_r, embeddings_client, persist_directory = \"../ballad/vectordb/recursive_basic\")\n",
    "db_basic.persist()\n",
    "retriever_basic = db_basic.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_basic = Chroma(persist_directory = \"../ballad/vectordb/recursive_basic\", embedding_function=embeddings_client)\n",
    "retriever_basic = db_basic.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400, 'innererror': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_result': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'low'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': True, 'severity': 'medium'}}}}}on the following question: Analyze this quote from 'Ballad of Songbirds and Snakes': 'All right, so he'd dropped the handkerchief with Lucy Gray's scent - the one from the outside pocket of his book bag - into the snake tank. He'd done it so they would not bite her as they had Clemensia. So they would not kill her. Because he cared about her. Because he cared about her? Or because he wanted to win the Hunger Games so that he could secure the Plinth Prize. If it was the latter, he had cheated to win, and that was that.'\n"
     ]
    }
   ],
   "source": [
    "answers_recursive = []\n",
    "contexts_recursive = []\n",
    "for query in questions:\n",
    "    try:  \n",
    "        response = retrieval_chain(prompt, retriever_basic, llm).invoke({\"question\": query})\n",
    "        # Access the response content\n",
    "        answers_recursive.append(response[\"response\"].content)\n",
    "        # Access the context content\n",
    "        context_content = [context.page_content for context in response[\"context\"]]\n",
    "        contexts_recursive.append(context_content)  \n",
    "    except Exception as e:  \n",
    "        print(f\"Warning: {e}\" + \"on the following question: \" + query)  \n",
    "        answers_recursive.append(\"No answer\")\n",
    "        context_full = retriever_basic.get_relevant_documents(query)\n",
    "        context_content = [context.page_content for context in context_full]\n",
    "        contexts_recursive.append(context_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "passing column names as 'ground_truths' is deprecated and will be removed in the next version, please use 'ground_truth' instead. Note that `ground_truth` should be of type string and not Sequence[string] like `ground_truths`\n",
      "Evaluating:   0%|          | 0/54 [00:00<?, ?it/s]Task exception was never retrieved\n",
      "future: <Task finished name='Task-164' coro=<AsyncClient.aclose() done, defined at c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\httpx\\_client.py:2011> exception=RuntimeError('Event loop is closed')>\n",
      "RuntimeError: Event loop is closed\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-165' coro=<AsyncClient.aclose() done, defined at c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\httpx\\_client.py:2011> exception=RuntimeError('Event loop is closed')>\n",
      "RuntimeError: Event loop is closed\n",
      "Runner in Executor raised an exception\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400, 'innererror': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_result': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': True, 'severity': 'medium'}}}}}\n",
      "Evaluating:  20%|██        | 11/54 [00:03<00:11,  3.90it/s]Runner in Executor raised an exception\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400, 'innererror': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_result': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': True, 'severity': 'medium'}}}}}\n",
      "Evaluating: 100%|██████████| 54/54 [00:07<00:00,  6.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average score is: 0.7157690662921116\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>System</th>\n",
       "      <th>Faithfulness</th>\n",
       "      <th>Answer Relevancy</th>\n",
       "      <th>Context Precision</th>\n",
       "      <th>Context Recall</th>\n",
       "      <th>Answer Similarity</th>\n",
       "      <th>Answer Correctness</th>\n",
       "      <th>Average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Recursive</td>\n",
       "      <td>0.865996</td>\n",
       "      <td>0.729346</td>\n",
       "      <td>0.5125</td>\n",
       "      <td>0.580707</td>\n",
       "      <td>0.816281</td>\n",
       "      <td>0.789784</td>\n",
       "      <td>0.715769</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      System  Faithfulness  Answer Relevancy  Context Precision  \\\n",
       "0  Recursive      0.865996          0.729346             0.5125   \n",
       "\n",
       "   Context Recall  Answer Similarity  Answer Correctness   Average  \n",
       "0        0.580707           0.816281            0.789784  0.715769  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_recursive = evaluate_system(\"Recursive\", questions, answers_naive, contexts_naive, ground_truths)\n",
    "results_df = pd.concat([results_df, result_recursive], ignore_index=True)\n",
    "result_recursive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### chunk sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_and_evaluate(name, retriever, prompt, llm, results_df):\n",
    "    answers = []\n",
    "    contexts_extra = []\n",
    "\n",
    "    for query in questions:\n",
    "        try:  \n",
    "            response = retrieval_chain(prompt, retriever, llm).invoke({\"question\": query})\n",
    "            # Access the response content\n",
    "            answers.append(response[\"response\"].content)\n",
    "            # Access the context content\n",
    "            context_content = [context.page_content for context in response[\"context\"]]\n",
    "            contexts_extra.append(context_content)  \n",
    "        except Exception as e:  \n",
    "            print(f\"Warning: {e}\" + \"on the following question: \" + query)  \n",
    "            answers.append(\"No answer\")\n",
    "            context_full = retriever.get_relevant_documents(query)\n",
    "            context_content = [context.page_content for context in context_full]\n",
    "            contexts_extra.append(context_content)\n",
    "\n",
    "    result = evaluate_system(name, questions, answers, contexts_extra, ground_truths)\n",
    "    results_df = pd.concat([results_df, result], ignore_index=True)\n",
    "    return result, results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of chunks for chunk size 500, overlap 0%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "passing column names as 'ground_truths' is deprecated and will be removed in the next version, please use 'ground_truth' instead. Note that `ground_truth` should be of type string and not Sequence[string] like `ground_truths`\n",
      "Evaluating: 100%|██████████| 54/54 [00:07<00:00,  7.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average score is: 0.6824418951653323\n",
      "CHUNK SIZE 500, 0% overlap:\n",
      "                  System  Faithfulness  Answer Relevancy  Context Precision  \\\n",
      "0  Chunk 500, overlap 0%      0.866667           0.88476           0.376543   \n",
      "\n",
      "   Context Recall  Answer Similarity  Answer Correctness   Average  \n",
      "0        0.435185           0.866883            0.664614  0.682442  \n",
      "Number of chunks for chunk size 500, overlap 5%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "passing column names as 'ground_truths' is deprecated and will be removed in the next version, please use 'ground_truth' instead. Note that `ground_truth` should be of type string and not Sequence[string] like `ground_truths`\n",
      "Evaluating: 100%|██████████| 54/54 [00:07<00:00,  7.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average score is: 0.7011332254990136\n",
      "CHUNK SIZE 500, 5% overlap:\n",
      "                  System  Faithfulness  Answer Relevancy  Context Precision  \\\n",
      "0  Chunk 500, overlap 5%      0.680952          0.901854           0.441358   \n",
      "\n",
      "   Context Recall  Answer Similarity  Answer Correctness   Average  \n",
      "0        0.666667           0.863189             0.65278  0.701133  \n",
      "Number of chunks for chunk size 500, overlap 10%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "passing column names as 'ground_truths' is deprecated and will be removed in the next version, please use 'ground_truth' instead. Note that `ground_truth` should be of type string and not Sequence[string] like `ground_truths`\n",
      "Evaluating: 100%|██████████| 54/54 [00:07<00:00,  6.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average score is: 0.7091465704405379\n",
      "CHUNK SIZE 500, 10% overlap:\n",
      "                   System  Faithfulness  Answer Relevancy  Context Precision  \\\n",
      "0  Chunk 500, overlap 10%           0.8          0.885184           0.450617   \n",
      "\n",
      "   Context Recall  Answer Similarity  Answer Correctness   Average  \n",
      "0        0.592593           0.863726             0.66276  0.709147  \n",
      "Number of chunks for chunk size 500, overlap 15%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "passing column names as 'ground_truths' is deprecated and will be removed in the next version, please use 'ground_truth' instead. Note that `ground_truth` should be of type string and not Sequence[string] like `ground_truths`\n",
      "Evaluating: 100%|██████████| 54/54 [00:06<00:00,  8.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average score is: 0.7791517963321956\n",
      "CHUNK SIZE 500, 15% overlap:\n",
      "                   System  Faithfulness  Answer Relevancy  Context Precision  \\\n",
      "0  Chunk 500, overlap 15%       0.82619          0.879043           0.645062   \n",
      "\n",
      "   Context Recall  Answer Similarity  Answer Correctness   Average  \n",
      "0        0.824074           0.869306            0.631235  0.779152  \n",
      "Number of chunks for chunk size 500, overlap 20%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "passing column names as 'ground_truths' is deprecated and will be removed in the next version, please use 'ground_truth' instead. Note that `ground_truth` should be of type string and not Sequence[string] like `ground_truths`\n",
      "Evaluating: 100%|██████████| 54/54 [00:07<00:00,  7.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average score is: 0.709873706222197\n",
      "CHUNK SIZE 500, 20% overlap:\n",
      "                   System  Faithfulness  Answer Relevancy  Context Precision  \\\n",
      "0  Chunk 500, overlap 20%      0.714286          0.903706           0.506173   \n",
      "\n",
      "   Context Recall  Answer Similarity  Answer Correctness   Average  \n",
      "0        0.675926           0.872395            0.586756  0.709874  \n",
      "Number of chunks for chunk size 1000, overlap 0%\n",
      "Warning: Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400, 'innererror': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_result': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': True, 'severity': 'medium'}}}}}on the following question: Analyze this quote from 'Ballad of Songbirds and Snakes': 'All right, so he'd dropped the handkerchief with Lucy Gray's scent - the one from the outside pocket of his book bag - into the snake tank. He'd done it so they would not bite her as they had Clemensia. So they would not kill her. Because he cared about her. Because he cared about her? Or because he wanted to win the Hunger Games so that he could secure the Plinth Prize. If it was the latter, he had cheated to win, and that was that.'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "passing column names as 'ground_truths' is deprecated and will be removed in the next version, please use 'ground_truth' instead. Note that `ground_truth` should be of type string and not Sequence[string] like `ground_truths`\n",
      "Evaluating:   0%|          | 0/54 [00:00<?, ?it/s]Runner in Executor raised an exception\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400, 'innererror': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_result': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': True, 'severity': 'medium'}}}}}\n",
      "Evaluating:  20%|██        | 11/54 [00:03<00:11,  3.71it/s]Runner in Executor raised an exception\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400, 'innererror': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_result': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': True, 'severity': 'medium'}}}}}\n",
      "Evaluating: 100%|██████████| 54/54 [00:07<00:00,  7.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average score is: 0.7142748275123901\n",
      "CHUNK SIZE 1000, 0% overlap:\n",
      "                   System  Faithfulness  Answer Relevancy  Context Precision  \\\n",
      "0  Chunk 1000, overlap 0%      0.834282          0.723396             0.4875   \n",
      "\n",
      "   Context Recall  Answer Similarity  Answer Correctness   Average  \n",
      "0        0.689591           0.780951            0.769929  0.714275  \n",
      "Number of chunks for chunk size 1000, overlap 5%\n",
      "Warning: Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400, 'innererror': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_result': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'low'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': True, 'severity': 'medium'}}}}}on the following question: Analyze this quote from 'Ballad of Songbirds and Snakes': 'All right, so he'd dropped the handkerchief with Lucy Gray's scent - the one from the outside pocket of his book bag - into the snake tank. He'd done it so they would not bite her as they had Clemensia. So they would not kill her. Because he cared about her. Because he cared about her? Or because he wanted to win the Hunger Games so that he could secure the Plinth Prize. If it was the latter, he had cheated to win, and that was that.'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "passing column names as 'ground_truths' is deprecated and will be removed in the next version, please use 'ground_truth' instead. Note that `ground_truth` should be of type string and not Sequence[string] like `ground_truths`\n",
      "Evaluating:   0%|          | 0/54 [00:00<?, ?it/s]Runner in Executor raised an exception\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400, 'innererror': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_result': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': True, 'severity': 'medium'}}}}}\n",
      "Evaluating:  20%|██        | 11/54 [00:03<00:10,  4.27it/s]Runner in Executor raised an exception\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400, 'innererror': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_result': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': True, 'severity': 'medium'}}}}}\n",
      "Evaluating: 100%|██████████| 54/54 [00:06<00:00,  8.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average score is: 0.6929915529118457\n",
      "CHUNK SIZE 1000, 5% overlap:\n",
      "                   System  Faithfulness  Answer Relevancy  Context Precision  \\\n",
      "0  Chunk 1000, overlap 5%      0.859269          0.710329           0.520833   \n",
      "\n",
      "   Context Recall  Answer Similarity  Answer Correctness   Average  \n",
      "0        0.567662            0.78902            0.710835  0.692992  \n",
      "Number of chunks for chunk size 1000, overlap 10%\n",
      "Warning: Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400, 'innererror': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_result': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'low'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': True, 'severity': 'medium'}}}}}on the following question: Analyze this quote from 'Ballad of Songbirds and Snakes': 'All right, so he'd dropped the handkerchief with Lucy Gray's scent - the one from the outside pocket of his book bag - into the snake tank. He'd done it so they would not bite her as they had Clemensia. So they would not kill her. Because he cared about her. Because he cared about her? Or because he wanted to win the Hunger Games so that he could secure the Plinth Prize. If it was the latter, he had cheated to win, and that was that.'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "passing column names as 'ground_truths' is deprecated and will be removed in the next version, please use 'ground_truth' instead. Note that `ground_truth` should be of type string and not Sequence[string] like `ground_truths`\n",
      "Evaluating:   0%|          | 0/54 [00:00<?, ?it/s]Runner in Executor raised an exception\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400, 'innererror': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_result': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': True, 'severity': 'medium'}}}}}\n",
      "Evaluating:  24%|██▍       | 13/54 [00:03<00:09,  4.25it/s]Runner in Executor raised an exception\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400, 'innererror': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_result': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': True, 'severity': 'medium'}}}}}\n",
      "Evaluating: 100%|██████████| 54/54 [00:06<00:00,  7.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average score is: 0.6843498324662227\n",
      "CHUNK SIZE 1000, 10% overlap:\n",
      "                    System  Faithfulness  Answer Relevancy  Context Precision  \\\n",
      "0  Chunk 1000, overlap 10%      0.833369          0.724186           0.472222   \n",
      "\n",
      "   Context Recall  Answer Similarity  Answer Correctness  Average  \n",
      "0        0.635688           0.677939            0.762695  0.68435  \n",
      "Number of chunks for chunk size 1000, overlap 15%\n",
      "Warning: Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400, 'innererror': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_result': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'low'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': True, 'severity': 'medium'}}}}}on the following question: Analyze this quote from 'Ballad of Songbirds and Snakes': 'All right, so he'd dropped the handkerchief with Lucy Gray's scent - the one from the outside pocket of his book bag - into the snake tank. He'd done it so they would not bite her as they had Clemensia. So they would not kill her. Because he cared about her. Because he cared about her? Or because he wanted to win the Hunger Games so that he could secure the Plinth Prize. If it was the latter, he had cheated to win, and that was that.'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "passing column names as 'ground_truths' is deprecated and will be removed in the next version, please use 'ground_truth' instead. Note that `ground_truth` should be of type string and not Sequence[string] like `ground_truths`\n",
      "Evaluating:   0%|          | 0/54 [00:00<?, ?it/s]Runner in Executor raised an exception\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400, 'innererror': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_result': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': True, 'severity': 'medium'}}}}}\n",
      "Evaluating:  20%|██        | 11/54 [00:03<00:10,  4.13it/s]Runner in Executor raised an exception\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400, 'innererror': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_result': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': True, 'severity': 'medium'}}}}}\n",
      "Evaluating: 100%|██████████| 54/54 [00:07<00:00,  7.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average score is: 0.6877679727146745\n",
      "CHUNK SIZE 1000, 15% overlap:\n",
      "                    System  Faithfulness  Answer Relevancy  Context Precision  \\\n",
      "0  Chunk 1000, overlap 15%      0.809964          0.719308           0.519048   \n",
      "\n",
      "   Context Recall  Answer Similarity  Answer Correctness   Average  \n",
      "0        0.558069           0.735682            0.784538  0.687768  \n",
      "Number of chunks for chunk size 1000, overlap 20%\n",
      "Warning: Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400, 'innererror': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_result': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'low'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': True, 'severity': 'medium'}}}}}on the following question: Analyze this quote from 'Ballad of Songbirds and Snakes': 'All right, so he'd dropped the handkerchief with Lucy Gray's scent - the one from the outside pocket of his book bag - into the snake tank. He'd done it so they would not bite her as they had Clemensia. So they would not kill her. Because he cared about her. Because he cared about her? Or because he wanted to win the Hunger Games so that he could secure the Plinth Prize. If it was the latter, he had cheated to win, and that was that.'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "passing column names as 'ground_truths' is deprecated and will be removed in the next version, please use 'ground_truth' instead. Note that `ground_truth` should be of type string and not Sequence[string] like `ground_truths`\n",
      "Evaluating:   0%|          | 0/54 [00:00<?, ?it/s]Runner in Executor raised an exception\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400, 'innererror': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_result': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': True, 'severity': 'medium'}}}}}\n",
      "Evaluating:   4%|▎         | 2/54 [00:01<00:43,  1.20it/s]Runner in Executor raised an exception\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400, 'innererror': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_result': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': True, 'severity': 'medium'}}}}}\n",
      "Evaluating: 100%|██████████| 54/54 [00:06<00:00,  8.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average score is: 0.6682921671909154\n",
      "CHUNK SIZE 1000, 20% overlap:\n",
      "                    System  Faithfulness  Answer Relevancy  Context Precision  \\\n",
      "0  Chunk 1000, overlap 20%      0.808816          0.718937           0.380952   \n",
      "\n",
      "   Context Recall  Answer Similarity  Answer Correctness   Average  \n",
      "0        0.538053           0.763482            0.799512  0.668292  \n",
      "Number of chunks for chunk size 2000, overlap 0%\n",
      "Warning: Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400, 'innererror': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_result': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'low'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': True, 'severity': 'medium'}}}}}on the following question: Analyze this quote from 'Ballad of Songbirds and Snakes': 'All right, so he'd dropped the handkerchief with Lucy Gray's scent - the one from the outside pocket of his book bag - into the snake tank. He'd done it so they would not bite her as they had Clemensia. So they would not kill her. Because he cared about her. Because he cared about her? Or because he wanted to win the Hunger Games so that he could secure the Plinth Prize. If it was the latter, he had cheated to win, and that was that.'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "passing column names as 'ground_truths' is deprecated and will be removed in the next version, please use 'ground_truth' instead. Note that `ground_truth` should be of type string and not Sequence[string] like `ground_truths`\n",
      "Evaluating:   0%|          | 0/54 [00:00<?, ?it/s]Runner in Executor raised an exception\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400, 'innererror': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_result': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': True, 'severity': 'medium'}}}}}\n",
      "Evaluating:  20%|██        | 11/54 [00:03<00:11,  3.67it/s]Runner in Executor raised an exception\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400, 'innererror': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_result': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': True, 'severity': 'medium'}}}}}\n",
      "Evaluating: 100%|██████████| 54/54 [00:08<00:00,  6.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average score is: 0.6527207248465835\n",
      "CHUNK SIZE 2000, 0% overlap:\n",
      "                   System  Faithfulness  Answer Relevancy  Context Precision  \\\n",
      "0  Chunk 2000, overlap 0%      0.788936          0.747135           0.470833   \n",
      "\n",
      "   Context Recall  Answer Similarity  Answer Correctness   Average  \n",
      "0        0.693106            0.66052            0.555794  0.652721  \n",
      "Number of chunks for chunk size 2000, overlap 5%\n",
      "Warning: Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400, 'innererror': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_result': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'low'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': True, 'severity': 'medium'}}}}}on the following question: Analyze this quote from 'Ballad of Songbirds and Snakes': 'All right, so he'd dropped the handkerchief with Lucy Gray's scent - the one from the outside pocket of his book bag - into the snake tank. He'd done it so they would not bite her as they had Clemensia. So they would not kill her. Because he cared about her. Because he cared about her? Or because he wanted to win the Hunger Games so that he could secure the Plinth Prize. If it was the latter, he had cheated to win, and that was that.'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "passing column names as 'ground_truths' is deprecated and will be removed in the next version, please use 'ground_truth' instead. Note that `ground_truth` should be of type string and not Sequence[string] like `ground_truths`\n",
      "Evaluating:   0%|          | 0/54 [00:00<?, ?it/s]Runner in Executor raised an exception\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400, 'innererror': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_result': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': True, 'severity': 'medium'}}}}}\n",
      "Evaluating:  28%|██▊       | 15/54 [00:03<00:08,  4.67it/s]Runner in Executor raised an exception\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400, 'innererror': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_result': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': True, 'severity': 'medium'}}}}}\n",
      "Evaluating: 100%|██████████| 54/54 [00:07<00:00,  7.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average score is: 0.6827169705822705\n",
      "CHUNK SIZE 2000, 5% overlap:\n",
      "                   System  Faithfulness  Answer Relevancy  Context Precision  \\\n",
      "0  Chunk 2000, overlap 5%        0.8193          0.724491           0.537037   \n",
      "\n",
      "   Context Recall  Answer Similarity  Answer Correctness   Average  \n",
      "0        0.653868           0.765334            0.596272  0.682717  \n",
      "Number of chunks for chunk size 2000, overlap 10%\n",
      "Warning: Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400, 'innererror': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_result': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': True, 'severity': 'medium'}}}}}on the following question: Analyze this quote from 'Ballad of Songbirds and Snakes': 'All right, so he'd dropped the handkerchief with Lucy Gray's scent - the one from the outside pocket of his book bag - into the snake tank. He'd done it so they would not bite her as they had Clemensia. So they would not kill her. Because he cared about her. Because he cared about her? Or because he wanted to win the Hunger Games so that he could secure the Plinth Prize. If it was the latter, he had cheated to win, and that was that.'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "passing column names as 'ground_truths' is deprecated and will be removed in the next version, please use 'ground_truth' instead. Note that `ground_truth` should be of type string and not Sequence[string] like `ground_truths`\n",
      "Evaluating:   0%|          | 0/54 [00:00<?, ?it/s]Runner in Executor raised an exception\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400, 'innererror': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_result': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': True, 'severity': 'medium'}}}}}\n",
      "Evaluating:  20%|██        | 11/54 [00:03<00:10,  4.18it/s]Runner in Executor raised an exception\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400, 'innererror': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_result': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': True, 'severity': 'medium'}}}}}\n",
      "Evaluating: 100%|██████████| 54/54 [00:07<00:00,  7.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average score is: 0.6891334308860277\n",
      "CHUNK SIZE 2000, 10% overlap:\n",
      "                    System  Faithfulness  Answer Relevancy  Context Precision  \\\n",
      "0  Chunk 2000, overlap 10%      0.894395          0.730272           0.470833   \n",
      "\n",
      "   Context Recall  Answer Similarity  Answer Correctness   Average  \n",
      "0        0.560752           0.678642            0.799907  0.689133  \n",
      "Number of chunks for chunk size 2000, overlap 15%\n",
      "Warning: Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400, 'innererror': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_result': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'low'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': True, 'severity': 'medium'}}}}}on the following question: Analyze this quote from 'Ballad of Songbirds and Snakes': 'All right, so he'd dropped the handkerchief with Lucy Gray's scent - the one from the outside pocket of his book bag - into the snake tank. He'd done it so they would not bite her as they had Clemensia. So they would not kill her. Because he cared about her. Because he cared about her? Or because he wanted to win the Hunger Games so that he could secure the Plinth Prize. If it was the latter, he had cheated to win, and that was that.'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "passing column names as 'ground_truths' is deprecated and will be removed in the next version, please use 'ground_truth' instead. Note that `ground_truth` should be of type string and not Sequence[string] like `ground_truths`\n",
      "Evaluating:   0%|          | 0/54 [00:00<?, ?it/s]Runner in Executor raised an exception\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400, 'innererror': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_result': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': True, 'severity': 'medium'}}}}}\n",
      "Evaluating:  20%|██        | 11/54 [00:03<00:10,  3.95it/s]Runner in Executor raised an exception\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400, 'innererror': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_result': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': True, 'severity': 'medium'}}}}}\n",
      "Evaluating: 100%|██████████| 54/54 [00:06<00:00,  7.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average score is: 0.6680273033133194\n",
      "CHUNK SIZE 2000, 15% overlap:\n",
      "                    System  Faithfulness  Answer Relevancy  Context Precision  \\\n",
      "0  Chunk 2000, overlap 15%      0.762022          0.723838           0.442857   \n",
      "\n",
      "   Context Recall  Answer Similarity  Answer Correctness   Average  \n",
      "0        0.579288           0.733706            0.766451  0.668027  \n",
      "Number of chunks for chunk size 2000, overlap 20%\n",
      "Warning: Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400, 'innererror': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_result': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'low'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': True, 'severity': 'medium'}}}}}on the following question: Analyze this quote from 'Ballad of Songbirds and Snakes': 'All right, so he'd dropped the handkerchief with Lucy Gray's scent - the one from the outside pocket of his book bag - into the snake tank. He'd done it so they would not bite her as they had Clemensia. So they would not kill her. Because he cared about her. Because he cared about her? Or because he wanted to win the Hunger Games so that he could secure the Plinth Prize. If it was the latter, he had cheated to win, and that was that.'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "passing column names as 'ground_truths' is deprecated and will be removed in the next version, please use 'ground_truth' instead. Note that `ground_truth` should be of type string and not Sequence[string] like `ground_truths`\n",
      "Evaluating:   0%|          | 0/54 [00:00<?, ?it/s]Runner in Executor raised an exception\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400, 'innererror': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_result': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': True, 'severity': 'medium'}}}}}\n",
      "Evaluating:  22%|██▏       | 12/54 [00:03<00:11,  3.77it/s]Runner in Executor raised an exception\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400, 'innererror': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_result': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': True, 'severity': 'medium'}}}}}\n",
      "Evaluating: 100%|██████████| 54/54 [00:07<00:00,  7.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average score is: 0.6936143090952968\n",
      "CHUNK SIZE 2000, 20% overlap:\n",
      "                    System  Faithfulness  Answer Relevancy  Context Precision  \\\n",
      "0  Chunk 2000, overlap 20%      0.859328            0.7308           0.470833   \n",
      "\n",
      "   Context Recall  Answer Similarity  Answer Correctness   Average  \n",
      "0        0.675626           0.699462            0.725637  0.693614  \n",
      "Number of chunks for chunk size 3000, overlap 0%\n",
      "Warning: Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400, 'innererror': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_result': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'low'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': True, 'severity': 'medium'}}}}}on the following question: Analyze this quote from 'Ballad of Songbirds and Snakes': 'All right, so he'd dropped the handkerchief with Lucy Gray's scent - the one from the outside pocket of his book bag - into the snake tank. He'd done it so they would not bite her as they had Clemensia. So they would not kill her. Because he cared about her. Because he cared about her? Or because he wanted to win the Hunger Games so that he could secure the Plinth Prize. If it was the latter, he had cheated to win, and that was that.'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "passing column names as 'ground_truths' is deprecated and will be removed in the next version, please use 'ground_truth' instead. Note that `ground_truth` should be of type string and not Sequence[string] like `ground_truths`\n",
      "Evaluating:   0%|          | 0/54 [00:00<?, ?it/s]Task exception was never retrieved\n",
      "future: <Task finished name='Task-1058' coro=<AsyncClient.aclose() done, defined at c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\httpx\\_client.py:2011> exception=RuntimeError('Event loop is closed')>\n",
      "RuntimeError: Event loop is closed\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1059' coro=<AsyncClient.aclose() done, defined at c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\httpx\\_client.py:2011> exception=RuntimeError('Event loop is closed')>\n",
      "RuntimeError: Event loop is closed\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1060' coro=<AsyncClient.aclose() done, defined at c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\httpx\\_client.py:2011> exception=RuntimeError('Event loop is closed')>\n",
      "RuntimeError: Event loop is closed\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1061' coro=<AsyncClient.aclose() done, defined at c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\httpx\\_client.py:2011> exception=RuntimeError('Event loop is closed')>\n",
      "RuntimeError: Event loop is closed\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1062' coro=<AsyncClient.aclose() done, defined at c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\httpx\\_client.py:2011> exception=RuntimeError('Event loop is closed')>\n",
      "RuntimeError: Event loop is closed\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1063' coro=<AsyncClient.aclose() done, defined at c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\httpx\\_client.py:2011> exception=RuntimeError('Event loop is closed')>\n",
      "RuntimeError: Event loop is closed\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1064' coro=<AsyncClient.aclose() done, defined at c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\httpx\\_client.py:2011> exception=RuntimeError('Event loop is closed')>\n",
      "RuntimeError: Event loop is closed\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1065' coro=<AsyncClient.aclose() done, defined at c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\httpx\\_client.py:2011> exception=RuntimeError('Event loop is closed')>\n",
      "RuntimeError: Event loop is closed\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1066' coro=<AsyncClient.aclose() done, defined at c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\httpx\\_client.py:2011> exception=RuntimeError('Event loop is closed')>\n",
      "RuntimeError: Event loop is closed\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1067' coro=<AsyncClient.aclose() done, defined at c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\httpx\\_client.py:2011> exception=RuntimeError('Event loop is closed')>\n",
      "RuntimeError: Event loop is closed\n",
      "Runner in Executor raised an exception\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400, 'innererror': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_result': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': True, 'severity': 'medium'}}}}}\n",
      "Evaluating:  20%|██        | 11/54 [00:03<00:11,  3.84it/s]Runner in Executor raised an exception\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400, 'innererror': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_result': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': True, 'severity': 'medium'}}}}}\n",
      "Evaluating: 100%|██████████| 54/54 [00:07<00:00,  7.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average score is: 0.7434476339150485\n",
      "CHUNK SIZE 3000, 0% overlap:\n",
      "                   System  Faithfulness  Answer Relevancy  Context Precision  \\\n",
      "0  Chunk 3000, overlap 0%      0.864944          0.729709             0.6375   \n",
      "\n",
      "   Context Recall  Answer Similarity  Answer Correctness   Average  \n",
      "0        0.689309           0.733664            0.805561  0.743448  \n",
      "Number of chunks for chunk size 3000, overlap 5%\n",
      "Warning: Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400, 'innererror': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_result': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'low'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': True, 'severity': 'medium'}}}}}on the following question: Analyze this quote from 'Ballad of Songbirds and Snakes': 'All right, so he'd dropped the handkerchief with Lucy Gray's scent - the one from the outside pocket of his book bag - into the snake tank. He'd done it so they would not bite her as they had Clemensia. So they would not kill her. Because he cared about her. Because he cared about her? Or because he wanted to win the Hunger Games so that he could secure the Plinth Prize. If it was the latter, he had cheated to win, and that was that.'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "passing column names as 'ground_truths' is deprecated and will be removed in the next version, please use 'ground_truth' instead. Note that `ground_truth` should be of type string and not Sequence[string] like `ground_truths`\n",
      "Evaluating:   0%|          | 0/54 [00:00<?, ?it/s]Runner in Executor raised an exception\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400, 'innererror': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_result': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': True, 'severity': 'medium'}}}}}\n",
      "Evaluating:  20%|██        | 11/54 [00:03<00:11,  3.86it/s]Runner in Executor raised an exception\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400, 'innererror': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_result': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': True, 'severity': 'medium'}}}}}\n",
      "Evaluating: 100%|██████████| 54/54 [00:06<00:00,  8.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average score is: 0.68596410701437\n",
      "CHUNK SIZE 3000, 5% overlap:\n",
      "                   System  Faithfulness  Answer Relevancy  Context Precision  \\\n",
      "0  Chunk 3000, overlap 5%       0.86207          0.747021           0.464286   \n",
      "\n",
      "   Context Recall  Answer Similarity  Answer Correctness   Average  \n",
      "0        0.729848           0.670983            0.641577  0.685964  \n",
      "Number of chunks for chunk size 3000, overlap 10%\n",
      "Warning: Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400, 'innererror': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_result': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'low'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': True, 'severity': 'medium'}}}}}on the following question: Analyze this quote from 'Ballad of Songbirds and Snakes': 'All right, so he'd dropped the handkerchief with Lucy Gray's scent - the one from the outside pocket of his book bag - into the snake tank. He'd done it so they would not bite her as they had Clemensia. So they would not kill her. Because he cared about her. Because he cared about her? Or because he wanted to win the Hunger Games so that he could secure the Plinth Prize. If it was the latter, he had cheated to win, and that was that.'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "passing column names as 'ground_truths' is deprecated and will be removed in the next version, please use 'ground_truth' instead. Note that `ground_truth` should be of type string and not Sequence[string] like `ground_truths`\n",
      "Evaluating:   0%|          | 0/54 [00:00<?, ?it/s]Runner in Executor raised an exception\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400, 'innererror': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_result': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': True, 'severity': 'medium'}}}}}\n",
      "Evaluating:  26%|██▌       | 14/54 [00:03<00:09,  4.39it/s]Runner in Executor raised an exception\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400, 'innererror': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_result': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': True, 'severity': 'medium'}}}}}\n",
      "Evaluating: 100%|██████████| 54/54 [00:06<00:00,  7.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average score is: 0.6816862158841568\n",
      "CHUNK SIZE 3000, 10% overlap:\n",
      "                    System  Faithfulness  Answer Relevancy  Context Precision  \\\n",
      "0  Chunk 3000, overlap 10%      0.863684          0.711061                0.5   \n",
      "\n",
      "   Context Recall  Answer Similarity  Answer Correctness   Average  \n",
      "0        0.579188           0.677831            0.758354  0.681686  \n",
      "Number of chunks for chunk size 3000, overlap 15%\n",
      "Warning: Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400, 'innererror': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_result': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'low'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': True, 'severity': 'medium'}}}}}on the following question: Analyze this quote from 'Ballad of Songbirds and Snakes': 'All right, so he'd dropped the handkerchief with Lucy Gray's scent - the one from the outside pocket of his book bag - into the snake tank. He'd done it so they would not bite her as they had Clemensia. So they would not kill her. Because he cared about her. Because he cared about her? Or because he wanted to win the Hunger Games so that he could secure the Plinth Prize. If it was the latter, he had cheated to win, and that was that.'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "passing column names as 'ground_truths' is deprecated and will be removed in the next version, please use 'ground_truth' instead. Note that `ground_truth` should be of type string and not Sequence[string] like `ground_truths`\n",
      "Evaluating:   0%|          | 0/54 [00:00<?, ?it/s]Runner in Executor raised an exception\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400, 'innererror': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_result': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': True, 'severity': 'medium'}}}}}\n",
      "Evaluating:  26%|██▌       | 14/54 [00:03<00:07,  5.02it/s]Runner in Executor raised an exception\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400, 'innererror': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_result': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': True, 'severity': 'medium'}}}}}\n",
      "Evaluating: 100%|██████████| 54/54 [00:07<00:00,  7.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average score is: 0.6558806901737344\n",
      "CHUNK SIZE 3000, 15% overlap:\n",
      "                    System  Faithfulness  Answer Relevancy  Context Precision  \\\n",
      "0  Chunk 3000, overlap 15%      0.884277          0.744819           0.414583   \n",
      "\n",
      "   Context Recall  Answer Similarity  Answer Correctness   Average  \n",
      "0        0.577723           0.736018            0.577863  0.655881  \n",
      "Number of chunks for chunk size 3000, overlap 20%\n",
      "Warning: Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400, 'innererror': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_result': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'low'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': True, 'severity': 'medium'}}}}}on the following question: Analyze this quote from 'Ballad of Songbirds and Snakes': 'All right, so he'd dropped the handkerchief with Lucy Gray's scent - the one from the outside pocket of his book bag - into the snake tank. He'd done it so they would not bite her as they had Clemensia. So they would not kill her. Because he cared about her. Because he cared about her? Or because he wanted to win the Hunger Games so that he could secure the Plinth Prize. If it was the latter, he had cheated to win, and that was that.'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "passing column names as 'ground_truths' is deprecated and will be removed in the next version, please use 'ground_truth' instead. Note that `ground_truth` should be of type string and not Sequence[string] like `ground_truths`\n",
      "Evaluating:   0%|          | 0/54 [00:00<?, ?it/s]Runner in Executor raised an exception\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400, 'innererror': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_result': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': True, 'severity': 'medium'}}}}}\n",
      "Evaluating:  20%|██        | 11/54 [00:03<00:10,  4.28it/s]Runner in Executor raised an exception\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400, 'innererror': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_result': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': True, 'severity': 'medium'}}}}}\n",
      "Evaluating: 100%|██████████| 54/54 [00:06<00:00,  8.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average score is: 0.7006815116686758\n",
      "CHUNK SIZE 3000, 20% overlap:\n",
      "                    System  Faithfulness  Answer Relevancy  Context Precision  \\\n",
      "0  Chunk 3000, overlap 20%      0.877549          0.747584           0.458333   \n",
      "\n",
      "   Context Recall  Answer Similarity  Answer Correctness   Average  \n",
      "0        0.747531            0.72432            0.648772  0.700682  \n"
     ]
    }
   ],
   "source": [
    "chunk_sizes = [500, 1000, 2000, 3000]\n",
    "overlap_percentages = [0, 5, 10, 15, 20]\n",
    "\n",
    "for chunk_size in chunk_sizes:\n",
    "    for overlap_percentage in overlap_percentages:\n",
    "        # Calculate overlap based on percentage\n",
    "        chunk_overlap = int(chunk_size * overlap_percentage / 100)\n",
    "        \n",
    "        # Create text splitter\n",
    "        # text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
    "        \n",
    "        # # Split documents\n",
    "        # chunks = text_splitter.split_documents(documents)\n",
    "        \n",
    "        # Print number of chunks\n",
    "        print(f\"Number of chunks for chunk size {chunk_size}, overlap {overlap_percentage}%\")\n",
    "        \n",
    "        # Create Chroma database\n",
    "        # db = Chroma.from_documents(chunks, embeddings_client, persist_directory=f\"../ballad/vectordb-edit/chunking_{chunk_size}_{overlap_percentage}\")\n",
    "        db = Chroma(persist_directory=f\"../ballad/vectordb-edit/chunking_{chunk_size}_{overlap_percentage}\", embedding_function=embeddings_client)\n",
    "        # db.persist()\n",
    "        \n",
    "        # Create retriever\n",
    "        retriever = db.as_retriever()\n",
    "        \n",
    "        # Run and evaluate\n",
    "        result,results_df = run_and_evaluate(f\"Chunk {chunk_size}, overlap {overlap_percentage}%\", retriever, prompt, llm, results_df)\n",
    "        print(f\"CHUNK SIZE {chunk_size}, {overlap_percentage}% overlap:\")\n",
    "        print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "chunk = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # THE FIRST TIME RUN THIS, AFTER RUN THE NEXT CELL\n",
    "# text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(chunk_size = 1000, chunk_overlap = 100)\n",
    "# chunks_1000 = text_splitter.split_documents(documents)\n",
    "# print(len(chunks_1000))\n",
    "# db_1000 = Chroma.from_documents(chunks_1000, embeddings_client, persist_directory = \"../ballad/vectordb/recursive_1000\")\n",
    "# db_1000.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# db_1000 = Chroma(persist_directory = \"../ballad/vectordb/recursive_1000\", embedding_function=embeddings_client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400, 'innererror': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_result': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'low'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': True, 'severity': 'medium'}}}}}on the following question: Analyze this quote from 'Ballad of Songbirds and Snakes': 'All right, so he'd dropped the handkerchief with Lucy Gray's scent - the one from the outside pocket of his book bag - into the snake tank. He'd done it so they would not bite her as they had Clemensia. So they would not kill her. Because he cared about her. Because he cared about her? Or because he wanted to win the Hunger Games so that he could secure the Plinth Prize. If it was the latter, he had cheated to win, and that was that.'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "passing column names as 'ground_truths' is deprecated and will be removed in the next version, please use 'ground_truth' instead. Note that `ground_truth` should be of type string and not Sequence[string] like `ground_truths`\n",
      "Evaluating:   0%|          | 0/54 [00:00<?, ?it/s]Runner in Executor raised an exception\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400, 'innererror': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_result': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': True, 'severity': 'medium'}}}}}\n",
      "Evaluating:  26%|██▌       | 14/54 [00:03<00:08,  4.52it/s]Runner in Executor raised an exception\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400, 'innererror': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_result': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': True, 'severity': 'medium'}}}}}\n",
      "Evaluating: 100%|██████████| 54/54 [00:08<00:00,  6.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHUNK SIZE 1000\n",
      "{'faithfulness': 0.8073, 'answer_relevancy': 0.7830, 'context_precision': 0.4722, 'context_recall': 0.7878, 'answer_similarity': 0.6856, 'answer_correctness': 0.8029}\n",
      "The average score is: 0.7231345250780993\n"
     ]
    }
   ],
   "source": [
    "# retriever_1000 = db_1000.as_retriever()\n",
    "# result_1000 = run_and_evaluate(retriever_1000, prompt, llm)\n",
    "# print(\"CHUNK SIZE 1000\")\n",
    "# print(result_1000)\n",
    "# avg_result_1000, dict_result_1000 = dictionary(result_1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "chunk = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107\n"
     ]
    }
   ],
   "source": [
    "# # THE FIRST TIME RUN THIS, AFTER RUN THE NEXT CELL\n",
    "# text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(chunk_size = 500, chunk_overlap = 50)\n",
    "# chunks_500 = text_splitter.split_documents(documents)\n",
    "# print(len(chunks_500))\n",
    "# db_500 = Chroma.from_documents(chunks_500, embeddings_client, persist_directory = \"../ballad/vectordb/recursive_500\")\n",
    "# db_500.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# db_500 = Chroma(persist_directory = \"../ballad/vectordb/recursive_500\", embedding_function=embeddings_client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "passing column names as 'ground_truths' is deprecated and will be removed in the next version, please use 'ground_truth' instead. Note that `ground_truth` should be of type string and not Sequence[string] like `ground_truths`\n",
      "Evaluating:   0%|          | 0/54 [00:00<?, ?it/s]Task exception was never retrieved\n",
      "future: <Task finished name='Task-202' coro=<AsyncClient.aclose() done, defined at c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\httpx\\_client.py:2011> exception=RuntimeError('Event loop is closed')>\n",
      "RuntimeError: Event loop is closed\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-203' coro=<AsyncClient.aclose() done, defined at c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\httpx\\_client.py:2011> exception=RuntimeError('Event loop is closed')>\n",
      "RuntimeError: Event loop is closed\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-204' coro=<AsyncClient.aclose() done, defined at c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\httpx\\_client.py:2011> exception=RuntimeError('Event loop is closed')>\n",
      "RuntimeError: Event loop is closed\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-205' coro=<AsyncClient.aclose() done, defined at c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\httpx\\_client.py:2011> exception=RuntimeError('Event loop is closed')>\n",
      "RuntimeError: Event loop is closed\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-206' coro=<AsyncClient.aclose() done, defined at c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\httpx\\_client.py:2011> exception=RuntimeError('Event loop is closed')>\n",
      "RuntimeError: Event loop is closed\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-207' coro=<AsyncClient.aclose() done, defined at c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\httpx\\_client.py:2011> exception=RuntimeError('Event loop is closed')>\n",
      "RuntimeError: Event loop is closed\n",
      "Evaluating: 100%|██████████| 54/54 [00:08<00:00,  6.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHUNK SIZE 500\n",
      "{'faithfulness': 0.8163, 'answer_relevancy': 0.9034, 'context_precision': 0.4012, 'context_recall': 0.6481, 'answer_similarity': 0.8669, 'answer_correctness': 0.6844}\n",
      "The average score is: 0.720067425291858\n"
     ]
    }
   ],
   "source": [
    "# retriever_500 = db_500.as_retriever()\n",
    "# result_500 = run_and_evaluate(retriever_500, prompt, llm)\n",
    "# print(\"CHUNK SIZE 500\")\n",
    "# print(result_500)\n",
    "# avg_result_500, dict_result_500 = dictionary(result_500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "chunk = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37\n"
     ]
    }
   ],
   "source": [
    "# text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(chunk_size = 2000, chunk_overlap = 200)\n",
    "# chunks_2000 = text_splitter.split_documents(documents)\n",
    "# print(len(chunks_2000))\n",
    "# db_2000 = Chroma.from_documents(chunks_2000, embeddings_client, persist_directory = \"../ballad/vectordb/recursive_2000\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# db_2000 = Chroma(persist_directory = \"../ballad/vectordb/recursive_2000\", embedding_function=embeddings_client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400, 'innererror': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_result': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'low'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': True, 'severity': 'medium'}}}}}on the following question: Analyze this quote from 'Ballad of Songbirds and Snakes': 'All right, so he'd dropped the handkerchief with Lucy Gray's scent - the one from the outside pocket of his book bag - into the snake tank. He'd done it so they would not bite her as they had Clemensia. So they would not kill her. Because he cared about her. Because he cared about her? Or because he wanted to win the Hunger Games so that he could secure the Plinth Prize. If it was the latter, he had cheated to win, and that was that.'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "passing column names as 'ground_truths' is deprecated and will be removed in the next version, please use 'ground_truth' instead. Note that `ground_truth` should be of type string and not Sequence[string] like `ground_truths`\n",
      "Evaluating:   0%|          | 0/54 [00:00<?, ?it/s]Runner in Executor raised an exception\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400, 'innererror': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_result': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': True, 'severity': 'medium'}}}}}\n",
      "Evaluating:  20%|██        | 11/54 [00:03<00:10,  3.93it/s]Runner in Executor raised an exception\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400, 'innererror': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_result': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': True, 'severity': 'medium'}}}}}\n",
      "Evaluating: 100%|██████████| 54/54 [00:09<00:00,  5.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHUNK SIZE 2000\n",
      "{'faithfulness': 0.8064, 'answer_relevancy': 0.7431, 'context_precision': 0.4389, 'context_recall': 0.6734, 'answer_similarity': 0.6855, 'answer_correctness': 0.7563}\n",
      "The average score is: 0.6839296969751175\n"
     ]
    }
   ],
   "source": [
    "# retriever_2000 = db_2000.as_retriever()\n",
    "# result_2000 = run_and_evaluate(retriever_2000, prompt, llm)\n",
    "# print(\"CHUNK SIZE 2000\")\n",
    "# print(result_2000)\n",
    "# avg_result_2000, dict_result_2000 = dictionary(result_2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "chunk = 3000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n"
     ]
    }
   ],
   "source": [
    "# text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(chunk_size = 3000, chunk_overlap = 300)\n",
    "# chunks_3000 = text_splitter.split_documents(documents)\n",
    "# print(len(chunks_3000))\n",
    "# db_3000 = Chroma.from_documents(chunks_3000, embeddings_client, persist_directory = \"../ballad/vectordb/recursive_3000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# db_3000 = Chroma(persist_directory = \"../ballad/vectordb/recursive_3000\", embedding_function=embeddings_client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400, 'innererror': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_result': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'low'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': True, 'severity': 'medium'}}}}}on the following question: Analyze this quote from 'Ballad of Songbirds and Snakes': 'All right, so he'd dropped the handkerchief with Lucy Gray's scent - the one from the outside pocket of his book bag - into the snake tank. He'd done it so they would not bite her as they had Clemensia. So they would not kill her. Because he cared about her. Because he cared about her? Or because he wanted to win the Hunger Games so that he could secure the Plinth Prize. If it was the latter, he had cheated to win, and that was that.'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "passing column names as 'ground_truths' is deprecated and will be removed in the next version, please use 'ground_truth' instead. Note that `ground_truth` should be of type string and not Sequence[string] like `ground_truths`\n",
      "Evaluating:   0%|          | 0/54 [00:00<?, ?it/s]Runner in Executor raised an exception\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400, 'innererror': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_result': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': True, 'severity': 'medium'}}}}}\n",
      "Evaluating:  26%|██▌       | 14/54 [00:03<00:07,  5.49it/s]Runner in Executor raised an exception\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400, 'innererror': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_result': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': True, 'severity': 'medium'}}}}}\n",
      "Evaluating: 100%|██████████| 54/54 [00:08<00:00,  6.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHUNK SIZE 3000\n",
      "{'faithfulness': 0.8087, 'answer_relevancy': 0.7442, 'context_precision': 0.5190, 'context_recall': 0.6554, 'answer_similarity': 0.7109, 'answer_correctness': 0.8236}\n",
      "The average score is: 0.7103154417058323\n"
     ]
    }
   ],
   "source": [
    "# retriever_3000 = db_3000.as_retriever()\n",
    "# result_3000 = run_and_evaluate(retriever_3000, prompt, llm)\n",
    "# print(\"CHUNK SIZE 3000\")\n",
    "# print(result_3000)\n",
    "# avg_result_3000 ,dict_result_3000 = dictionary(result_3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>System</th>\n",
       "      <th>Faithfulness</th>\n",
       "      <th>Answer Relevancy</th>\n",
       "      <th>Context Precision</th>\n",
       "      <th>Context Recall</th>\n",
       "      <th>Answer Similarity</th>\n",
       "      <th>Answer Correctness</th>\n",
       "      <th>Average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GPT-3.5</td>\n",
       "      <td>0.971429</td>\n",
       "      <td>0.745413</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.866096</td>\n",
       "      <td>0.660199</td>\n",
       "      <td>0.810784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GPT-4</td>\n",
       "      <td>0.942857</td>\n",
       "      <td>0.884441</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.860459</td>\n",
       "      <td>0.654768</td>\n",
       "      <td>0.835631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Naive</td>\n",
       "      <td>0.881621</td>\n",
       "      <td>0.726491</td>\n",
       "      <td>0.512500</td>\n",
       "      <td>0.693275</td>\n",
       "      <td>0.683565</td>\n",
       "      <td>0.715710</td>\n",
       "      <td>0.702194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Recursive</td>\n",
       "      <td>0.865996</td>\n",
       "      <td>0.729346</td>\n",
       "      <td>0.512500</td>\n",
       "      <td>0.580707</td>\n",
       "      <td>0.816281</td>\n",
       "      <td>0.789784</td>\n",
       "      <td>0.715769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Chunk 500, overlap 0%</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.884760</td>\n",
       "      <td>0.376543</td>\n",
       "      <td>0.435185</td>\n",
       "      <td>0.866883</td>\n",
       "      <td>0.664614</td>\n",
       "      <td>0.682442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Chunk 500, overlap 5%</td>\n",
       "      <td>0.680952</td>\n",
       "      <td>0.901854</td>\n",
       "      <td>0.441358</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.863189</td>\n",
       "      <td>0.652780</td>\n",
       "      <td>0.701133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Chunk 500, overlap 10%</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.885184</td>\n",
       "      <td>0.450617</td>\n",
       "      <td>0.592593</td>\n",
       "      <td>0.863726</td>\n",
       "      <td>0.662760</td>\n",
       "      <td>0.709147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Chunk 500, overlap 15%</td>\n",
       "      <td>0.826190</td>\n",
       "      <td>0.879043</td>\n",
       "      <td>0.645062</td>\n",
       "      <td>0.824074</td>\n",
       "      <td>0.869306</td>\n",
       "      <td>0.631235</td>\n",
       "      <td>0.779152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Chunk 500, overlap 20%</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.903706</td>\n",
       "      <td>0.506173</td>\n",
       "      <td>0.675926</td>\n",
       "      <td>0.872395</td>\n",
       "      <td>0.586756</td>\n",
       "      <td>0.709874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Chunk 1000, overlap 0%</td>\n",
       "      <td>0.834282</td>\n",
       "      <td>0.723396</td>\n",
       "      <td>0.487500</td>\n",
       "      <td>0.689591</td>\n",
       "      <td>0.780951</td>\n",
       "      <td>0.769929</td>\n",
       "      <td>0.714275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Chunk 1000, overlap 5%</td>\n",
       "      <td>0.859269</td>\n",
       "      <td>0.710329</td>\n",
       "      <td>0.520833</td>\n",
       "      <td>0.567662</td>\n",
       "      <td>0.789020</td>\n",
       "      <td>0.710835</td>\n",
       "      <td>0.692992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Chunk 1000, overlap 10%</td>\n",
       "      <td>0.833369</td>\n",
       "      <td>0.724186</td>\n",
       "      <td>0.472222</td>\n",
       "      <td>0.635688</td>\n",
       "      <td>0.677939</td>\n",
       "      <td>0.762695</td>\n",
       "      <td>0.684350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Chunk 1000, overlap 15%</td>\n",
       "      <td>0.809964</td>\n",
       "      <td>0.719308</td>\n",
       "      <td>0.519048</td>\n",
       "      <td>0.558069</td>\n",
       "      <td>0.735682</td>\n",
       "      <td>0.784538</td>\n",
       "      <td>0.687768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Chunk 1000, overlap 20%</td>\n",
       "      <td>0.808816</td>\n",
       "      <td>0.718937</td>\n",
       "      <td>0.380952</td>\n",
       "      <td>0.538053</td>\n",
       "      <td>0.763482</td>\n",
       "      <td>0.799512</td>\n",
       "      <td>0.668292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Chunk 2000, overlap 0%</td>\n",
       "      <td>0.788936</td>\n",
       "      <td>0.747135</td>\n",
       "      <td>0.470833</td>\n",
       "      <td>0.693106</td>\n",
       "      <td>0.660520</td>\n",
       "      <td>0.555794</td>\n",
       "      <td>0.652721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Chunk 2000, overlap 5%</td>\n",
       "      <td>0.819300</td>\n",
       "      <td>0.724491</td>\n",
       "      <td>0.537037</td>\n",
       "      <td>0.653868</td>\n",
       "      <td>0.765334</td>\n",
       "      <td>0.596272</td>\n",
       "      <td>0.682717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Chunk 2000, overlap 10%</td>\n",
       "      <td>0.894395</td>\n",
       "      <td>0.730272</td>\n",
       "      <td>0.470833</td>\n",
       "      <td>0.560752</td>\n",
       "      <td>0.678642</td>\n",
       "      <td>0.799907</td>\n",
       "      <td>0.689133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Chunk 2000, overlap 15%</td>\n",
       "      <td>0.762022</td>\n",
       "      <td>0.723838</td>\n",
       "      <td>0.442857</td>\n",
       "      <td>0.579288</td>\n",
       "      <td>0.733706</td>\n",
       "      <td>0.766451</td>\n",
       "      <td>0.668027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Chunk 2000, overlap 20%</td>\n",
       "      <td>0.859328</td>\n",
       "      <td>0.730800</td>\n",
       "      <td>0.470833</td>\n",
       "      <td>0.675626</td>\n",
       "      <td>0.699462</td>\n",
       "      <td>0.725637</td>\n",
       "      <td>0.693614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Chunk 3000, overlap 0%</td>\n",
       "      <td>0.864944</td>\n",
       "      <td>0.729709</td>\n",
       "      <td>0.637500</td>\n",
       "      <td>0.689309</td>\n",
       "      <td>0.733664</td>\n",
       "      <td>0.805561</td>\n",
       "      <td>0.743448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Chunk 3000, overlap 5%</td>\n",
       "      <td>0.862070</td>\n",
       "      <td>0.747021</td>\n",
       "      <td>0.464286</td>\n",
       "      <td>0.729848</td>\n",
       "      <td>0.670983</td>\n",
       "      <td>0.641577</td>\n",
       "      <td>0.685964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Chunk 3000, overlap 10%</td>\n",
       "      <td>0.863684</td>\n",
       "      <td>0.711061</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.579188</td>\n",
       "      <td>0.677831</td>\n",
       "      <td>0.758354</td>\n",
       "      <td>0.681686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Chunk 3000, overlap 15%</td>\n",
       "      <td>0.884277</td>\n",
       "      <td>0.744819</td>\n",
       "      <td>0.414583</td>\n",
       "      <td>0.577723</td>\n",
       "      <td>0.736018</td>\n",
       "      <td>0.577863</td>\n",
       "      <td>0.655881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Chunk 3000, overlap 20%</td>\n",
       "      <td>0.877549</td>\n",
       "      <td>0.747584</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.747531</td>\n",
       "      <td>0.724320</td>\n",
       "      <td>0.648772</td>\n",
       "      <td>0.700682</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     System  Faithfulness  Answer Relevancy  \\\n",
       "0                   GPT-3.5      0.971429          0.745413   \n",
       "1                     GPT-4      0.942857          0.884441   \n",
       "2                     Naive      0.881621          0.726491   \n",
       "3                 Recursive      0.865996          0.729346   \n",
       "4     Chunk 500, overlap 0%      0.866667          0.884760   \n",
       "5     Chunk 500, overlap 5%      0.680952          0.901854   \n",
       "6    Chunk 500, overlap 10%      0.800000          0.885184   \n",
       "7    Chunk 500, overlap 15%      0.826190          0.879043   \n",
       "8    Chunk 500, overlap 20%      0.714286          0.903706   \n",
       "9    Chunk 1000, overlap 0%      0.834282          0.723396   \n",
       "10   Chunk 1000, overlap 5%      0.859269          0.710329   \n",
       "11  Chunk 1000, overlap 10%      0.833369          0.724186   \n",
       "12  Chunk 1000, overlap 15%      0.809964          0.719308   \n",
       "13  Chunk 1000, overlap 20%      0.808816          0.718937   \n",
       "14   Chunk 2000, overlap 0%      0.788936          0.747135   \n",
       "15   Chunk 2000, overlap 5%      0.819300          0.724491   \n",
       "16  Chunk 2000, overlap 10%      0.894395          0.730272   \n",
       "17  Chunk 2000, overlap 15%      0.762022          0.723838   \n",
       "18  Chunk 2000, overlap 20%      0.859328          0.730800   \n",
       "19   Chunk 3000, overlap 0%      0.864944          0.729709   \n",
       "20   Chunk 3000, overlap 5%      0.862070          0.747021   \n",
       "21  Chunk 3000, overlap 10%      0.863684          0.711061   \n",
       "22  Chunk 3000, overlap 15%      0.884277          0.744819   \n",
       "23  Chunk 3000, overlap 20%      0.877549          0.747584   \n",
       "\n",
       "    Context Precision  Context Recall  Answer Similarity  Answer Correctness  \\\n",
       "0                 NaN             NaN           0.866096            0.660199   \n",
       "1                 NaN             NaN           0.860459            0.654768   \n",
       "2            0.512500        0.693275           0.683565            0.715710   \n",
       "3            0.512500        0.580707           0.816281            0.789784   \n",
       "4            0.376543        0.435185           0.866883            0.664614   \n",
       "5            0.441358        0.666667           0.863189            0.652780   \n",
       "6            0.450617        0.592593           0.863726            0.662760   \n",
       "7            0.645062        0.824074           0.869306            0.631235   \n",
       "8            0.506173        0.675926           0.872395            0.586756   \n",
       "9            0.487500        0.689591           0.780951            0.769929   \n",
       "10           0.520833        0.567662           0.789020            0.710835   \n",
       "11           0.472222        0.635688           0.677939            0.762695   \n",
       "12           0.519048        0.558069           0.735682            0.784538   \n",
       "13           0.380952        0.538053           0.763482            0.799512   \n",
       "14           0.470833        0.693106           0.660520            0.555794   \n",
       "15           0.537037        0.653868           0.765334            0.596272   \n",
       "16           0.470833        0.560752           0.678642            0.799907   \n",
       "17           0.442857        0.579288           0.733706            0.766451   \n",
       "18           0.470833        0.675626           0.699462            0.725637   \n",
       "19           0.637500        0.689309           0.733664            0.805561   \n",
       "20           0.464286        0.729848           0.670983            0.641577   \n",
       "21           0.500000        0.579188           0.677831            0.758354   \n",
       "22           0.414583        0.577723           0.736018            0.577863   \n",
       "23           0.458333        0.747531           0.724320            0.648772   \n",
       "\n",
       "     Average  \n",
       "0   0.810784  \n",
       "1   0.835631  \n",
       "2   0.702194  \n",
       "3   0.715769  \n",
       "4   0.682442  \n",
       "5   0.701133  \n",
       "6   0.709147  \n",
       "7   0.779152  \n",
       "8   0.709874  \n",
       "9   0.714275  \n",
       "10  0.692992  \n",
       "11  0.684350  \n",
       "12  0.687768  \n",
       "13  0.668292  \n",
       "14  0.652721  \n",
       "15  0.682717  \n",
       "16  0.689133  \n",
       "17  0.668027  \n",
       "18  0.693614  \n",
       "19  0.743448  \n",
       "20  0.685964  \n",
       "21  0.681686  \n",
       "22  0.655881  \n",
       "23  0.700682  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.to_csv(f\"../ballad/results/results_report.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>System</th>\n",
       "      <th>Faithfulness</th>\n",
       "      <th>Answer Relevancy</th>\n",
       "      <th>Context Precision</th>\n",
       "      <th>Context Recall</th>\n",
       "      <th>Answer Similarity</th>\n",
       "      <th>Answer Correctness</th>\n",
       "      <th>Average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GPT-4</td>\n",
       "      <td>0.942857</td>\n",
       "      <td>0.884441</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.860459</td>\n",
       "      <td>0.654768</td>\n",
       "      <td>0.835631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GPT-3.5</td>\n",
       "      <td>0.971429</td>\n",
       "      <td>0.745413</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.866096</td>\n",
       "      <td>0.660199</td>\n",
       "      <td>0.810784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Chunk 500, overlap 15%</td>\n",
       "      <td>0.826190</td>\n",
       "      <td>0.879043</td>\n",
       "      <td>0.645062</td>\n",
       "      <td>0.824074</td>\n",
       "      <td>0.869306</td>\n",
       "      <td>0.631235</td>\n",
       "      <td>0.779152</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   System  Faithfulness  Answer Relevancy  Context Precision  \\\n",
       "1                   GPT-4      0.942857          0.884441                NaN   \n",
       "0                 GPT-3.5      0.971429          0.745413                NaN   \n",
       "7  Chunk 500, overlap 15%      0.826190          0.879043           0.645062   \n",
       "\n",
       "   Context Recall  Answer Similarity  Answer Correctness   Average  \n",
       "1             NaN           0.860459            0.654768  0.835631  \n",
       "0             NaN           0.866096            0.660199  0.810784  \n",
       "7        0.824074           0.869306            0.631235  0.779152  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "highest_average = results_df.nlargest(3, \"Average\")\n",
    "highest_average"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### now time to look for different top-k\n",
    "\n",
    "Note: We continue with Chunk 3000, overlap 10%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_k = Chroma(persist_directory = \"../ballad/vectordb-edit/chunking_500_15\", embedding_function=embeddings_client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "passing column names as 'ground_truths' is deprecated and will be removed in the next version, please use 'ground_truth' instead. Note that `ground_truth` should be of type string and not Sequence[string] like `ground_truths`\n",
      "Evaluating: 100%|██████████| 54/54 [00:06<00:00,  7.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average score is: 0.7578063194974834\n",
      "Results for K=2:\n",
      "                             System  Faithfulness  Answer Relevancy  \\\n",
      "0  Chunk size 500, overlap 15%, K=2          0.74          0.880395   \n",
      "\n",
      "   Context Precision  Context Recall  Answer Similarity  Answer Correctness  \\\n",
      "0           0.666667         0.72963           0.870647              0.6595   \n",
      "\n",
      "    Average  \n",
      "0  0.757806  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "passing column names as 'ground_truths' is deprecated and will be removed in the next version, please use 'ground_truth' instead. Note that `ground_truth` should be of type string and not Sequence[string] like `ground_truths`\n",
      "Evaluating:   0%|          | 0/54 [00:00<?, ?it/s]Runner in Executor raised an exception\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400, 'innererror': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_result': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'low'}, 'violence': {'filtered': True, 'severity': 'medium'}}}}}\n",
      "Evaluating: 100%|██████████| 54/54 [00:08<00:00,  6.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average score is: 0.7246070182988021\n",
      "Results for K=3:\n",
      "                             System  Faithfulness  Answer Relevancy  \\\n",
      "0  Chunk size 500, overlap 15%, K=3      0.750577          0.806049   \n",
      "\n",
      "   Context Precision  Context Recall  Answer Similarity  Answer Correctness  \\\n",
      "0           0.775391        0.453704           0.804792             0.75713   \n",
      "\n",
      "    Average  \n",
      "0  0.724607  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "passing column names as 'ground_truths' is deprecated and will be removed in the next version, please use 'ground_truth' instead. Note that `ground_truth` should be of type string and not Sequence[string] like `ground_truths`\n",
      "Evaluating: 100%|██████████| 54/54 [00:07<00:00,  6.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average score is: 0.8265952620225997\n",
      "Results for K=5:\n",
      "                             System  Faithfulness  Answer Relevancy  \\\n",
      "0  Chunk size 500, overlap 15%, K=5      0.966667          0.905295   \n",
      "\n",
      "   Context Precision  Context Recall  Answer Similarity  Answer Correctness  \\\n",
      "0           0.636883        0.944444           0.874627            0.631657   \n",
      "\n",
      "    Average  \n",
      "0  0.826595  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "passing column names as 'ground_truths' is deprecated and will be removed in the next version, please use 'ground_truth' instead. Note that `ground_truth` should be of type string and not Sequence[string] like `ground_truths`\n",
      "Evaluating: 100%|██████████| 54/54 [00:06<00:00,  7.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average score is: 0.7564957837489547\n",
      "Results for K=6:\n",
      "                             System  Faithfulness  Answer Relevancy  \\\n",
      "0  Chunk size 500, overlap 15%, K=6      0.792857          0.897322   \n",
      "\n",
      "   Context Precision  Context Recall  Answer Similarity  Answer Correctness  \\\n",
      "0           0.681821        0.675926           0.866473            0.624575   \n",
      "\n",
      "    Average  \n",
      "0  0.756496  \n",
      "Warning: Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400, 'innererror': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_result': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': True, 'severity': 'medium'}}}}}on the following question: Analyze this quote from 'Ballad of Songbirds and Snakes': 'If I'm helping to kill people in the districts, how is it any better than helping to kill them in the Hunger Games?'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "passing column names as 'ground_truths' is deprecated and will be removed in the next version, please use 'ground_truth' instead. Note that `ground_truth` should be of type string and not Sequence[string] like `ground_truths`\n",
      "Evaluating:  19%|█▊        | 10/54 [00:03<00:13,  3.25it/s]Runner in Executor raised an exception\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400, 'innererror': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_result': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': True, 'severity': 'medium'}}}}}\n",
      "Evaluating: 100%|██████████| 54/54 [00:06<00:00,  8.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average score is: 0.7512490419021468\n",
      "Results for K=7:\n",
      "                             System  Faithfulness  Answer Relevancy  \\\n",
      "0  Chunk size 500, overlap 15%, K=7      0.693972          0.747306   \n",
      "\n",
      "   Context Precision  Context Recall  Answer Similarity  Answer Correctness  \\\n",
      "0           0.844508        0.625705           0.824804              0.7712   \n",
      "\n",
      "    Average  \n",
      "0  0.751249  \n"
     ]
    }
   ],
   "source": [
    "k_values = [2, 3, 5, 6, 7]\n",
    "\n",
    "# Iterate over different k values\n",
    "for k in k_values:\n",
    "    # Create retriever with k value\n",
    "    retriever = db_k.as_retriever(search_kwargs={\"k\": k})\n",
    "    \n",
    "    # Run and evaluate\n",
    "    result,results_df = run_and_evaluate(f\"Chunk size 500, overlap 15%, K={k}\", retriever, prompt, llm, results_df)\n",
    "    print(f\"Results for K={k}:\")\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "passing column names as 'ground_truths' is deprecated and will be removed in the next version, please use 'ground_truth' instead. Note that `ground_truth` should be of type string and not Sequence[string] like `ground_truths`\n",
      "Evaluating: 100%|██████████| 54/54 [00:09<00:00,  5.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHUNK SIZE 1000, K=3\n",
      "{'faithfulness': 0.8200, 'answer_relevancy': 0.9060, 'context_precision': 0.5370, 'context_recall': 0.7963, 'answer_similarity': 0.8722, 'answer_correctness': 0.6900}\n",
      "The average score is: 0.7702549797617143\n"
     ]
    }
   ],
   "source": [
    "# retriever_3 = db_1000.as_retriever(search_kwargs={\"k\": 3})\n",
    "# result_3 = run_and_evaluate(retriever_3, prompt, llm)\n",
    "# print(\"CHUNK SIZE 1000, K=3\")\n",
    "# print(result_3)\n",
    "# avg_result_3, dict_result_3 = dictionary(result_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "passing column names as 'ground_truths' is deprecated and will be removed in the next version, please use 'ground_truth' instead. Note that `ground_truth` should be of type string and not Sequence[string] like `ground_truths`\n",
      "Evaluating: 100%|██████████| 54/54 [00:10<00:00,  5.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHUNK SIZE 1000, K=5\n",
      "{'faithfulness': 0.8667, 'answer_relevancy': 0.8925, 'context_precision': 0.4636, 'context_recall': 0.6204, 'answer_similarity': 0.8748, 'answer_correctness': 0.6645}\n",
      "The average score is: 0.7303917310800102\n"
     ]
    }
   ],
   "source": [
    "# retriever_5 = db_1000.as_retriever(search_kwargs={\"k\": 5})\n",
    "# result_5 = run_and_evaluate(retriever_5, prompt, llm)\n",
    "# print(\"CHUNK SIZE 1000, K=5\")\n",
    "# print(result_5)\n",
    "# avg_result_5, dict_result_5 = dictionary(result_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "passing column names as 'ground_truths' is deprecated and will be removed in the next version, please use 'ground_truth' instead. Note that `ground_truth` should be of type string and not Sequence[string] like `ground_truths`\n",
      "Evaluating: 100%|██████████| 54/54 [00:10<00:00,  5.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHUNK SIZE 1000, K=5\n",
      "{'faithfulness': 0.8667, 'answer_relevancy': 0.9038, 'context_precision': 0.4434, 'context_recall': 0.6481, 'answer_similarity': 0.8671, 'answer_correctness': 0.6306}\n",
      "The average score is: 0.7266041952543404\n"
     ]
    }
   ],
   "source": [
    "# retriever_6= db_1000.as_retriever(search_kwargs={\"k\": 6})\n",
    "# result_6 = run_and_evaluate(retriever_6, prompt, llm)\n",
    "# print(\"CHUNK SIZE 1000, K=5\")\n",
    "# print(result_6)\n",
    "# avg_result_6, dict_result_6 = dictionary(result_6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400, 'innererror': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_result': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'low'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': True, 'severity': 'medium'}}}}}on the following question: Analyze this quote from 'Ballad of Songbirds and Snakes': 'Bombs and blood. That was how the rebels had killed his mother. He wondered if they had killed Lucy Gray's, too. 'Just like her pearly white bones.' She seemed to have no love for District 12, always separating herself from it, saying she was, what was it . . . Covey?'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "passing column names as 'ground_truths' is deprecated and will be removed in the next version, please use 'ground_truth' instead. Note that `ground_truth` should be of type string and not Sequence[string] like `ground_truths`\n",
      "Evaluating:   0%|          | 0/54 [00:00<?, ?it/s]Runner in Executor raised an exception\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400, 'innererror': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_result': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': True, 'severity': 'medium'}}}}}\n",
      "Evaluating:  20%|██        | 11/54 [00:03<00:12,  3.38it/s]Runner in Executor raised an exception\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400, 'innererror': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_result': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': True, 'severity': 'medium'}}}}}\n",
      "Evaluating: 100%|██████████| 54/54 [00:08<00:00,  6.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHUNK SIZE 1000, K=7\n",
      "{'faithfulness': 0.9253, 'answer_relevancy': 0.7778, 'context_precision': 0.4403, 'context_recall': 0.8073, 'answer_similarity': 0.7465, 'answer_correctness': 0.5476}\n",
      "The average score is: 0.7074589251052892\n"
     ]
    }
   ],
   "source": [
    "# retriever_7= db_1000.as_retriever(search_kwargs={\"k\": 7})\n",
    "# result_7 = run_and_evaluate(retriever_7, prompt, llm)\n",
    "# print(\"CHUNK SIZE 1000, K=7\")\n",
    "# print(result_7)\n",
    "# avg_result_7, dict_result_7 = dictionary(result_7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "passing column names as 'ground_truths' is deprecated and will be removed in the next version, please use 'ground_truth' instead. Note that `ground_truth` should be of type string and not Sequence[string] like `ground_truths`\n",
      "Evaluating: 100%|██████████| 54/54 [00:11<00:00,  4.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHUNK SIZE 1000, K=2\n",
      "{'faithfulness': 0.6167, 'answer_relevancy': 0.8891, 'context_precision': 0.5000, 'context_recall': 0.7778, 'answer_similarity': 0.8708, 'answer_correctness': 0.6751}\n",
      "The average score is: 0.7215756009304392\n"
     ]
    }
   ],
   "source": [
    "# retriever_2 = db_1000.as_retriever(search_kwargs={\"k\": 2})\n",
    "# result_2 = run_and_evaluate(retriever_2, prompt, llm)\n",
    "# print(\"CHUNK SIZE 1000, K=2\")\n",
    "# print(result_2)\n",
    "# avg_result_2, dict_result_2 = dictionary(result_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### look for different retrievers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### parent document retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "passing column names as 'ground_truths' is deprecated and will be removed in the next version, please use 'ground_truth' instead. Note that `ground_truth` should be of type string and not Sequence[string] like `ground_truths`\n",
      "Evaluating: 100%|██████████| 54/54 [00:06<00:00,  8.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average score is: 0.6465194256933376\n",
      "                      System  Faithfulness  Answer Relevancy  \\\n",
      "0  Parent Retriever 1000-200       0.73125          0.582884   \n",
      "\n",
      "   Context Precision  Context Recall  Answer Similarity  Answer Correctness  \\\n",
      "0           0.444444        0.685185           0.862021            0.573332   \n",
      "\n",
      "    Average  \n",
      "0  0.646519  \n"
     ]
    }
   ],
   "source": [
    "from langchain.retrievers import ParentDocumentRetriever\n",
    "from langchain.storage import InMemoryStore\n",
    "\n",
    "parent_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(chunk_size=1000, chunk_overlap = 200)\n",
    "child_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(chunk_size=200, chunk_overlap = 0)\n",
    "\n",
    "vectorstore = Chroma(collection_name=\"split_parents\",persist_directory = \"../ballad/vectordb-edit/parent-report\", embedding_function=embeddings_client)\n",
    "store = InMemoryStore()\n",
    "parent_document_retriever = ParentDocumentRetriever(\n",
    "    vectorstore=vectorstore,\n",
    "    docstore=store,\n",
    "    child_splitter=child_splitter,\n",
    "    parent_splitter=parent_splitter,\n",
    "    search_kwargs = ({\"k\": 5})\n",
    ")\n",
    "parent_document_retriever.add_documents(documents)\n",
    "result_parent, results_df = run_and_evaluate(f\"Parent Retriever 1000-200\", parent_document_retriever, prompt, llm, results_df)\n",
    "print(result_parent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "passing column names as 'ground_truths' is deprecated and will be removed in the next version, please use 'ground_truth' instead. Note that `ground_truth` should be of type string and not Sequence[string] like `ground_truths`\n",
      "Evaluating:   0%|          | 0/54 [00:00<?, ?it/s]Runner in Executor raised an exception\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400, 'innererror': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_result': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': True, 'severity': 'medium'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}}}\n",
      "Evaluating: 100%|██████████| 54/54 [00:07<00:00,  7.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average score is: 0.7753608442569068\n",
      "                     System  Faithfulness  Answer Relevancy  \\\n",
      "0  Parent Retriever 500-100      0.815535          0.880237   \n",
      "\n",
      "   Context Precision  Context Recall  Answer Similarity  Answer Correctness  \\\n",
      "0           0.719369        0.648148           0.850717            0.738159   \n",
      "\n",
      "    Average  \n",
      "0  0.775361  \n"
     ]
    }
   ],
   "source": [
    "parent_splitter_small = RecursiveCharacterTextSplitter.from_tiktoken_encoder(chunk_size=500, chunk_overlap = 50)\n",
    "child_splitter_small = RecursiveCharacterTextSplitter.from_tiktoken_encoder(chunk_size=100, chunk_overlap = 0)\n",
    "\n",
    "vectorstore = Chroma(collection_name=\"split_parents_small\",persist_directory = \"../ballad/vectordb-edit/parent_small-report\", embedding_function=embeddings_client)\n",
    "store = InMemoryStore()\n",
    "parent_document_retriever_small = ParentDocumentRetriever(\n",
    "    vectorstore=vectorstore,\n",
    "    docstore=store,\n",
    "    child_splitter=child_splitter_small,\n",
    "    parent_splitter=parent_splitter_small,\n",
    "    search_kwargs = ({\"k\": 5})\n",
    ")\n",
    "parent_document_retriever_small.add_documents(documents)\n",
    "result_parent_small, results_df = run_and_evaluate(f\"Parent Retriever 500-100\", parent_document_retriever_small, prompt, llm, results_df)\n",
    "print(result_parent_small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "passing column names as 'ground_truths' is deprecated and will be removed in the next version, please use 'ground_truth' instead. Note that `ground_truth` should be of type string and not Sequence[string] like `ground_truths`\n",
      "Evaluating: 100%|██████████| 54/54 [00:07<00:00,  7.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average score is: 0.7104080808180977\n",
      "                      System  Faithfulness  Answer Relevancy  \\\n",
      "0  Parent Retriever 1500-200         0.775           0.79208   \n",
      "\n",
      "   Context Precision  Context Recall  Answer Similarity  Answer Correctness  \\\n",
      "0           0.444444        0.768519           0.869522            0.612883   \n",
      "\n",
      "    Average  \n",
      "0  0.710408  \n"
     ]
    }
   ],
   "source": [
    "parent_splitter_large = RecursiveCharacterTextSplitter.from_tiktoken_encoder(chunk_size=1500, chunk_overlap = 150)\n",
    "child_splitter_large = RecursiveCharacterTextSplitter.from_tiktoken_encoder(chunk_size=200, chunk_overlap = 0)\n",
    "\n",
    "vectorstore = Chroma(collection_name=\"split_parents_large\",persist_directory = \"../ballad/vectordb-edit/parent_large-report\", embedding_function=embeddings_client)\n",
    "store = InMemoryStore()\n",
    "parent_document_retriever_large = ParentDocumentRetriever(\n",
    "    vectorstore=vectorstore,\n",
    "    docstore=store,\n",
    "    child_splitter=child_splitter_large,\n",
    "    parent_splitter=parent_splitter_large,\n",
    "    search_kwargs = ({\"k\": 5})\n",
    ")\n",
    "parent_document_retriever_large.add_documents(documents)\n",
    "result_parent_large , results_df = run_and_evaluate(f\"Parent Retriever 1500-200\", parent_document_retriever_large, prompt, llm, results_df)\n",
    "print(result_parent_large)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Maximum marginal relevance retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "passing column names as 'ground_truths' is deprecated and will be removed in the next version, please use 'ground_truth' instead. Note that `ground_truth` should be of type string and not Sequence[string] like `ground_truths`\n",
      "Evaluating: 100%|██████████| 54/54 [00:07<00:00,  7.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average score is: 0.8071934659779852\n",
      "Marginal relevance\n",
      "  System  Faithfulness  Answer Relevancy  Context Precision  Context Recall  \\\n",
      "0    MMR      0.792857          0.898714           0.738735        0.888889   \n",
      "\n",
      "   Answer Similarity  Answer Correctness   Average  \n",
      "0           0.874188            0.649778  0.807193  \n"
     ]
    }
   ],
   "source": [
    "retriever_mmr = db_k.as_retriever(search_type=\"mmr\",search_kwargs = ({\"k\": 5}))\n",
    "result_mmr, results_df = run_and_evaluate(f\"MMR\", retriever_mmr, prompt, llm, results_df)\n",
    "print(\"Marginal relevance\")\n",
    "print(result_mmr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BM25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(chunk_size = 500, chunk_overlap = 75)\n",
    "chunks_500 = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400, 'innererror': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_result': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': True, 'severity': 'medium'}}}}}on the following question: Analyze the following quote from Dr. Volumnia Gaul from 'Ballad of Songbirds and Snakes': 'There is a point to everything or nothing at all, depending on your worldview.'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "passing column names as 'ground_truths' is deprecated and will be removed in the next version, please use 'ground_truth' instead. Note that `ground_truth` should be of type string and not Sequence[string] like `ground_truths`\n",
      "Evaluating:   2%|▏         | 1/54 [00:01<01:15,  1.43s/it]Runner in Executor raised an exception\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400, 'innererror': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_result': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'low'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': True, 'severity': 'medium'}}}}}\n",
      "Runner in Executor raised an exception\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400, 'innererror': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_result': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': True, 'severity': 'medium'}, 'violence': {'filtered': False, 'severity': 'safe'}}}}}\n",
      "Evaluating:  20%|██        | 11/54 [00:01<00:05,  8.20it/s]Runner in Executor raised an exception\n",
      "TypeError: expected string or buffer\n",
      "Evaluating: 100%|██████████| 54/54 [00:06<00:00,  8.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average score is: 0.7419127592786244\n",
      "BM25\n",
      "  System  Faithfulness  Answer Relevancy  Context Precision  Context Recall  \\\n",
      "0   BM25      0.851285          0.577793           0.761905        0.880525   \n",
      "\n",
      "   Answer Similarity  Answer Correctness   Average  \n",
      "0           0.600237            0.779732  0.741913  \n"
     ]
    }
   ],
   "source": [
    "retriever_bm25 = BM25Retriever.from_documents(chunks_500,search_kwargs = ({\"k\": 5}))\n",
    "result_bm25, results_df = run_and_evaluate(f\"BM25\", retriever_bm25, prompt, llm, results_df)\n",
    "print(\"BM25\")\n",
    "print(result_bm25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ensambler - Hybrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever_500 = db_k.as_retriever(search_kwargs = ({\"k\": 5}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "passing column names as 'ground_truths' is deprecated and will be removed in the next version, please use 'ground_truth' instead. Note that `ground_truth` should be of type string and not Sequence[string] like `ground_truths`\n",
      "Evaluating: 100%|██████████| 54/54 [00:07<00:00,  7.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average score is: 0.778723471794867\n",
      "Ensambler\n",
      "        System  Faithfulness  Answer Relevancy  Context Precision  \\\n",
      "0  Ensambler 1        0.8625          0.896181           0.641499   \n",
      "\n",
      "   Context Recall  Answer Similarity  Answer Correctness   Average  \n",
      "0        0.712963           0.883615            0.675582  0.778723  \n"
     ]
    }
   ],
   "source": [
    "ensemble_retriever_1 = EnsembleRetriever(retrievers=[retriever_bm25, retriever_500], weights=[0.75, 0.25])\n",
    "result_ensemble1, results_df = run_and_evaluate(f\"Ensambler 1\", ensemble_retriever_1, prompt, llm, results_df)\n",
    "print(\"Ensambler\")\n",
    "print(result_ensemble1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "passing column names as 'ground_truths' is deprecated and will be removed in the next version, please use 'ground_truth' instead. Note that `ground_truth` should be of type string and not Sequence[string] like `ground_truths`\n",
      "Evaluating: 100%|██████████| 54/54 [00:07<00:00,  7.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average score is: 0.8248493896414025\n",
      "Ensambler\n",
      "        System  Faithfulness  Answer Relevancy  Context Precision  \\\n",
      "0  Ensambler 2      0.911111          0.899975           0.631411   \n",
      "\n",
      "   Context Recall  Answer Similarity  Answer Correctness   Average  \n",
      "0        0.944444           0.883797            0.678357  0.824849  \n"
     ]
    }
   ],
   "source": [
    "ensemble_retriever_2 = EnsembleRetriever(retrievers=[retriever_bm25, retriever_500], weights=[0.5, 0.5])\n",
    "result_ensemble2, results_df = run_and_evaluate(f\"Ensambler 2\", ensemble_retriever_2, prompt, llm, results_df)\n",
    "print(\"Ensambler\")\n",
    "print(result_ensemble2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400, 'innererror': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_result': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': True, 'severity': 'medium'}}}}}on the following question: Analyze the following quote from Dr. Volumnia Gaul from 'Ballad of Songbirds and Snakes': 'There is a point to everything or nothing at all, depending on your worldview.'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "passing column names as 'ground_truths' is deprecated and will be removed in the next version, please use 'ground_truth' instead. Note that `ground_truth` should be of type string and not Sequence[string] like `ground_truths`\n",
      "Evaluating:   2%|▏         | 1/54 [00:01<01:19,  1.50s/it]Runner in Executor raised an exception\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400, 'innererror': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_result': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'low'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': True, 'severity': 'medium'}}}}}\n",
      "Evaluating:  24%|██▍       | 13/54 [00:03<00:10,  4.09it/s]Runner in Executor raised an exception\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400, 'innererror': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_result': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': True, 'severity': 'medium'}, 'violence': {'filtered': False, 'severity': 'safe'}}}}}\n",
      "Runner in Executor raised an exception\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400, 'innererror': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_result': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': True, 'severity': 'medium'}}}}}\n",
      "Evaluating: 100%|██████████| 54/54 [00:08<00:00,  6.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average score is: 0.769417606058456\n",
      "Ensambler\n",
      "        System  Faithfulness  Answer Relevancy  Context Precision  \\\n",
      "0  Ensambler 3       0.82858          0.589649              0.975   \n",
      "\n",
      "   Context Recall  Answer Similarity  Answer Correctness   Average  \n",
      "0        0.784893            0.55125            0.887134  0.769418  \n"
     ]
    }
   ],
   "source": [
    "ensemble_retriever_3 = EnsembleRetriever(retrievers=[retriever_bm25, retriever_500], weights=[0.25,0.75])\n",
    "result_ensemble3, results_df = run_and_evaluate(f\"Ensambler 3\", ensemble_retriever_3, prompt, llm, results_df)\n",
    "print(\"Ensambler\")\n",
    "print(result_ensemble3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multi-stage - reranker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.environ[\"COHERE_API_KEY\"] = getpass.getpass(\"Cohere API Key:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "passing column names as 'ground_truths' is deprecated and will be removed in the next version, please use 'ground_truth' instead. Note that `ground_truth` should be of type string and not Sequence[string] like `ground_truths`\n",
      "Evaluating: 100%|██████████| 54/54 [00:08<00:00,  6.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reranker\n",
      "{'faithfulness': 0.8286, 'answer_relevancy': 0.8882, 'context_precision': 0.5185, 'context_recall': 0.7407, 'answer_similarity': 0.8663, 'answer_correctness': 0.6374}\n",
      "The average score is: 0.7466056282196497\n"
     ]
    }
   ],
   "source": [
    "# retriever_context = retriever_3\n",
    "# compressor = CohereRerank(top_n = 5)\n",
    "# compression_retriever = ContextualCompressionRetriever(\n",
    "#     base_compressor=compressor, base_retriever=retriever_context\n",
    "# )\n",
    "\n",
    "# result_compression = run_and_evaluate(compression_retriever, prompt, llm)\n",
    "# print(\"Reranker\")\n",
    "# print(result_compression)\n",
    "# avg_result_compression, dict_result_compression = dictionary(result_compression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "passing column names as 'ground_truths' is deprecated and will be removed in the next version, please use 'ground_truth' instead. Note that `ground_truth` should be of type string and not Sequence[string] like `ground_truths`\n",
      "Evaluating:   0%|          | 0/54 [00:00<?, ?it/s]Runner in Executor raised an exception\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400, 'innererror': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_result': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': True, 'severity': 'medium'}}}}}\n",
      "Evaluating: 100%|██████████| 54/54 [00:08<00:00,  6.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reranker\n",
      "{'faithfulness': 0.6468, 'answer_relevancy': 0.8313, 'context_precision': 0.6104, 'context_recall': 0.5648, 'answer_similarity': 0.8625, 'answer_correctness': 0.7789}\n",
      "The average score is: 0.7157937819391315\n"
     ]
    }
   ],
   "source": [
    "# retriever_context_more = retriever_500\n",
    "# compressor = CohereRerank(top_n = 5)\n",
    "# compression_retriever_more = ContextualCompressionRetriever(\n",
    "#     base_compressor=compressor, base_retriever=retriever_context_more\n",
    "# )\n",
    "\n",
    "# result_compression_more = run_and_evaluate(compression_retriever_more, prompt, llm)\n",
    "# print(\"Reranker\")\n",
    "# print(result_compression_more)\n",
    "# avg_result_compression_more, dict_result_compression_more = dictionary(result_compression_more)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### creating context by remaking the query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "template_context = \"Generate a search query to fetch the relevant documents using the user's {question}. Craft a query that specifically targets the keywords in the question. In the answer provide only the query.\"\n",
    "prompt_context = ChatPromptTemplate.from_template(template_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400, 'innererror': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_result': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': True, 'severity': 'medium'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}}}on the following question: Analyze this quote from 'Ballad of Songbirds and Snakes': '...at eighteen, the heir to the once-great house of Snow had nothing to live on but his wits.'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "passing column names as 'ground_truths' is deprecated and will be removed in the next version, please use 'ground_truth' instead. Note that `ground_truth` should be of type string and not Sequence[string] like `ground_truths`\n",
      "Evaluating:   0%|          | 0/54 [00:00<?, ?it/s]Runner in Executor raised an exception\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400, 'innererror': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_result': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': True, 'severity': 'medium'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}}}\n",
      "Evaluating:  20%|██        | 11/54 [00:02<00:09,  4.38it/s]Runner in Executor raised an exception\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400, 'innererror': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_result': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': True, 'severity': 'medium'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}}}\n",
      "Evaluating: 100%|██████████| 54/54 [00:06<00:00,  8.42it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'faithfulness': 0.8266, 'answer_relevancy': 0.6130, 'context_precision': 0.5875, 'context_recall': 0.5302, 'answer_similarity': 0.7671, 'answer_correctness': 0.5118}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers_final = []\n",
    "contexts_final = []\n",
    "llm_for_context =(\n",
    "    { \"question\": itemgetter(\"question\")}\n",
    "    | RunnablePassthrough()\n",
    "    | {\"response\": prompt_context | llm}\n",
    ")\n",
    "for query in questions:\n",
    "    response_check = llm_for_context.invoke({\"question\": query})\n",
    "    search_query = response_check[\"response\"].content\n",
    "    retrieval_augmented_qa_chain = (\n",
    "        {\"context\": itemgetter(\"context\"), \"question\": itemgetter(\"question\")}\n",
    "        | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
    "        | {\"response\": prompt | llm, \"context\": itemgetter(\"context\")}\n",
    ")\n",
    "    docs = retriever_500.get_relevant_documents(search_query)\n",
    "    formatted_docs = []\n",
    "    for doc in docs:\n",
    "        resulting_doc = doc.page_content\n",
    "        formatted_docs.append(resulting_doc)\n",
    "    try:  \n",
    "            response = retrieval_augmented_qa_chain.invoke({\"context\": formatted_docs, \"question\": query})\n",
    "            # Access the response content\n",
    "            answers_final.append(response[\"response\"].content)\n",
    "            contexts_final.append(formatted_docs)  \n",
    "    except Exception as e:  \n",
    "            print(f\"Warning: {e}\" + \"on the following question: \" + query)  \n",
    "            answers_final.append(\"No answer\")\n",
    "            contexts_final.append(formatted_docs)\n",
    "\n",
    "\n",
    "result_search_query = evaluation_rag(questions, answers_final, contexts_final, ground_truths)\n",
    "result_search_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average score is: 0.6393715733935755\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>System</th>\n",
       "      <th>Faithfulness</th>\n",
       "      <th>Answer Relevancy</th>\n",
       "      <th>Context Precision</th>\n",
       "      <th>Context Recall</th>\n",
       "      <th>Answer Similarity</th>\n",
       "      <th>Answer Correctness</th>\n",
       "      <th>Average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GPT-3.5</td>\n",
       "      <td>0.971429</td>\n",
       "      <td>0.745413</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.866096</td>\n",
       "      <td>0.660199</td>\n",
       "      <td>0.810784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GPT-4</td>\n",
       "      <td>0.942857</td>\n",
       "      <td>0.884441</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.860459</td>\n",
       "      <td>0.654768</td>\n",
       "      <td>0.835631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Naive</td>\n",
       "      <td>0.881621</td>\n",
       "      <td>0.726491</td>\n",
       "      <td>0.512500</td>\n",
       "      <td>0.693275</td>\n",
       "      <td>0.683565</td>\n",
       "      <td>0.715710</td>\n",
       "      <td>0.702194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Recursive</td>\n",
       "      <td>0.865996</td>\n",
       "      <td>0.729346</td>\n",
       "      <td>0.512500</td>\n",
       "      <td>0.580707</td>\n",
       "      <td>0.816281</td>\n",
       "      <td>0.789784</td>\n",
       "      <td>0.715769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Chunk 500, overlap 0%</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.884760</td>\n",
       "      <td>0.376543</td>\n",
       "      <td>0.435185</td>\n",
       "      <td>0.866883</td>\n",
       "      <td>0.664614</td>\n",
       "      <td>0.682442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Chunk 500, overlap 5%</td>\n",
       "      <td>0.680952</td>\n",
       "      <td>0.901854</td>\n",
       "      <td>0.441358</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.863189</td>\n",
       "      <td>0.652780</td>\n",
       "      <td>0.701133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Chunk 500, overlap 10%</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.885184</td>\n",
       "      <td>0.450617</td>\n",
       "      <td>0.592593</td>\n",
       "      <td>0.863726</td>\n",
       "      <td>0.662760</td>\n",
       "      <td>0.709147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Chunk 500, overlap 15%</td>\n",
       "      <td>0.826190</td>\n",
       "      <td>0.879043</td>\n",
       "      <td>0.645062</td>\n",
       "      <td>0.824074</td>\n",
       "      <td>0.869306</td>\n",
       "      <td>0.631235</td>\n",
       "      <td>0.779152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Chunk 500, overlap 20%</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.903706</td>\n",
       "      <td>0.506173</td>\n",
       "      <td>0.675926</td>\n",
       "      <td>0.872395</td>\n",
       "      <td>0.586756</td>\n",
       "      <td>0.709874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Chunk 1000, overlap 0%</td>\n",
       "      <td>0.834282</td>\n",
       "      <td>0.723396</td>\n",
       "      <td>0.487500</td>\n",
       "      <td>0.689591</td>\n",
       "      <td>0.780951</td>\n",
       "      <td>0.769929</td>\n",
       "      <td>0.714275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Chunk 1000, overlap 5%</td>\n",
       "      <td>0.859269</td>\n",
       "      <td>0.710329</td>\n",
       "      <td>0.520833</td>\n",
       "      <td>0.567662</td>\n",
       "      <td>0.789020</td>\n",
       "      <td>0.710835</td>\n",
       "      <td>0.692992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Chunk 1000, overlap 10%</td>\n",
       "      <td>0.833369</td>\n",
       "      <td>0.724186</td>\n",
       "      <td>0.472222</td>\n",
       "      <td>0.635688</td>\n",
       "      <td>0.677939</td>\n",
       "      <td>0.762695</td>\n",
       "      <td>0.684350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Chunk 1000, overlap 15%</td>\n",
       "      <td>0.809964</td>\n",
       "      <td>0.719308</td>\n",
       "      <td>0.519048</td>\n",
       "      <td>0.558069</td>\n",
       "      <td>0.735682</td>\n",
       "      <td>0.784538</td>\n",
       "      <td>0.687768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Chunk 1000, overlap 20%</td>\n",
       "      <td>0.808816</td>\n",
       "      <td>0.718937</td>\n",
       "      <td>0.380952</td>\n",
       "      <td>0.538053</td>\n",
       "      <td>0.763482</td>\n",
       "      <td>0.799512</td>\n",
       "      <td>0.668292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Chunk 2000, overlap 0%</td>\n",
       "      <td>0.788936</td>\n",
       "      <td>0.747135</td>\n",
       "      <td>0.470833</td>\n",
       "      <td>0.693106</td>\n",
       "      <td>0.660520</td>\n",
       "      <td>0.555794</td>\n",
       "      <td>0.652721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Chunk 2000, overlap 5%</td>\n",
       "      <td>0.819300</td>\n",
       "      <td>0.724491</td>\n",
       "      <td>0.537037</td>\n",
       "      <td>0.653868</td>\n",
       "      <td>0.765334</td>\n",
       "      <td>0.596272</td>\n",
       "      <td>0.682717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Chunk 2000, overlap 10%</td>\n",
       "      <td>0.894395</td>\n",
       "      <td>0.730272</td>\n",
       "      <td>0.470833</td>\n",
       "      <td>0.560752</td>\n",
       "      <td>0.678642</td>\n",
       "      <td>0.799907</td>\n",
       "      <td>0.689133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Chunk 2000, overlap 15%</td>\n",
       "      <td>0.762022</td>\n",
       "      <td>0.723838</td>\n",
       "      <td>0.442857</td>\n",
       "      <td>0.579288</td>\n",
       "      <td>0.733706</td>\n",
       "      <td>0.766451</td>\n",
       "      <td>0.668027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Chunk 2000, overlap 20%</td>\n",
       "      <td>0.859328</td>\n",
       "      <td>0.730800</td>\n",
       "      <td>0.470833</td>\n",
       "      <td>0.675626</td>\n",
       "      <td>0.699462</td>\n",
       "      <td>0.725637</td>\n",
       "      <td>0.693614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Chunk 3000, overlap 0%</td>\n",
       "      <td>0.864944</td>\n",
       "      <td>0.729709</td>\n",
       "      <td>0.637500</td>\n",
       "      <td>0.689309</td>\n",
       "      <td>0.733664</td>\n",
       "      <td>0.805561</td>\n",
       "      <td>0.743448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Chunk 3000, overlap 5%</td>\n",
       "      <td>0.862070</td>\n",
       "      <td>0.747021</td>\n",
       "      <td>0.464286</td>\n",
       "      <td>0.729848</td>\n",
       "      <td>0.670983</td>\n",
       "      <td>0.641577</td>\n",
       "      <td>0.685964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Chunk 3000, overlap 10%</td>\n",
       "      <td>0.863684</td>\n",
       "      <td>0.711061</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.579188</td>\n",
       "      <td>0.677831</td>\n",
       "      <td>0.758354</td>\n",
       "      <td>0.681686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Chunk 3000, overlap 15%</td>\n",
       "      <td>0.884277</td>\n",
       "      <td>0.744819</td>\n",
       "      <td>0.414583</td>\n",
       "      <td>0.577723</td>\n",
       "      <td>0.736018</td>\n",
       "      <td>0.577863</td>\n",
       "      <td>0.655881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Chunk 3000, overlap 20%</td>\n",
       "      <td>0.877549</td>\n",
       "      <td>0.747584</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.747531</td>\n",
       "      <td>0.724320</td>\n",
       "      <td>0.648772</td>\n",
       "      <td>0.700682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Chunk size 500, overlap 15%, K=2</td>\n",
       "      <td>0.740000</td>\n",
       "      <td>0.880395</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.729630</td>\n",
       "      <td>0.870647</td>\n",
       "      <td>0.659500</td>\n",
       "      <td>0.757806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Chunk size 500, overlap 15%, K=3</td>\n",
       "      <td>0.750577</td>\n",
       "      <td>0.806049</td>\n",
       "      <td>0.775391</td>\n",
       "      <td>0.453704</td>\n",
       "      <td>0.804792</td>\n",
       "      <td>0.757130</td>\n",
       "      <td>0.724607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Chunk size 500, overlap 15%, K=5</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.905295</td>\n",
       "      <td>0.636883</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.874627</td>\n",
       "      <td>0.631657</td>\n",
       "      <td>0.826595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Chunk size 500, overlap 15%, K=6</td>\n",
       "      <td>0.792857</td>\n",
       "      <td>0.897322</td>\n",
       "      <td>0.681821</td>\n",
       "      <td>0.675926</td>\n",
       "      <td>0.866473</td>\n",
       "      <td>0.624575</td>\n",
       "      <td>0.756496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Chunk size 500, overlap 15%, K=7</td>\n",
       "      <td>0.693972</td>\n",
       "      <td>0.747306</td>\n",
       "      <td>0.844508</td>\n",
       "      <td>0.625705</td>\n",
       "      <td>0.824804</td>\n",
       "      <td>0.771200</td>\n",
       "      <td>0.751249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Parent Retriever 1000-200</td>\n",
       "      <td>0.731250</td>\n",
       "      <td>0.582884</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.685185</td>\n",
       "      <td>0.862021</td>\n",
       "      <td>0.573332</td>\n",
       "      <td>0.646519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Parent Retriever 500-100</td>\n",
       "      <td>0.815535</td>\n",
       "      <td>0.880237</td>\n",
       "      <td>0.719369</td>\n",
       "      <td>0.648148</td>\n",
       "      <td>0.850717</td>\n",
       "      <td>0.738159</td>\n",
       "      <td>0.775361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Parent Retriever 1500-200</td>\n",
       "      <td>0.775000</td>\n",
       "      <td>0.792080</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.768519</td>\n",
       "      <td>0.869522</td>\n",
       "      <td>0.612883</td>\n",
       "      <td>0.710408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>MMR</td>\n",
       "      <td>0.792857</td>\n",
       "      <td>0.898714</td>\n",
       "      <td>0.738735</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.874188</td>\n",
       "      <td>0.649778</td>\n",
       "      <td>0.807193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>BM25</td>\n",
       "      <td>0.851285</td>\n",
       "      <td>0.577793</td>\n",
       "      <td>0.761905</td>\n",
       "      <td>0.880525</td>\n",
       "      <td>0.600237</td>\n",
       "      <td>0.779732</td>\n",
       "      <td>0.741913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Ensambler 1</td>\n",
       "      <td>0.862500</td>\n",
       "      <td>0.896181</td>\n",
       "      <td>0.641499</td>\n",
       "      <td>0.712963</td>\n",
       "      <td>0.883615</td>\n",
       "      <td>0.675582</td>\n",
       "      <td>0.778723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Ensambler 2</td>\n",
       "      <td>0.911111</td>\n",
       "      <td>0.899975</td>\n",
       "      <td>0.631411</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.883797</td>\n",
       "      <td>0.678357</td>\n",
       "      <td>0.824849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Ensambler 3</td>\n",
       "      <td>0.828580</td>\n",
       "      <td>0.589649</td>\n",
       "      <td>0.975000</td>\n",
       "      <td>0.784893</td>\n",
       "      <td>0.551250</td>\n",
       "      <td>0.887134</td>\n",
       "      <td>0.769418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Search query</td>\n",
       "      <td>0.826606</td>\n",
       "      <td>0.613022</td>\n",
       "      <td>0.587500</td>\n",
       "      <td>0.530187</td>\n",
       "      <td>0.767127</td>\n",
       "      <td>0.511787</td>\n",
       "      <td>0.639372</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              System  Faithfulness  Answer Relevancy  \\\n",
       "0                            GPT-3.5      0.971429          0.745413   \n",
       "1                              GPT-4      0.942857          0.884441   \n",
       "2                              Naive      0.881621          0.726491   \n",
       "3                          Recursive      0.865996          0.729346   \n",
       "4              Chunk 500, overlap 0%      0.866667          0.884760   \n",
       "5              Chunk 500, overlap 5%      0.680952          0.901854   \n",
       "6             Chunk 500, overlap 10%      0.800000          0.885184   \n",
       "7             Chunk 500, overlap 15%      0.826190          0.879043   \n",
       "8             Chunk 500, overlap 20%      0.714286          0.903706   \n",
       "9             Chunk 1000, overlap 0%      0.834282          0.723396   \n",
       "10            Chunk 1000, overlap 5%      0.859269          0.710329   \n",
       "11           Chunk 1000, overlap 10%      0.833369          0.724186   \n",
       "12           Chunk 1000, overlap 15%      0.809964          0.719308   \n",
       "13           Chunk 1000, overlap 20%      0.808816          0.718937   \n",
       "14            Chunk 2000, overlap 0%      0.788936          0.747135   \n",
       "15            Chunk 2000, overlap 5%      0.819300          0.724491   \n",
       "16           Chunk 2000, overlap 10%      0.894395          0.730272   \n",
       "17           Chunk 2000, overlap 15%      0.762022          0.723838   \n",
       "18           Chunk 2000, overlap 20%      0.859328          0.730800   \n",
       "19            Chunk 3000, overlap 0%      0.864944          0.729709   \n",
       "20            Chunk 3000, overlap 5%      0.862070          0.747021   \n",
       "21           Chunk 3000, overlap 10%      0.863684          0.711061   \n",
       "22           Chunk 3000, overlap 15%      0.884277          0.744819   \n",
       "23           Chunk 3000, overlap 20%      0.877549          0.747584   \n",
       "24  Chunk size 500, overlap 15%, K=2      0.740000          0.880395   \n",
       "25  Chunk size 500, overlap 15%, K=3      0.750577          0.806049   \n",
       "26  Chunk size 500, overlap 15%, K=5      0.966667          0.905295   \n",
       "27  Chunk size 500, overlap 15%, K=6      0.792857          0.897322   \n",
       "28  Chunk size 500, overlap 15%, K=7      0.693972          0.747306   \n",
       "29         Parent Retriever 1000-200      0.731250          0.582884   \n",
       "30          Parent Retriever 500-100      0.815535          0.880237   \n",
       "31         Parent Retriever 1500-200      0.775000          0.792080   \n",
       "32                               MMR      0.792857          0.898714   \n",
       "33                              BM25      0.851285          0.577793   \n",
       "34                       Ensambler 1      0.862500          0.896181   \n",
       "35                       Ensambler 2      0.911111          0.899975   \n",
       "36                       Ensambler 3      0.828580          0.589649   \n",
       "37                      Search query      0.826606          0.613022   \n",
       "\n",
       "    Context Precision  Context Recall  Answer Similarity  Answer Correctness  \\\n",
       "0                 NaN             NaN           0.866096            0.660199   \n",
       "1                 NaN             NaN           0.860459            0.654768   \n",
       "2            0.512500        0.693275           0.683565            0.715710   \n",
       "3            0.512500        0.580707           0.816281            0.789784   \n",
       "4            0.376543        0.435185           0.866883            0.664614   \n",
       "5            0.441358        0.666667           0.863189            0.652780   \n",
       "6            0.450617        0.592593           0.863726            0.662760   \n",
       "7            0.645062        0.824074           0.869306            0.631235   \n",
       "8            0.506173        0.675926           0.872395            0.586756   \n",
       "9            0.487500        0.689591           0.780951            0.769929   \n",
       "10           0.520833        0.567662           0.789020            0.710835   \n",
       "11           0.472222        0.635688           0.677939            0.762695   \n",
       "12           0.519048        0.558069           0.735682            0.784538   \n",
       "13           0.380952        0.538053           0.763482            0.799512   \n",
       "14           0.470833        0.693106           0.660520            0.555794   \n",
       "15           0.537037        0.653868           0.765334            0.596272   \n",
       "16           0.470833        0.560752           0.678642            0.799907   \n",
       "17           0.442857        0.579288           0.733706            0.766451   \n",
       "18           0.470833        0.675626           0.699462            0.725637   \n",
       "19           0.637500        0.689309           0.733664            0.805561   \n",
       "20           0.464286        0.729848           0.670983            0.641577   \n",
       "21           0.500000        0.579188           0.677831            0.758354   \n",
       "22           0.414583        0.577723           0.736018            0.577863   \n",
       "23           0.458333        0.747531           0.724320            0.648772   \n",
       "24           0.666667        0.729630           0.870647            0.659500   \n",
       "25           0.775391        0.453704           0.804792            0.757130   \n",
       "26           0.636883        0.944444           0.874627            0.631657   \n",
       "27           0.681821        0.675926           0.866473            0.624575   \n",
       "28           0.844508        0.625705           0.824804            0.771200   \n",
       "29           0.444444        0.685185           0.862021            0.573332   \n",
       "30           0.719369        0.648148           0.850717            0.738159   \n",
       "31           0.444444        0.768519           0.869522            0.612883   \n",
       "32           0.738735        0.888889           0.874188            0.649778   \n",
       "33           0.761905        0.880525           0.600237            0.779732   \n",
       "34           0.641499        0.712963           0.883615            0.675582   \n",
       "35           0.631411        0.944444           0.883797            0.678357   \n",
       "36           0.975000        0.784893           0.551250            0.887134   \n",
       "37           0.587500        0.530187           0.767127            0.511787   \n",
       "\n",
       "     Average  \n",
       "0   0.810784  \n",
       "1   0.835631  \n",
       "2   0.702194  \n",
       "3   0.715769  \n",
       "4   0.682442  \n",
       "5   0.701133  \n",
       "6   0.709147  \n",
       "7   0.779152  \n",
       "8   0.709874  \n",
       "9   0.714275  \n",
       "10  0.692992  \n",
       "11  0.684350  \n",
       "12  0.687768  \n",
       "13  0.668292  \n",
       "14  0.652721  \n",
       "15  0.682717  \n",
       "16  0.689133  \n",
       "17  0.668027  \n",
       "18  0.693614  \n",
       "19  0.743448  \n",
       "20  0.685964  \n",
       "21  0.681686  \n",
       "22  0.655881  \n",
       "23  0.700682  \n",
       "24  0.757806  \n",
       "25  0.724607  \n",
       "26  0.826595  \n",
       "27  0.756496  \n",
       "28  0.751249  \n",
       "29  0.646519  \n",
       "30  0.775361  \n",
       "31  0.710408  \n",
       "32  0.807193  \n",
       "33  0.741913  \n",
       "34  0.778723  \n",
       "35  0.824849  \n",
       "36  0.769418  \n",
       "37  0.639372  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average = dictionary(result_search_query)\n",
    "    # Create a dictionary to store the results\n",
    "system_results = {\n",
    "        \"System\": \"Search query\",\n",
    "        \"Faithfulness\": result_search_query[\"faithfulness\"],\n",
    "        \"Answer Relevancy\": result_search_query[\"answer_relevancy\"],\n",
    "        \"Context Precision\": result_search_query[\"context_precision\"],\n",
    "        \"Context Recall\": result_search_query[\"context_recall\"],\n",
    "        \"Answer Similarity\": result_search_query[\"answer_similarity\"],\n",
    "        \"Answer Correctness\": result_search_query[\"answer_correctness\"],\n",
    "        \"Average\": average\n",
    "    }\n",
    "df_result_search_query = pd.DataFrame([system_results])\n",
    "results_df = pd.concat([results_df, df_result_search_query], ignore_index=True)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### change model to GPT-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "passing column names as 'ground_truths' is deprecated and will be removed in the next version, please use 'ground_truth' instead. Note that `ground_truth` should be of type string and not Sequence[string] like `ground_truths`\n",
      "Evaluating: 100%|██████████| 54/54 [00:07<00:00,  7.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average score is: 0.8268215027275688\n",
      "                                   System  Faithfulness  Answer Relevancy  \\\n",
      "0  Chunk size 500, overlap 15%, K=5- GPT4           1.0          0.745908   \n",
      "\n",
      "   Context Precision  Context Recall  Answer Similarity  Answer Correctness  \\\n",
      "0           0.658642        0.944444           0.886735            0.725199   \n",
      "\n",
      "    Average  \n",
      "0  0.826822  \n"
     ]
    }
   ],
   "source": [
    "results_retriever_500_gpt4, results_df = run_and_evaluate(f\"Chunk size 500, overlap 15%, K=5- GPT4\", retriever_500, prompt, llm_gpt4, results_df)\n",
    "print(results_retriever_500_gpt4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "passing column names as 'ground_truths' is deprecated and will be removed in the next version, please use 'ground_truth' instead. Note that `ground_truth` should be of type string and not Sequence[string] like `ground_truths`\n",
      "Evaluating:  17%|█▋        | 9/54 [00:01<00:06,  6.45it/s]Runner in Executor raised an exception\n",
      "TypeError: expected string or buffer\n",
      "Evaluating: 100%|██████████| 54/54 [00:08<00:00,  6.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average score is: 0.8358661838530649\n",
      "This is the new best value!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>System</th>\n",
       "      <th>Faithfulness</th>\n",
       "      <th>Answer Relevancy</th>\n",
       "      <th>Context Precision</th>\n",
       "      <th>Context Recall</th>\n",
       "      <th>Answer Similarity</th>\n",
       "      <th>Answer Correctness</th>\n",
       "      <th>Average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ensambler 2, GPT-4</td>\n",
       "      <td>0.947619</td>\n",
       "      <td>0.879338</td>\n",
       "      <td>0.689436</td>\n",
       "      <td>0.922222</td>\n",
       "      <td>0.892164</td>\n",
       "      <td>0.684419</td>\n",
       "      <td>0.835866</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               System  Faithfulness  Answer Relevancy  Context Precision  \\\n",
       "0  Ensambler 2, GPT-4      0.947619          0.879338           0.689436   \n",
       "\n",
       "   Context Recall  Answer Similarity  Answer Correctness   Average  \n",
       "0        0.922222           0.892164            0.684419  0.835866  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_ensemble2_gpt4, results_df = run_and_evaluate(f\"Ensambler 2, GPT-4\", ensemble_retriever_2, prompt, llm_gpt4, results_df)\n",
    "result_ensemble2_gpt4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "passing column names as 'ground_truths' is deprecated and will be removed in the next version, please use 'ground_truth' instead. Note that `ground_truth` should be of type string and not Sequence[string] like `ground_truths`\n",
      "Evaluating: 100%|██████████| 54/54 [00:32<00:00,  1.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average score is: 0.8482167245348319\n",
      "This is the new best value!\n",
      "     System  Faithfulness  Answer Relevancy  Context Precision  \\\n",
      "0  MMR GPT4           1.0          0.869917           0.738735   \n",
      "\n",
      "   Context Recall  Answer Similarity  Answer Correctness   Average  \n",
      "0        0.888889           0.871896            0.719863  0.848217  \n"
     ]
    }
   ],
   "source": [
    "result_mmr_gpt4, results_df = run_and_evaluate(f\"MMR GPT4\", retriever_mmr, prompt, llm_gpt4, results_df)\n",
    "print(result_mmr_gpt4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>System</th>\n",
       "      <th>Faithfulness</th>\n",
       "      <th>Answer Relevancy</th>\n",
       "      <th>Context Precision</th>\n",
       "      <th>Context Recall</th>\n",
       "      <th>Answer Similarity</th>\n",
       "      <th>Answer Correctness</th>\n",
       "      <th>Average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GPT-3.5</td>\n",
       "      <td>0.971429</td>\n",
       "      <td>0.745413</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.866096</td>\n",
       "      <td>0.660199</td>\n",
       "      <td>0.810784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Naive</td>\n",
       "      <td>0.881621</td>\n",
       "      <td>0.726491</td>\n",
       "      <td>0.512500</td>\n",
       "      <td>0.693275</td>\n",
       "      <td>0.683565</td>\n",
       "      <td>0.715710</td>\n",
       "      <td>0.702194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Recursive</td>\n",
       "      <td>0.865996</td>\n",
       "      <td>0.729346</td>\n",
       "      <td>0.512500</td>\n",
       "      <td>0.580707</td>\n",
       "      <td>0.816281</td>\n",
       "      <td>0.789784</td>\n",
       "      <td>0.715769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Chunk 500, overlap 0%</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.884760</td>\n",
       "      <td>0.376543</td>\n",
       "      <td>0.435185</td>\n",
       "      <td>0.866883</td>\n",
       "      <td>0.664614</td>\n",
       "      <td>0.682442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Chunk 500, overlap 5%</td>\n",
       "      <td>0.680952</td>\n",
       "      <td>0.901854</td>\n",
       "      <td>0.441358</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.863189</td>\n",
       "      <td>0.652780</td>\n",
       "      <td>0.701133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Chunk 500, overlap 10%</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.885184</td>\n",
       "      <td>0.450617</td>\n",
       "      <td>0.592593</td>\n",
       "      <td>0.863726</td>\n",
       "      <td>0.662760</td>\n",
       "      <td>0.709147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Chunk 500, overlap 15%</td>\n",
       "      <td>0.826190</td>\n",
       "      <td>0.879043</td>\n",
       "      <td>0.645062</td>\n",
       "      <td>0.824074</td>\n",
       "      <td>0.869306</td>\n",
       "      <td>0.631235</td>\n",
       "      <td>0.779152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Chunk 500, overlap 20%</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.903706</td>\n",
       "      <td>0.506173</td>\n",
       "      <td>0.675926</td>\n",
       "      <td>0.872395</td>\n",
       "      <td>0.586756</td>\n",
       "      <td>0.709874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Chunk 1000, overlap 0%</td>\n",
       "      <td>0.834282</td>\n",
       "      <td>0.723396</td>\n",
       "      <td>0.487500</td>\n",
       "      <td>0.689591</td>\n",
       "      <td>0.780951</td>\n",
       "      <td>0.769929</td>\n",
       "      <td>0.714275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Chunk 1000, overlap 5%</td>\n",
       "      <td>0.859269</td>\n",
       "      <td>0.710329</td>\n",
       "      <td>0.520833</td>\n",
       "      <td>0.567662</td>\n",
       "      <td>0.789020</td>\n",
       "      <td>0.710835</td>\n",
       "      <td>0.692992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Chunk 1000, overlap 10%</td>\n",
       "      <td>0.833369</td>\n",
       "      <td>0.724186</td>\n",
       "      <td>0.472222</td>\n",
       "      <td>0.635688</td>\n",
       "      <td>0.677939</td>\n",
       "      <td>0.762695</td>\n",
       "      <td>0.684350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Chunk 1000, overlap 15%</td>\n",
       "      <td>0.809964</td>\n",
       "      <td>0.719308</td>\n",
       "      <td>0.519048</td>\n",
       "      <td>0.558069</td>\n",
       "      <td>0.735682</td>\n",
       "      <td>0.784538</td>\n",
       "      <td>0.687768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Chunk 1000, overlap 20%</td>\n",
       "      <td>0.808816</td>\n",
       "      <td>0.718937</td>\n",
       "      <td>0.380952</td>\n",
       "      <td>0.538053</td>\n",
       "      <td>0.763482</td>\n",
       "      <td>0.799512</td>\n",
       "      <td>0.668292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Chunk 2000, overlap 0%</td>\n",
       "      <td>0.788936</td>\n",
       "      <td>0.747135</td>\n",
       "      <td>0.470833</td>\n",
       "      <td>0.693106</td>\n",
       "      <td>0.660520</td>\n",
       "      <td>0.555794</td>\n",
       "      <td>0.652721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Chunk 2000, overlap 5%</td>\n",
       "      <td>0.819300</td>\n",
       "      <td>0.724491</td>\n",
       "      <td>0.537037</td>\n",
       "      <td>0.653868</td>\n",
       "      <td>0.765334</td>\n",
       "      <td>0.596272</td>\n",
       "      <td>0.682717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Chunk 2000, overlap 10%</td>\n",
       "      <td>0.894395</td>\n",
       "      <td>0.730272</td>\n",
       "      <td>0.470833</td>\n",
       "      <td>0.560752</td>\n",
       "      <td>0.678642</td>\n",
       "      <td>0.799907</td>\n",
       "      <td>0.689133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Chunk 2000, overlap 15%</td>\n",
       "      <td>0.762022</td>\n",
       "      <td>0.723838</td>\n",
       "      <td>0.442857</td>\n",
       "      <td>0.579288</td>\n",
       "      <td>0.733706</td>\n",
       "      <td>0.766451</td>\n",
       "      <td>0.668027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Chunk 2000, overlap 20%</td>\n",
       "      <td>0.859328</td>\n",
       "      <td>0.730800</td>\n",
       "      <td>0.470833</td>\n",
       "      <td>0.675626</td>\n",
       "      <td>0.699462</td>\n",
       "      <td>0.725637</td>\n",
       "      <td>0.693614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Chunk 3000, overlap 0%</td>\n",
       "      <td>0.864944</td>\n",
       "      <td>0.729709</td>\n",
       "      <td>0.637500</td>\n",
       "      <td>0.689309</td>\n",
       "      <td>0.733664</td>\n",
       "      <td>0.805561</td>\n",
       "      <td>0.743448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Chunk 3000, overlap 5%</td>\n",
       "      <td>0.862070</td>\n",
       "      <td>0.747021</td>\n",
       "      <td>0.464286</td>\n",
       "      <td>0.729848</td>\n",
       "      <td>0.670983</td>\n",
       "      <td>0.641577</td>\n",
       "      <td>0.685964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Chunk 3000, overlap 10%</td>\n",
       "      <td>0.863684</td>\n",
       "      <td>0.711061</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.579188</td>\n",
       "      <td>0.677831</td>\n",
       "      <td>0.758354</td>\n",
       "      <td>0.681686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Chunk 3000, overlap 15%</td>\n",
       "      <td>0.884277</td>\n",
       "      <td>0.744819</td>\n",
       "      <td>0.414583</td>\n",
       "      <td>0.577723</td>\n",
       "      <td>0.736018</td>\n",
       "      <td>0.577863</td>\n",
       "      <td>0.655881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Chunk 3000, overlap 20%</td>\n",
       "      <td>0.877549</td>\n",
       "      <td>0.747584</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.747531</td>\n",
       "      <td>0.724320</td>\n",
       "      <td>0.648772</td>\n",
       "      <td>0.700682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Chunk size 500, overlap 15%, K=2</td>\n",
       "      <td>0.740000</td>\n",
       "      <td>0.880395</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.729630</td>\n",
       "      <td>0.870647</td>\n",
       "      <td>0.659500</td>\n",
       "      <td>0.757806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Chunk size 500, overlap 15%, K=3</td>\n",
       "      <td>0.750577</td>\n",
       "      <td>0.806049</td>\n",
       "      <td>0.775391</td>\n",
       "      <td>0.453704</td>\n",
       "      <td>0.804792</td>\n",
       "      <td>0.757130</td>\n",
       "      <td>0.724607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Chunk size 500, overlap 15%, K=5</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.905295</td>\n",
       "      <td>0.636883</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.874627</td>\n",
       "      <td>0.631657</td>\n",
       "      <td>0.826595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Chunk size 500, overlap 15%, K=6</td>\n",
       "      <td>0.792857</td>\n",
       "      <td>0.897322</td>\n",
       "      <td>0.681821</td>\n",
       "      <td>0.675926</td>\n",
       "      <td>0.866473</td>\n",
       "      <td>0.624575</td>\n",
       "      <td>0.756496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Chunk size 500, overlap 15%, K=7</td>\n",
       "      <td>0.693972</td>\n",
       "      <td>0.747306</td>\n",
       "      <td>0.844508</td>\n",
       "      <td>0.625705</td>\n",
       "      <td>0.824804</td>\n",
       "      <td>0.771200</td>\n",
       "      <td>0.751249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Parent Retriever 1000-200</td>\n",
       "      <td>0.731250</td>\n",
       "      <td>0.582884</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.685185</td>\n",
       "      <td>0.862021</td>\n",
       "      <td>0.573332</td>\n",
       "      <td>0.646519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Parent Retriever 500-100</td>\n",
       "      <td>0.815535</td>\n",
       "      <td>0.880237</td>\n",
       "      <td>0.719369</td>\n",
       "      <td>0.648148</td>\n",
       "      <td>0.850717</td>\n",
       "      <td>0.738159</td>\n",
       "      <td>0.775361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Parent Retriever 1500-200</td>\n",
       "      <td>0.775000</td>\n",
       "      <td>0.792080</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.768519</td>\n",
       "      <td>0.869522</td>\n",
       "      <td>0.612883</td>\n",
       "      <td>0.710408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>MMR</td>\n",
       "      <td>0.792857</td>\n",
       "      <td>0.898714</td>\n",
       "      <td>0.738735</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.874188</td>\n",
       "      <td>0.649778</td>\n",
       "      <td>0.807193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>BM25</td>\n",
       "      <td>0.851285</td>\n",
       "      <td>0.577793</td>\n",
       "      <td>0.761905</td>\n",
       "      <td>0.880525</td>\n",
       "      <td>0.600237</td>\n",
       "      <td>0.779732</td>\n",
       "      <td>0.741913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Ensambler 1</td>\n",
       "      <td>0.862500</td>\n",
       "      <td>0.896181</td>\n",
       "      <td>0.641499</td>\n",
       "      <td>0.712963</td>\n",
       "      <td>0.883615</td>\n",
       "      <td>0.675582</td>\n",
       "      <td>0.778723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Ensambler 2</td>\n",
       "      <td>0.911111</td>\n",
       "      <td>0.899975</td>\n",
       "      <td>0.631411</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.883797</td>\n",
       "      <td>0.678357</td>\n",
       "      <td>0.824849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Ensambler 3</td>\n",
       "      <td>0.828580</td>\n",
       "      <td>0.589649</td>\n",
       "      <td>0.975000</td>\n",
       "      <td>0.784893</td>\n",
       "      <td>0.551250</td>\n",
       "      <td>0.887134</td>\n",
       "      <td>0.769418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Search query</td>\n",
       "      <td>0.826606</td>\n",
       "      <td>0.613022</td>\n",
       "      <td>0.587500</td>\n",
       "      <td>0.530187</td>\n",
       "      <td>0.767127</td>\n",
       "      <td>0.511787</td>\n",
       "      <td>0.639372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Chunk size 500, overlap 15%, K=5- GPT4</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.745908</td>\n",
       "      <td>0.658642</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.886735</td>\n",
       "      <td>0.725199</td>\n",
       "      <td>0.826822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Ensambler 2, GPT-4</td>\n",
       "      <td>0.947619</td>\n",
       "      <td>0.879338</td>\n",
       "      <td>0.689436</td>\n",
       "      <td>0.922222</td>\n",
       "      <td>0.892164</td>\n",
       "      <td>0.684419</td>\n",
       "      <td>0.835866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>MMR GPT4</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.869917</td>\n",
       "      <td>0.738735</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.871896</td>\n",
       "      <td>0.719863</td>\n",
       "      <td>0.848217</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    System  Faithfulness  Answer Relevancy  \\\n",
       "0                                  GPT-3.5      0.971429          0.745413   \n",
       "2                                    Naive      0.881621          0.726491   \n",
       "3                                Recursive      0.865996          0.729346   \n",
       "4                    Chunk 500, overlap 0%      0.866667          0.884760   \n",
       "5                    Chunk 500, overlap 5%      0.680952          0.901854   \n",
       "6                   Chunk 500, overlap 10%      0.800000          0.885184   \n",
       "7                   Chunk 500, overlap 15%      0.826190          0.879043   \n",
       "8                   Chunk 500, overlap 20%      0.714286          0.903706   \n",
       "9                   Chunk 1000, overlap 0%      0.834282          0.723396   \n",
       "10                  Chunk 1000, overlap 5%      0.859269          0.710329   \n",
       "11                 Chunk 1000, overlap 10%      0.833369          0.724186   \n",
       "12                 Chunk 1000, overlap 15%      0.809964          0.719308   \n",
       "13                 Chunk 1000, overlap 20%      0.808816          0.718937   \n",
       "14                  Chunk 2000, overlap 0%      0.788936          0.747135   \n",
       "15                  Chunk 2000, overlap 5%      0.819300          0.724491   \n",
       "16                 Chunk 2000, overlap 10%      0.894395          0.730272   \n",
       "17                 Chunk 2000, overlap 15%      0.762022          0.723838   \n",
       "18                 Chunk 2000, overlap 20%      0.859328          0.730800   \n",
       "19                  Chunk 3000, overlap 0%      0.864944          0.729709   \n",
       "20                  Chunk 3000, overlap 5%      0.862070          0.747021   \n",
       "21                 Chunk 3000, overlap 10%      0.863684          0.711061   \n",
       "22                 Chunk 3000, overlap 15%      0.884277          0.744819   \n",
       "23                 Chunk 3000, overlap 20%      0.877549          0.747584   \n",
       "24        Chunk size 500, overlap 15%, K=2      0.740000          0.880395   \n",
       "25        Chunk size 500, overlap 15%, K=3      0.750577          0.806049   \n",
       "26        Chunk size 500, overlap 15%, K=5      0.966667          0.905295   \n",
       "27        Chunk size 500, overlap 15%, K=6      0.792857          0.897322   \n",
       "28        Chunk size 500, overlap 15%, K=7      0.693972          0.747306   \n",
       "29               Parent Retriever 1000-200      0.731250          0.582884   \n",
       "30                Parent Retriever 500-100      0.815535          0.880237   \n",
       "31               Parent Retriever 1500-200      0.775000          0.792080   \n",
       "32                                     MMR      0.792857          0.898714   \n",
       "33                                    BM25      0.851285          0.577793   \n",
       "34                             Ensambler 1      0.862500          0.896181   \n",
       "35                             Ensambler 2      0.911111          0.899975   \n",
       "36                             Ensambler 3      0.828580          0.589649   \n",
       "37                            Search query      0.826606          0.613022   \n",
       "38  Chunk size 500, overlap 15%, K=5- GPT4      1.000000          0.745908   \n",
       "39                      Ensambler 2, GPT-4      0.947619          0.879338   \n",
       "40                                MMR GPT4      1.000000          0.869917   \n",
       "\n",
       "    Context Precision  Context Recall  Answer Similarity  Answer Correctness  \\\n",
       "0                 NaN             NaN           0.866096            0.660199   \n",
       "2            0.512500        0.693275           0.683565            0.715710   \n",
       "3            0.512500        0.580707           0.816281            0.789784   \n",
       "4            0.376543        0.435185           0.866883            0.664614   \n",
       "5            0.441358        0.666667           0.863189            0.652780   \n",
       "6            0.450617        0.592593           0.863726            0.662760   \n",
       "7            0.645062        0.824074           0.869306            0.631235   \n",
       "8            0.506173        0.675926           0.872395            0.586756   \n",
       "9            0.487500        0.689591           0.780951            0.769929   \n",
       "10           0.520833        0.567662           0.789020            0.710835   \n",
       "11           0.472222        0.635688           0.677939            0.762695   \n",
       "12           0.519048        0.558069           0.735682            0.784538   \n",
       "13           0.380952        0.538053           0.763482            0.799512   \n",
       "14           0.470833        0.693106           0.660520            0.555794   \n",
       "15           0.537037        0.653868           0.765334            0.596272   \n",
       "16           0.470833        0.560752           0.678642            0.799907   \n",
       "17           0.442857        0.579288           0.733706            0.766451   \n",
       "18           0.470833        0.675626           0.699462            0.725637   \n",
       "19           0.637500        0.689309           0.733664            0.805561   \n",
       "20           0.464286        0.729848           0.670983            0.641577   \n",
       "21           0.500000        0.579188           0.677831            0.758354   \n",
       "22           0.414583        0.577723           0.736018            0.577863   \n",
       "23           0.458333        0.747531           0.724320            0.648772   \n",
       "24           0.666667        0.729630           0.870647            0.659500   \n",
       "25           0.775391        0.453704           0.804792            0.757130   \n",
       "26           0.636883        0.944444           0.874627            0.631657   \n",
       "27           0.681821        0.675926           0.866473            0.624575   \n",
       "28           0.844508        0.625705           0.824804            0.771200   \n",
       "29           0.444444        0.685185           0.862021            0.573332   \n",
       "30           0.719369        0.648148           0.850717            0.738159   \n",
       "31           0.444444        0.768519           0.869522            0.612883   \n",
       "32           0.738735        0.888889           0.874188            0.649778   \n",
       "33           0.761905        0.880525           0.600237            0.779732   \n",
       "34           0.641499        0.712963           0.883615            0.675582   \n",
       "35           0.631411        0.944444           0.883797            0.678357   \n",
       "36           0.975000        0.784893           0.551250            0.887134   \n",
       "37           0.587500        0.530187           0.767127            0.511787   \n",
       "38           0.658642        0.944444           0.886735            0.725199   \n",
       "39           0.689436        0.922222           0.892164            0.684419   \n",
       "40           0.738735        0.888889           0.871896            0.719863   \n",
       "\n",
       "     Average  \n",
       "0   0.810784  \n",
       "2   0.702194  \n",
       "3   0.715769  \n",
       "4   0.682442  \n",
       "5   0.701133  \n",
       "6   0.709147  \n",
       "7   0.779152  \n",
       "8   0.709874  \n",
       "9   0.714275  \n",
       "10  0.692992  \n",
       "11  0.684350  \n",
       "12  0.687768  \n",
       "13  0.668292  \n",
       "14  0.652721  \n",
       "15  0.682717  \n",
       "16  0.689133  \n",
       "17  0.668027  \n",
       "18  0.693614  \n",
       "19  0.743448  \n",
       "20  0.685964  \n",
       "21  0.681686  \n",
       "22  0.655881  \n",
       "23  0.700682  \n",
       "24  0.757806  \n",
       "25  0.724607  \n",
       "26  0.826595  \n",
       "27  0.756496  \n",
       "28  0.751249  \n",
       "29  0.646519  \n",
       "30  0.775361  \n",
       "31  0.710408  \n",
       "32  0.807193  \n",
       "33  0.741913  \n",
       "34  0.778723  \n",
       "35  0.824849  \n",
       "36  0.769418  \n",
       "37  0.639372  \n",
       "38  0.826822  \n",
       "39  0.835866  \n",
       "40  0.848217  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df = results_df[results_df['System'] != 'GPT-4']\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.to_csv(f\"../ballad/results/results_report.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
