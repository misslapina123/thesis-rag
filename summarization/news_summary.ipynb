{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dotenv\n",
    "from langchain.text_splitter import CharacterTextSplitter, RecursiveCharacterTextSplitter\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.document_loaders import DirectoryLoader\n",
    "from langchain_openai import AzureOpenAIEmbeddings\n",
    "dotenv.load_dotenv()\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from ragas import evaluate\n",
    "from ragas.metrics import (\n",
    "    faithfulness,\n",
    "    answer_relevancy,\n",
    "    context_recall,\n",
    "    context_precision,\n",
    "    answer_similarity,\n",
    "    answer_correctness,\n",
    ")\n",
    "from datasets import Dataset\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "from operator import itemgetter\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "import os\n",
    "from langchain.retrievers import BM25Retriever\n",
    "from langchain.retrievers import EnsembleRetriever\n",
    "import getpass\n",
    "from langchain.retrievers.document_compressors import CohereRerank\n",
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "import sys\n",
    "sys.tracebacklimit = 0\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_API_KEY = os.environ.get(\"OPENAI_API_KEY\")\n",
    "OPENAI_API_VERSION = os.environ.get(\"OPENAI_API_VERSION\")\n",
    "AZURE_OPENAI_ENDPOINT = os.environ.get(\"AZURE_OPENAI_ENDPOINT\")\n",
    "OPENAI_MODEL = os.environ.get(\"OPENAI_MODEL\")\n",
    "OPENAI_DEPLOYMENT = os.environ.get(\"OPENAI_DEPLOYMENT\")\n",
    "EMBEDDING_MODEL = os.environ.get(\"EMBEDDING_MODEL\")\n",
    "EMBEDDING_DEPLOYMENT = os.environ.get(\"EMBEDDING_DEPLOYMENT\")\n",
    "OPENAI_MODEL_GPT4 = os.environ.get(\"OPENAI_MODEL_GPT4\")\n",
    "OPENAI_DEPLOYMENT_GPT4 = os.environ.get(\"OPENAI_DEPLOYMENT_GPT4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_client = AzureOpenAIEmbeddings(\n",
    "    azure_deployment=EMBEDDING_DEPLOYMENT,\n",
    "    openai_api_version=OPENAI_API_VERSION)\n",
    "llm = AzureChatOpenAI(model_name=OPENAI_MODEL, azure_deployment=OPENAI_DEPLOYMENT,temperature=0)\n",
    "llm_gpt4 = AzureChatOpenAI(model_name=OPENAI_MODEL_GPT4, azure_deployment=OPENAI_DEPLOYMENT_GPT4,temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation_llm(questions, answers, contexts, ground_truths):\n",
    "    data = {\n",
    "        \"question\": questions,\n",
    "        \"answer\": answers,\n",
    "        \"contexts\": contexts,\n",
    "        \"ground_truths\": ground_truths\n",
    "    }\n",
    "    dataset = Dataset.from_dict(data)\n",
    "    azure_configs = {\n",
    "        \"base_url\": AZURE_OPENAI_ENDPOINT,\n",
    "        \"model_deployment\": OPENAI_DEPLOYMENT,\n",
    "        \"model_name\": OPENAI_MODEL,\n",
    "        \"embedding_deployment\": EMBEDDING_DEPLOYMENT,\n",
    "        \"embedding_name\": EMBEDDING_MODEL,  \n",
    "    }\n",
    "\n",
    "    azure_model = AzureChatOpenAI(\n",
    "        openai_api_version=OPENAI_API_VERSION,\n",
    "        azure_endpoint=azure_configs[\"base_url\"],\n",
    "        azure_deployment=azure_configs[\"model_deployment\"],\n",
    "        model=azure_configs[\"model_name\"],\n",
    "        validate_base_url=False,\n",
    "    )\n",
    "\n",
    "    azure_embeddings = AzureOpenAIEmbeddings(\n",
    "        openai_api_version=OPENAI_API_VERSION,\n",
    "        azure_endpoint=azure_configs[\"base_url\"],\n",
    "        azure_deployment=azure_configs[\"embedding_deployment\"],\n",
    "        model=azure_configs[\"embedding_name\"],\n",
    "    )\n",
    "    result = evaluate(\n",
    "        dataset = dataset, \n",
    "        metrics=[\n",
    "            faithfulness,\n",
    "            answer_relevancy,\n",
    "            answer_similarity,\n",
    "            answer_correctness,\n",
    "        ], \n",
    "        llm=azure_model, \n",
    "        embeddings=azure_embeddings,\n",
    "    )\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation_rag(questions, answers, contexts, ground_truths):\n",
    "    data = {\n",
    "        \"question\": questions,\n",
    "        \"answer\": answers,\n",
    "        \"contexts\": contexts,\n",
    "        \"ground_truths\": ground_truths\n",
    "    }\n",
    "    dataset = Dataset.from_dict(data)\n",
    "    azure_configs = {\n",
    "        \"base_url\": AZURE_OPENAI_ENDPOINT,\n",
    "        \"model_deployment\": OPENAI_DEPLOYMENT,\n",
    "        \"model_name\": OPENAI_MODEL,\n",
    "        \"embedding_deployment\": EMBEDDING_DEPLOYMENT,\n",
    "        \"embedding_name\": EMBEDDING_MODEL,  # most likely\n",
    "    }\n",
    "\n",
    "    azure_model = AzureChatOpenAI(\n",
    "        openai_api_version=OPENAI_API_VERSION,\n",
    "        azure_endpoint=azure_configs[\"base_url\"],\n",
    "        azure_deployment=azure_configs[\"model_deployment\"],\n",
    "        model=azure_configs[\"model_name\"],\n",
    "        validate_base_url=False,\n",
    "    )\n",
    "\n",
    "    azure_embeddings = AzureOpenAIEmbeddings(\n",
    "        openai_api_version=OPENAI_API_VERSION,\n",
    "        azure_endpoint=azure_configs[\"base_url\"],\n",
    "        azure_deployment=azure_configs[\"embedding_deployment\"],\n",
    "        model=azure_configs[\"embedding_name\"],\n",
    "    )\n",
    "    result = evaluate(\n",
    "        dataset = dataset, \n",
    "        metrics=[\n",
    "            faithfulness,\n",
    "            answer_relevancy,\n",
    "            context_precision,\n",
    "            context_recall,\n",
    "            answer_similarity,\n",
    "            answer_correctness,\n",
    "        ], \n",
    "        llm=azure_model, \n",
    "        embeddings=azure_embeddings,\n",
    "        raise_exceptions=False,\n",
    "    )\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = [\n",
    "    \"What happened to Alexei Nivalny in February 2024?\",\n",
    "    \"What were the initial findings of the National Transportation Safety Board (NTSB) regarding the door blowout incident on an Alaska Airlines Boeing 737 Max 9, and how did Boeing respond to the report?\",\n",
    "    \"What is the current financial situation in Europe regarding support for Ukraine, and what potential challenges might arise in the next 12 months?\",\n",
    "    \"What is Prince William's stance on the Israel-Gaza conflict, and what key points did he emphasize during his statement?\",\n",
    "    \"What are the key details regarding the arrest of Daniela Klette, an alleged member of the Red Army Faction (RAF), after more than 30 years in hiding?\",\n",
    "    \"How does the entertainment industry, particularly Hollywood, respond to the introduction of OpenAI's Sora text-to-video generator, and what concerns and actions have been expressed by industry professionals?\",\n",
    "    \"What are the key reasons for the conflict between Israel and Hamas in Gaza?\",\n",
    "    \"What are some key factors influencing the upcoming 2024 US presidential election, especially in terms of the candidates' strategies, key battleground states, and significant issues?\",\n",
    "    \"How has Boeing responded to recent criticisms and safety concerns, and what steps has the company taken to address the identified issues in its safety culture and aircraft manufacturing processes?\",\n",
    "    \"What recent actions and statements by Kim Jong Un have raised concerns about the possibility of North Korea engaging in military conflict, and what factors do experts highlight as potential obstacles to such a war?\"\n",
    "    ]\n",
    "\n",
    "ground_truths = [\n",
    "    [\"Alexei Navalny died in his prison cell in Siberia on February 16. He was serving a 19-year sentence on charges widely seen as politically motivated. Navalny's colleague, Maria Pevchikh, claimed that he was about to be freed in a prisoner swap. The proposed exchange involved Navalny being exchanged for Vadim Krasikov, a Russian hitman serving a life sentence for murder in Germany. Two US citizens held in Russia were also reportedly part of the deal. However, Kremlin spokesperson Dmitry Peskov denied knowledge of such agreements. Maria Pevchikh stated that negotiations for the prisoner swap had been ongoing for two years and were in their final stage on February 15. Navalny's death occurred on February 16, with prison officials attributing it to him falling ill after a walk. Pevchikh claimed that Putin changed his mind about the deal at the last minute, and the Russian president 'could not tolerate Navalny being free.' The reasons behind Putin's potential agreement to the swap and subsequent change of mind remain unclear. Navalny's widow, Yulia, has accused Putin of killing her husband, and Western leaders have blamed Putin for Navalny's death. Investigations into Navalny's death were ongoing at the time of the provided text, and there were discussions of potential sanctions by the EU and the US on Russia following Navalny's death.\"],\n",
    "    [\"The National Transportation Safety Board (NTSB) conducted an investigation into the door blowout incident on an Alaska Airlines Boeing 737 Max 9. The initial findings revealed that four key bolts meant to secure the unused door to the fuselage were missing, leading to the door's detachment shortly after takeoff. Boeing accepted accountability for the incident, with its president, Dave Calhoun, acknowledging the need for improvement. Boeing outlined a comprehensive plan to strengthen quality and regain stakeholders' confidence, emphasizing increased inspections, documentation of door plug assembly, and additional scrutiny in the supply chain. Calhoun assured a commitment to transparency and collaboration with regulatory authorities in addressing safety concerns.\"],\n",
    "    [\"Europe is grappling with the question of how long it can sustain draining financial support for Ukraine, having spent over $100 billion since the crisis began. The war is deadlocked, and recent setbacks for Ukraine, coupled with delays in US financial aid approval, are causing concerns. As fatigue sets in and political pressure grows, there's uncertainty about continued funding, especially if the US pulls financial support. European officials are considering using frozen Russian assets for funding, but concerns about setting precedents and challenges in independently providing weapons make the situation complex. The next 12 months are crucial, with European elections approaching, and maintaining support for Ukraine is deemed essential, even if the US reduces its involvement.\"],\n",
    "    [\"Prince William expressed deep concern about the human cost of the conflict since the Hamas terrorist attack, called for an end to the fighting, emphasized the need for increased humanitarian support to Gaza, and urged the release of hostages. He highlighted the critical importance of aid delivery and acknowledged the severe humanitarian situation in the region. Additionally, Prince William emphasized the impact on civilians and expressed hope for a brighter future and permanent peace.\"],\n",
    "    [\"Daniela Klette, a 65-year-old alleged RAF member from the so-called third generation, was arrested in the Berlin district of Kreuzberg after three decades in hiding. She is accused of attempted murder and serious robberies, with charges dating back to the 1980s and 1990s. Klette was identified through fingerprints, did not resist arrest, and has been flown to Bremen for pre-trial detention. A second person, with unconfirmed identity, was also arrested. The arrest is considered a milestone in the fight against 'tterrorism,' with officials highlighting the persistence of pursuing criminals regardless of the time elapsed since their crimes.\"],\n",
    "    [\"The entertainment industry, including Hollywood, is cautiously reacting to OpenAI's Sora text-to-video generator. While some acknowledge the potential impact on job roles, others express concerns about the tool's current limitations, such as temporal consistency issues and artifacts. Filmmakers like Tyler Perry have taken action, delaying studio expansions due to AI advancements. Industry professionals are advocating for protections around the use of AI models, considering potential job redundancies. OpenAI, aware of these concerns, has expanded licensing agreements and expressed intentions to engage with policymakers, educators, and artists before making Sora publicly available. Concerns also include potential copyright issues and the generation of actors' likenesses without consent. The industry remains hopeful that it can adapt to AI innovations, emphasizing the irreplaceable role of the human creative mind.\"],\n",
    "    [\"The conflict between Israel and Hamas in Gaza stems from Hamas' desire to create an Islamic state, rejection of Israel's right to exist, and its justification for attacks based on perceived Israeli crimes against Palestinians. The recent escalation involves a series of Hamas attacks on Israel, leading to a significant military response and the ongoing hostage situation. The conflict has resulted in a high death toll, displacement of civilians, and severe humanitarian crises in Gaza.\"],\n",
    "    [\"The 2024 US presidential election is characterized by a unique rematch between Joe Biden and Donald Trump. Both candidates face challenges and vulnerabilities. Trump won the South Carolina Republican primary, strengthening his path to the GOP nomination. The election is expected to be decided in a few key states, such as Wisconsin, Pennsylvania, Michigan, Arizona, and Georgia. Economic factors, including positive indicators but lingering public concerns, play a role. The campaigns are likely to focus on issues like abortion and immigration, with Democrats emphasizing Trump's impact on abortion laws and Republicans highlighting immigration concerns. Other potential factors include crime rates, the environment, climate change, and foreign policy. The candidates' age, health, and the possibility of third-party candidates add uncertainty to the election landscape. Trump's legal challenges and the aftermath of the January 2021 Capitol attack could also influence public opinion.\"],\n",
    "    [\"Boeing has responded to recent criticisms and safety concerns by acknowledging accountability for incidents, such as the door blowout on an Alaska Airlines Boeing 737 Max 9. The company's president, Dave Calhoun, emphasized transparency and outlined a comprehensive plan to strengthen quality, including increased inspections, documentation of door plug assembly, and additional scrutiny in the supply chain. Boeing has also undergone organizational changes, with the departure of the head of the 737 program and the appointment of new leadership to enhance focus on safety and quality. Additionally, a recent FAA report highlighted major issues with Boeing's safety culture, and Boeing expressed support for the panel's review, acknowledging the need for continuous improvement in fostering a safety culture within the company.\"],\n",
    "    [\"Recent actions and statements by Kim Jong Un, including renouncing the goal of peaceful reunification with South Korea, intensifying nuclear threats, and mentioning South Korea as the 'principal enemy, have raised concerns about the potential for North Korea to initiate a military conflict. Experts point out factors such as the lack of support from China and Russia, North Korea's inferior conventional weapons, and doubts about Kim's willingness to risk his regime's stability as obstacles to a full-scale war. Despite increased tensions, some experts believe that provocations may be aimed at negotiation strategies or domestic stability rather than an imminent military attack.\"]\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\"System\", \"Faithfulness\", \"Answer Relevancy\", \"Context Precision\", \"Context Recall\", \"Answer Similarity\", \"Answer Correctness\"]\n",
    "results_df = pd.DataFrame(columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_average = 0\n",
    "def find_highest(average_score):\n",
    "    global max_average\n",
    "    if average_score > max_average:\n",
    "        max_average = average_score\n",
    "        print(\"This is the new best value!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dictionary(result):\n",
    "    dict_result = dict(result)\n",
    "    average_score = sum(dict_result.values()) / len(dict_result)\n",
    "    print(f\"The average score is: {average_score}\")\n",
    "    find_highest(average_score)\n",
    "    return average_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_system(system_name, questions, answers, contexts, ground_truths):\n",
    "    result = evaluation_rag(questions, answers, contexts, ground_truths)\n",
    "    average = dictionary(result)\n",
    "    # Create a dictionary to store the results\n",
    "    system_results = {\n",
    "        \"System\": system_name,\n",
    "        \"Faithfulness\": result[\"faithfulness\"],\n",
    "        \"Answer Relevancy\": result[\"answer_relevancy\"],\n",
    "        \"Context Precision\": result[\"context_precision\"],\n",
    "        \"Context Recall\": result[\"context_recall\"],\n",
    "        \"Answer Similarity\": result[\"answer_similarity\"],\n",
    "        \"Answer Correctness\": result[\"answer_correctness\"],\n",
    "        \"Average\": average\n",
    "    }\n",
    "    df_system_results = pd.DataFrame([system_results])\n",
    "    return df_system_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_LLM(system_name, questions, answers, contexts, ground_truths):\n",
    "    result = evaluation_rag(questions, answers, contexts, ground_truths)\n",
    "    average = dictionary(result)\n",
    "    # Create a dictionary to store the results\n",
    "    system_results = {\n",
    "        \"System\": system_name,\n",
    "        \"Faithfulness\": result[\"faithfulness\"],\n",
    "        \"Answer Relevancy\": result[\"answer_relevancy\"],\n",
    "        \"Context Precision\": np.nan,\n",
    "        \"Context Recall\": np.nan,\n",
    "        \"Answer Similarity\": result[\"answer_similarity\"],\n",
    "        \"Answer Correctness\": result[\"answer_correctness\"],\n",
    "        \"Average\": average\n",
    "    }\n",
    "    df_llm_results = pd.DataFrame([system_results])\n",
    "    return df_llm_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General answer by LLMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"{question}\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_chain =(\n",
    "    { \"question\": itemgetter(\"question\")}\n",
    "    | RunnablePassthrough()\n",
    "    | {\"response\": prompt | llm}\n",
    ")\n",
    "llm_chain_gpt4 =(\n",
    "    { \"question\": itemgetter(\"question\")}\n",
    "    | RunnablePassthrough()\n",
    "    | {\"response\": prompt | llm_gpt4}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "answers_llm = []\n",
    "contexts_llm = [[\"\"],[\"\"],[\"\"],[\"\"],[\"\"],[\"\"],[\"\"],[\"\"],[\"\"],[\"\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for query in questions:\n",
    "    response = llm_chain.invoke({\"question\": query})\n",
    "    answers_llm.append(response[\"response\"].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "passing column names as 'ground_truths' is deprecated and will be removed in the next version, please use 'ground_truth' instead. Note that `ground_truth` should be of type string and not Sequence[string] like `ground_truths`\n",
      "Evaluating: 100%|██████████| 60/60 [00:08<00:00,  6.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average score is: 0.6398844441439843\n",
      "    System  Faithfulness  Answer Relevancy  Context Precision  Context Recall  \\\n",
      "0  GPT-3.5       0.94709          0.463838                NaN             NaN   \n",
      "\n",
      "   Answer Similarity  Answer Correctness   Average  \n",
      "0           0.900371            0.468007  0.639884  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sigitalapina\\AppData\\Local\\Temp\\ipykernel_19264\\800954320.py:2: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  results_df = pd.concat([results_df, llm_results], ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "llm_results = evaluate_LLM(\"GPT-3.5\", questions, answers_llm, contexts_llm, ground_truths)\n",
    "results_df = pd.concat([results_df, llm_results], ignore_index=True)\n",
    "print(llm_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "passing column names as 'ground_truths' is deprecated and will be removed in the next version, please use 'ground_truth' instead. Note that `ground_truth` should be of type string and not Sequence[string] like `ground_truths`\n",
      "Evaluating: 100%|██████████| 60/60 [00:11<00:00,  5.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average score is: 0.6323262879939882\n",
      "  System  Faithfulness  Answer Relevancy  Context Precision  Context Recall  \\\n",
      "0  GPT-4           1.0          0.287687                NaN             NaN   \n",
      "\n",
      "   Answer Similarity  Answer Correctness   Average  \n",
      "0           0.909879            0.536392  0.632326  \n"
     ]
    }
   ],
   "source": [
    "answers_llm_gpt4 = []\n",
    "for query in questions:\n",
    "    response = llm_chain_gpt4.invoke({\"question\": query})\n",
    "    answers_llm_gpt4.append(response[\"response\"].content)\n",
    "llm_results_gpt4 = evaluate_LLM(\"GPT-4\",questions, answers_llm_gpt4, contexts_llm, ground_truths)\n",
    "results_df = pd.concat([results_df, llm_results_gpt4], ignore_index=True)\n",
    "print(llm_results_gpt4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>System</th>\n",
       "      <th>Faithfulness</th>\n",
       "      <th>Answer Relevancy</th>\n",
       "      <th>Context Precision</th>\n",
       "      <th>Context Recall</th>\n",
       "      <th>Answer Similarity</th>\n",
       "      <th>Answer Correctness</th>\n",
       "      <th>Average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GPT-3.5</td>\n",
       "      <td>0.94709</td>\n",
       "      <td>0.463838</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.900371</td>\n",
       "      <td>0.468007</td>\n",
       "      <td>0.639884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GPT-4</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.287687</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.909879</td>\n",
       "      <td>0.536392</td>\n",
       "      <td>0.632326</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    System  Faithfulness  Answer Relevancy  Context Precision  Context Recall  \\\n",
       "0  GPT-3.5       0.94709          0.463838                NaN             NaN   \n",
       "1    GPT-4       1.00000          0.287687                NaN             NaN   \n",
       "\n",
       "   Answer Similarity  Answer Correctness   Average  \n",
       "0           0.900371            0.468007  0.639884  \n",
       "1           0.909879            0.536392  0.632326  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieval_chain(prompt, retriever, llm):\n",
    "    retrieval_augmented_qa_chain = (\n",
    "        {\"context\": itemgetter(\"question\") | retriever, \"question\": itemgetter(\"question\")}\n",
    "        | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
    "        | {\"response\": prompt | llm, \"context\": itemgetter(\"context\")}\n",
    "    )\n",
    "    return retrieval_augmented_qa_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DirectoryLoader('../news', glob=\"./*.txt\", loader_cls=TextLoader)\n",
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THE FIRST TIME RUN THIS, AFTER RUN THE NEXT CELL\n",
    "text_splitter = CharacterTextSplitter()\n",
    "chunks = text_splitter.split_documents(documents)\n",
    "db_naive = Chroma.from_documents(chunks, embeddings_client, persist_directory = \"../news/vectordb/naive\")\n",
    "db_naive.persist()\n",
    "retriever_naive = db_naive.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_naive = Chroma(persist_directory = \"../news/vectordb/naive\", embedding_function=embeddings_client)\n",
    "retriever_naive = db_naive.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"{question}. \n",
    "Provided context {context}.\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "answers_naive = []\n",
    "contexts_naive = []\n",
    "for query in questions:\n",
    "    try:  \n",
    "        response = retrieval_chain(prompt, retriever_naive, llm).invoke({\"question\": query})\n",
    "        # Access the response content\n",
    "        answers_naive.append(response[\"response\"].content)\n",
    "        # Access the context content\n",
    "        context_content = [context.page_content for context in response[\"context\"]]\n",
    "        contexts_naive.append(context_content)  \n",
    "    except Exception as e:  \n",
    "        print(f\"Warning: {e}\" + \"on the following question: \" + query)  \n",
    "        answers_naive.append(\"No answer\")\n",
    "        context_full = retriever_naive.get_relevant_documents(query)\n",
    "        context_content = [context.page_content for context in context_full]\n",
    "        contexts_naive.append(context_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "passing column names as 'ground_truths' is deprecated and will be removed in the next version, please use 'ground_truth' instead. Note that `ground_truth` should be of type string and not Sequence[string] like `ground_truths`\n",
      "Evaluating: 100%|██████████| 60/60 [00:10<00:00,  5.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average score is: 0.9304607912730924\n",
      "This is the new best value!\n",
      "  System  Faithfulness  Answer Relevancy  Context Precision  Context Recall  \\\n",
      "0  Naive      0.966518           0.91753           0.983333           0.975   \n",
      "\n",
      "   Answer Similarity  Answer Correctness   Average  \n",
      "0           0.963399            0.776985  0.930461  \n"
     ]
    }
   ],
   "source": [
    "result_naive_rag = evaluate_system(\"Naive\", questions, answers_naive, contexts_naive, ground_truths)\n",
    "results_df = pd.concat([results_df, result_naive_rag], ignore_index=True)\n",
    "print(result_naive_rag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### recursive splitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THE FIRST TIME RUN THIS, AFTER RUN THE NEXT CELL\n",
    "text_splitter = text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder()\n",
    "chunks_r = text_splitter.split_documents(documents)\n",
    "db_basic = Chroma.from_documents(chunks_r, embeddings_client, persist_directory = \"../news/vectordb/recursive_basic\")\n",
    "db_basic.persist()\n",
    "retriever_basic = db_basic.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_basic = Chroma(persist_directory = \"../news/vectordb/recursive_basic\", embedding_function=embeddings_client)\n",
    "retriever_basic = db_basic.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "answers_recursive = []\n",
    "contexts_recursive = []\n",
    "for query in questions:\n",
    "    try:  \n",
    "        response = retrieval_chain(prompt, retriever_basic, llm).invoke({\"question\": query})\n",
    "        # Access the response content\n",
    "        answers_recursive.append(response[\"response\"].content)\n",
    "        # Access the context content\n",
    "        context_content = [context.page_content for context in response[\"context\"]]\n",
    "        contexts_recursive.append(context_content)  \n",
    "    except Exception as e:  \n",
    "        print(f\"Warning: {e}\" + \"on the following question: \" + query)  \n",
    "        answers_recursive.append(\"No answer\")\n",
    "        context_full = retriever_basic.get_relevant_documents(query)\n",
    "        context_content = [context.page_content for context in context_full]\n",
    "        contexts_recursive.append(context_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "passing column names as 'ground_truths' is deprecated and will be removed in the next version, please use 'ground_truth' instead. Note that `ground_truth` should be of type string and not Sequence[string] like `ground_truths`\n",
      "Evaluating: 100%|██████████| 60/60 [00:08<00:00,  6.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average score is: 0.8973359714366723\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>System</th>\n",
       "      <th>Faithfulness</th>\n",
       "      <th>Answer Relevancy</th>\n",
       "      <th>Context Precision</th>\n",
       "      <th>Context Recall</th>\n",
       "      <th>Answer Similarity</th>\n",
       "      <th>Answer Correctness</th>\n",
       "      <th>Average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Recursive</td>\n",
       "      <td>0.966518</td>\n",
       "      <td>0.737454</td>\n",
       "      <td>0.983333</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.963403</td>\n",
       "      <td>0.773308</td>\n",
       "      <td>0.897336</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      System  Faithfulness  Answer Relevancy  Context Precision  \\\n",
       "0  Recursive      0.966518          0.737454           0.983333   \n",
       "\n",
       "   Context Recall  Answer Similarity  Answer Correctness   Average  \n",
       "0            0.96           0.963403            0.773308  0.897336  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_recursive = evaluate_system(\"Recursive\", questions, answers_naive, contexts_naive, ground_truths)\n",
    "results_df = pd.concat([results_df, result_recursive], ignore_index=True)\n",
    "result_recursive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### chunk sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_and_evaluate(name, retriever, prompt, llm, results_df):\n",
    "    answers = []\n",
    "    contexts_extra = []\n",
    "\n",
    "    for query in questions:\n",
    "        try:  \n",
    "            response = retrieval_chain(prompt, retriever, llm).invoke({\"question\": query})\n",
    "            # Access the response content\n",
    "            answers.append(response[\"response\"].content)\n",
    "            # Access the context content\n",
    "            context_content = [context.page_content for context in response[\"context\"]]\n",
    "            contexts_extra.append(context_content)  \n",
    "        except Exception as e:  \n",
    "            print(f\"Warning: {e}\" + \"on the following question: \" + query)  \n",
    "            answers.append(\"No answer\")\n",
    "            context_full = retriever.get_relevant_documents(query)\n",
    "            context_content = [context.page_content for context in context_full]\n",
    "            contexts_extra.append(context_content)\n",
    "\n",
    "    result = evaluate_system(name, questions, answers, contexts_extra, ground_truths)\n",
    "    results_df = pd.concat([results_df, result], ignore_index=True)\n",
    "    return result, results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk size 500, overlap 0%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "passing column names as 'ground_truths' is deprecated and will be removed in the next version, please use 'ground_truth' instead. Note that `ground_truth` should be of type string and not Sequence[string] like `ground_truths`\n",
      "Evaluating: 100%|██████████| 60/60 [00:12<00:00,  4.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average score is: 0.9133206697764482\n",
      "CHUNK SIZE 500, 0% overlap:\n",
      "                  System  Faithfulness  Answer Relevancy  Context Precision  \\\n",
      "0  Chunk 500, overlap 0%      0.983333          0.925543           0.991667   \n",
      "\n",
      "   Context Recall  Answer Similarity  Answer Correctness   Average  \n",
      "0        0.946429           0.961035            0.671918  0.913321  \n",
      "Chunk size 500, overlap 5%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "passing column names as 'ground_truths' is deprecated and will be removed in the next version, please use 'ground_truth' instead. Note that `ground_truth` should be of type string and not Sequence[string] like `ground_truths`\n",
      "Evaluating: 100%|██████████| 60/60 [00:12<00:00,  4.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average score is: 0.9119826794772815\n",
      "CHUNK SIZE 500, 5% overlap:\n",
      "                  System  Faithfulness  Answer Relevancy  Context Precision  \\\n",
      "0  Chunk 500, overlap 5%      0.974603          0.932008           0.991667   \n",
      "\n",
      "   Context Recall  Answer Similarity  Answer Correctness   Average  \n",
      "0        0.902778           0.960365            0.710475  0.911983  \n",
      "Chunk size 500, overlap 10%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "passing column names as 'ground_truths' is deprecated and will be removed in the next version, please use 'ground_truth' instead. Note that `ground_truth` should be of type string and not Sequence[string] like `ground_truths`\n",
      "Evaluating: 100%|██████████| 60/60 [00:10<00:00,  5.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average score is: 0.8868214139392477\n",
      "CHUNK SIZE 500, 10% overlap:\n",
      "                   System  Faithfulness  Answer Relevancy  Context Precision  \\\n",
      "0  Chunk 500, overlap 10%      0.943386          0.807349               0.95   \n",
      "\n",
      "   Context Recall  Answer Similarity  Answer Correctness   Average  \n",
      "0        0.943333           0.962567            0.714292  0.886821  \n",
      "Chunk size 500, overlap 15%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "passing column names as 'ground_truths' is deprecated and will be removed in the next version, please use 'ground_truth' instead. Note that `ground_truth` should be of type string and not Sequence[string] like `ground_truths`\n",
      "Evaluating: 100%|██████████| 60/60 [00:09<00:00,  6.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average score is: 0.9086637065490365\n",
      "CHUNK SIZE 500, 15% overlap:\n",
      "                   System  Faithfulness  Answer Relevancy  Context Precision  \\\n",
      "0  Chunk 500, overlap 15%      0.982143          0.898565           0.963889   \n",
      "\n",
      "   Context Recall  Answer Similarity  Answer Correctness   Average  \n",
      "0        0.977778            0.96166            0.667948  0.908664  \n",
      "Chunk size 500, overlap 20%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "passing column names as 'ground_truths' is deprecated and will be removed in the next version, please use 'ground_truth' instead. Note that `ground_truth` should be of type string and not Sequence[string] like `ground_truths`\n",
      "Evaluating: 100%|██████████| 60/60 [00:08<00:00,  7.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average score is: 0.9072624385789081\n",
      "CHUNK SIZE 500, 20% overlap:\n",
      "                   System  Faithfulness  Answer Relevancy  Context Precision  \\\n",
      "0  Chunk 500, overlap 20%      0.954861          0.912232           0.955556   \n",
      "\n",
      "   Context Recall  Answer Similarity  Answer Correctness   Average  \n",
      "0        0.977778            0.96126            0.681888  0.907262  \n",
      "Chunk size 1000, overlap 0%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "passing column names as 'ground_truths' is deprecated and will be removed in the next version, please use 'ground_truth' instead. Note that `ground_truth` should be of type string and not Sequence[string] like `ground_truths`\n",
      "Evaluating:   0%|          | 0/60 [00:00<?, ?it/s]Task exception was never retrieved\n",
      "future: <Task finished name='Task-662' coro=<AsyncClient.aclose() done, defined at c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\httpx\\_client.py:2011> exception=RuntimeError('Event loop is closed')>\n",
      "RuntimeError: Event loop is closed\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-663' coro=<AsyncClient.aclose() done, defined at c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\httpx\\_client.py:2011> exception=RuntimeError('Event loop is closed')>\n",
      "RuntimeError: Event loop is closed\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-664' coro=<AsyncClient.aclose() done, defined at c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\httpx\\_client.py:2011> exception=RuntimeError('Event loop is closed')>\n",
      "RuntimeError: Event loop is closed\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-665' coro=<AsyncClient.aclose() done, defined at c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\httpx\\_client.py:2011> exception=RuntimeError('Event loop is closed')>\n",
      "RuntimeError: Event loop is closed\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-666' coro=<AsyncClient.aclose() done, defined at c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\httpx\\_client.py:2011> exception=RuntimeError('Event loop is closed')>\n",
      "RuntimeError: Event loop is closed\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-667' coro=<AsyncClient.aclose() done, defined at c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\httpx\\_client.py:2011> exception=RuntimeError('Event loop is closed')>\n",
      "RuntimeError: Event loop is closed\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-668' coro=<AsyncClient.aclose() done, defined at c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\httpx\\_client.py:2011> exception=RuntimeError('Event loop is closed')>\n",
      "RuntimeError: Event loop is closed\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-669' coro=<AsyncClient.aclose() done, defined at c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\httpx\\_client.py:2011> exception=RuntimeError('Event loop is closed')>\n",
      "RuntimeError: Event loop is closed\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-670' coro=<AsyncClient.aclose() done, defined at c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\httpx\\_client.py:2011> exception=RuntimeError('Event loop is closed')>\n",
      "RuntimeError: Event loop is closed\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-671' coro=<AsyncClient.aclose() done, defined at c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\httpx\\_client.py:2011> exception=RuntimeError('Event loop is closed')>\n",
      "RuntimeError: Event loop is closed\n",
      "Evaluating: 100%|██████████| 60/60 [00:10<00:00,  5.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average score is: 0.9250647005919422\n",
      "CHUNK SIZE 1000, 0% overlap:\n",
      "                   System  Faithfulness  Answer Relevancy  Context Precision  \\\n",
      "0  Chunk 1000, overlap 0%      0.987654          0.907493           0.983333   \n",
      "\n",
      "   Context Recall  Answer Similarity  Answer Correctness   Average  \n",
      "0           0.955           0.959331            0.757576  0.925065  \n",
      "Chunk size 1000, overlap 5%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "passing column names as 'ground_truths' is deprecated and will be removed in the next version, please use 'ground_truth' instead. Note that `ground_truth` should be of type string and not Sequence[string] like `ground_truths`\n",
      "Evaluating: 100%|██████████| 60/60 [00:11<00:00,  5.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average score is: 0.9118793657816106\n",
      "CHUNK SIZE 1000, 5% overlap:\n",
      "                   System  Faithfulness  Answer Relevancy  Context Precision  \\\n",
      "0  Chunk 1000, overlap 5%      0.984127          0.891685              0.975   \n",
      "\n",
      "   Context Recall  Answer Similarity  Answer Correctness   Average  \n",
      "0            0.94           0.961574             0.71889  0.911879  \n",
      "Chunk size 1000, overlap 10%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "passing column names as 'ground_truths' is deprecated and will be removed in the next version, please use 'ground_truth' instead. Note that `ground_truth` should be of type string and not Sequence[string] like `ground_truths`\n",
      "Evaluating: 100%|██████████| 60/60 [00:09<00:00,  6.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average score is: 0.9093015956435017\n",
      "CHUNK SIZE 1000, 10% overlap:\n",
      "                    System  Faithfulness  Answer Relevancy  Context Precision  \\\n",
      "0  Chunk 1000, overlap 10%      0.987654          0.889549           0.983333   \n",
      "\n",
      "   Context Recall  Answer Similarity  Answer Correctness   Average  \n",
      "0            0.94           0.961549            0.693724  0.909302  \n",
      "Chunk size 1000, overlap 15%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "passing column names as 'ground_truths' is deprecated and will be removed in the next version, please use 'ground_truth' instead. Note that `ground_truth` should be of type string and not Sequence[string] like `ground_truths`\n",
      "Evaluating: 100%|██████████| 60/60 [00:09<00:00,  6.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average score is: 0.9209129249333007\n",
      "CHUNK SIZE 1000, 15% overlap:\n",
      "                    System  Faithfulness  Answer Relevancy  Context Precision  \\\n",
      "0  Chunk 1000, overlap 15%      0.987654          0.900701           0.983333   \n",
      "\n",
      "   Context Recall  Answer Similarity  Answer Correctness   Average  \n",
      "0           0.955           0.962723            0.736066  0.920913  \n",
      "Chunk size 1000, overlap 20%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "passing column names as 'ground_truths' is deprecated and will be removed in the next version, please use 'ground_truth' instead. Note that `ground_truth` should be of type string and not Sequence[string] like `ground_truths`\n",
      "Evaluating: 100%|██████████| 60/60 [00:09<00:00,  6.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average score is: 0.9116297340988951\n",
      "CHUNK SIZE 1000, 20% overlap:\n",
      "                    System  Faithfulness  Answer Relevancy  Context Precision  \\\n",
      "0  Chunk 1000, overlap 20%      0.953086          0.937404           0.983333   \n",
      "\n",
      "   Context Recall  Answer Similarity  Answer Correctness  Average  \n",
      "0            0.94           0.962642            0.693313  0.91163  \n",
      "Chunk size 2000, overlap 0%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "passing column names as 'ground_truths' is deprecated and will be removed in the next version, please use 'ground_truth' instead. Note that `ground_truth` should be of type string and not Sequence[string] like `ground_truths`\n",
      "Evaluating:   0%|          | 0/60 [00:00<?, ?it/s]Task exception was never retrieved\n",
      "future: <Task finished name='Task-976' coro=<AsyncClient.aclose() done, defined at c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\httpx\\_client.py:2011> exception=RuntimeError('Event loop is closed')>\n",
      "RuntimeError: Event loop is closed\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-977' coro=<AsyncClient.aclose() done, defined at c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\httpx\\_client.py:2011> exception=RuntimeError('Event loop is closed')>\n",
      "RuntimeError: Event loop is closed\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-978' coro=<AsyncClient.aclose() done, defined at c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\httpx\\_client.py:2011> exception=RuntimeError('Event loop is closed')>\n",
      "RuntimeError: Event loop is closed\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-979' coro=<AsyncClient.aclose() done, defined at c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\httpx\\_client.py:2011> exception=RuntimeError('Event loop is closed')>\n",
      "RuntimeError: Event loop is closed\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-980' coro=<AsyncClient.aclose() done, defined at c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\httpx\\_client.py:2011> exception=RuntimeError('Event loop is closed')>\n",
      "RuntimeError: Event loop is closed\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-981' coro=<AsyncClient.aclose() done, defined at c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\httpx\\_client.py:2011> exception=RuntimeError('Event loop is closed')>\n",
      "RuntimeError: Event loop is closed\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-982' coro=<AsyncClient.aclose() done, defined at c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\httpx\\_client.py:2011> exception=RuntimeError('Event loop is closed')>\n",
      "RuntimeError: Event loop is closed\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-983' coro=<AsyncClient.aclose() done, defined at c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\httpx\\_client.py:2011> exception=RuntimeError('Event loop is closed')>\n",
      "RuntimeError: Event loop is closed\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-984' coro=<AsyncClient.aclose() done, defined at c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\httpx\\_client.py:2011> exception=RuntimeError('Event loop is closed')>\n",
      "RuntimeError: Event loop is closed\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-985' coro=<AsyncClient.aclose() done, defined at c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\httpx\\_client.py:2011> exception=RuntimeError('Event loop is closed')>\n",
      "RuntimeError: Event loop is closed\n",
      "Evaluating: 100%|██████████| 60/60 [00:10<00:00,  5.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average score is: 0.9136525045990239\n",
      "CHUNK SIZE 2000, 0% overlap:\n",
      "                   System  Faithfulness  Answer Relevancy  Context Precision  \\\n",
      "0  Chunk 2000, overlap 0%      0.949735          0.867421              0.975   \n",
      "\n",
      "   Context Recall  Answer Similarity  Answer Correctness   Average  \n",
      "0             1.0           0.963794            0.725964  0.913653  \n",
      "Chunk size 2000, overlap 5%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "passing column names as 'ground_truths' is deprecated and will be removed in the next version, please use 'ground_truth' instead. Note that `ground_truth` should be of type string and not Sequence[string] like `ground_truths`\n",
      "Evaluating: 100%|██████████| 60/60 [00:12<00:00,  4.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average score is: 0.9162885287561159\n",
      "CHUNK SIZE 2000, 5% overlap:\n",
      "                   System  Faithfulness  Answer Relevancy  Context Precision  \\\n",
      "0  Chunk 2000, overlap 5%      0.968254          0.876055           0.966667   \n",
      "\n",
      "   Context Recall  Answer Similarity  Answer Correctness   Average  \n",
      "0        0.971429           0.963941            0.751386  0.916289  \n",
      "Chunk size 2000, overlap 10%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "passing column names as 'ground_truths' is deprecated and will be removed in the next version, please use 'ground_truth' instead. Note that `ground_truth` should be of type string and not Sequence[string] like `ground_truths`\n",
      "Evaluating: 100%|██████████| 60/60 [00:10<00:00,  5.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average score is: 0.8974300761898079\n",
      "CHUNK SIZE 2000, 10% overlap:\n",
      "                    System  Faithfulness  Answer Relevancy  Context Precision  \\\n",
      "0  Chunk 2000, overlap 10%       0.96875          0.769901              0.975   \n",
      "\n",
      "   Context Recall  Answer Similarity  Answer Correctness  Average  \n",
      "0             1.0           0.964368            0.706562  0.89743  \n",
      "Chunk size 2000, overlap 15%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "passing column names as 'ground_truths' is deprecated and will be removed in the next version, please use 'ground_truth' instead. Note that `ground_truth` should be of type string and not Sequence[string] like `ground_truths`\n",
      "Evaluating: 100%|██████████| 60/60 [00:11<00:00,  5.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average score is: 0.8890887209203086\n",
      "CHUNK SIZE 2000, 15% overlap:\n",
      "                    System  Faithfulness  Answer Relevancy  Context Precision  \\\n",
      "0  Chunk 2000, overlap 15%      0.943452          0.781496           0.966667   \n",
      "\n",
      "   Context Recall  Answer Similarity  Answer Correctness   Average  \n",
      "0        0.983333           0.964392            0.695192  0.889089  \n",
      "Chunk size 2000, overlap 20%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "passing column names as 'ground_truths' is deprecated and will be removed in the next version, please use 'ground_truth' instead. Note that `ground_truth` should be of type string and not Sequence[string] like `ground_truths`\n",
      "Evaluating: 100%|██████████| 60/60 [00:12<00:00,  4.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average score is: 0.9138253337038399\n",
      "CHUNK SIZE 2000, 20% overlap:\n",
      "                    System  Faithfulness  Answer Relevancy  Context Precision  \\\n",
      "0  Chunk 2000, overlap 20%      0.964286           0.86897           0.966667   \n",
      "\n",
      "   Context Recall  Answer Similarity  Answer Correctness   Average  \n",
      "0             1.0           0.963397            0.719633  0.913825  \n",
      "Chunk size 3000, overlap 0%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "passing column names as 'ground_truths' is deprecated and will be removed in the next version, please use 'ground_truth' instead. Note that `ground_truth` should be of type string and not Sequence[string] like `ground_truths`\n",
      "Evaluating:   0%|          | 0/60 [00:00<?, ?it/s]Task exception was never retrieved\n",
      "future: <Task finished name='Task-1296' coro=<AsyncClient.aclose() done, defined at c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\httpx\\_client.py:2011> exception=RuntimeError('Event loop is closed')>\n",
      "RuntimeError: Event loop is closed\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1297' coro=<AsyncClient.aclose() done, defined at c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\httpx\\_client.py:2011> exception=RuntimeError('Event loop is closed')>\n",
      "RuntimeError: Event loop is closed\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1298' coro=<AsyncClient.aclose() done, defined at c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\httpx\\_client.py:2011> exception=RuntimeError('Event loop is closed')>\n",
      "RuntimeError: Event loop is closed\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1299' coro=<AsyncClient.aclose() done, defined at c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\httpx\\_client.py:2011> exception=RuntimeError('Event loop is closed')>\n",
      "RuntimeError: Event loop is closed\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1300' coro=<AsyncClient.aclose() done, defined at c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\httpx\\_client.py:2011> exception=RuntimeError('Event loop is closed')>\n",
      "RuntimeError: Event loop is closed\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1301' coro=<AsyncClient.aclose() done, defined at c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\httpx\\_client.py:2011> exception=RuntimeError('Event loop is closed')>\n",
      "RuntimeError: Event loop is closed\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1302' coro=<AsyncClient.aclose() done, defined at c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\httpx\\_client.py:2011> exception=RuntimeError('Event loop is closed')>\n",
      "RuntimeError: Event loop is closed\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1303' coro=<AsyncClient.aclose() done, defined at c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\httpx\\_client.py:2011> exception=RuntimeError('Event loop is closed')>\n",
      "RuntimeError: Event loop is closed\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1304' coro=<AsyncClient.aclose() done, defined at c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\httpx\\_client.py:2011> exception=RuntimeError('Event loop is closed')>\n",
      "RuntimeError: Event loop is closed\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1305' coro=<AsyncClient.aclose() done, defined at c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\httpx\\_client.py:2011> exception=RuntimeError('Event loop is closed')>\n",
      "RuntimeError: Event loop is closed\n",
      "Evaluating: 100%|██████████| 60/60 [00:09<00:00,  6.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average score is: 0.9094172273979401\n",
      "CHUNK SIZE 3000, 0% overlap:\n",
      "                   System  Faithfulness  Answer Relevancy  Context Precision  \\\n",
      "0  Chunk 3000, overlap 0%      0.952381          0.853019              0.975   \n",
      "\n",
      "   Context Recall  Answer Similarity  Answer Correctness   Average  \n",
      "0            0.98           0.963986            0.732118  0.909417  \n",
      "Chunk size 3000, overlap 5%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "passing column names as 'ground_truths' is deprecated and will be removed in the next version, please use 'ground_truth' instead. Note that `ground_truth` should be of type string and not Sequence[string] like `ground_truths`\n",
      "Evaluating: 100%|██████████| 60/60 [00:09<00:00,  6.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average score is: 0.9062728701136448\n",
      "CHUNK SIZE 3000, 5% overlap:\n",
      "                   System  Faithfulness  Answer Relevancy  Context Precision  \\\n",
      "0  Chunk 3000, overlap 5%       0.96875          0.834882              0.975   \n",
      "\n",
      "   Context Recall  Answer Similarity  Answer Correctness   Average  \n",
      "0            0.98           0.963353            0.715653  0.906273  \n",
      "Chunk size 3000, overlap 10%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "passing column names as 'ground_truths' is deprecated and will be removed in the next version, please use 'ground_truth' instead. Note that `ground_truth` should be of type string and not Sequence[string] like `ground_truths`\n",
      "Evaluating: 100%|██████████| 60/60 [00:10<00:00,  5.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average score is: 0.9063735498045288\n",
      "CHUNK SIZE 3000, 10% overlap:\n",
      "                    System  Faithfulness  Answer Relevancy  Context Precision  \\\n",
      "0  Chunk 3000, overlap 10%      0.952381          0.829536           0.958333   \n",
      "\n",
      "   Context Recall  Answer Similarity  Answer Correctness   Average  \n",
      "0            0.98           0.965752            0.752239  0.906374  \n",
      "Chunk size 3000, overlap 15%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "passing column names as 'ground_truths' is deprecated and will be removed in the next version, please use 'ground_truth' instead. Note that `ground_truth` should be of type string and not Sequence[string] like `ground_truths`\n",
      "Evaluating: 100%|██████████| 60/60 [00:10<00:00,  5.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average score is: 0.8895145277177904\n",
      "CHUNK SIZE 3000, 15% overlap:\n",
      "                    System  Faithfulness  Answer Relevancy  Context Precision  \\\n",
      "0  Chunk 3000, overlap 15%      0.873469          0.843047              0.975   \n",
      "\n",
      "   Context Recall  Answer Similarity  Answer Correctness   Average  \n",
      "0            0.98           0.963603            0.701967  0.889515  \n",
      "Chunk size 3000, overlap 20%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "passing column names as 'ground_truths' is deprecated and will be removed in the next version, please use 'ground_truth' instead. Note that `ground_truth` should be of type string and not Sequence[string] like `ground_truths`\n",
      "Evaluating: 100%|██████████| 60/60 [00:10<00:00,  5.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average score is: 0.9057416037974716\n",
      "CHUNK SIZE 3000, 20% overlap:\n",
      "                    System  Faithfulness  Answer Relevancy  Context Precision  \\\n",
      "0  Chunk 3000, overlap 20%      0.951389          0.856902              0.975   \n",
      "\n",
      "   Context Recall  Answer Similarity  Answer Correctness   Average  \n",
      "0            0.98           0.965436            0.705722  0.905742  \n"
     ]
    }
   ],
   "source": [
    "chunk_sizes = [500, 1000, 2000, 3000]\n",
    "overlap_percentages = [0, 5, 10, 15, 20]\n",
    "\n",
    "for chunk_size in chunk_sizes:\n",
    "    for overlap_percentage in overlap_percentages:\n",
    "        # Calculate overlap based on percentage\n",
    "        chunk_overlap = int(chunk_size * overlap_percentage / 100)\n",
    "        \n",
    "        # Create text splitter\n",
    "        # text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
    "        \n",
    "        # # Split documents\n",
    "        # chunks = text_splitter.split_documents(documents)\n",
    "        \n",
    "        # Print number of chunks\n",
    "        print(f\"Chunk size {chunk_size}, overlap {overlap_percentage}%\")\n",
    "        \n",
    "        # Create Chroma database\n",
    "        # db = Chroma.from_documents(chunks, embeddings_client, persist_directory=f\"../news/vectordb-edit/chunking_{chunk_size}_{overlap_percentage}\")\n",
    "        db = Chroma(persist_directory = f\"../news/vectordb-edit/chunking_{chunk_size}_{overlap_percentage}\", embedding_function=embeddings_client)\n",
    "        db.persist()\n",
    "        \n",
    "        # Create retriever\n",
    "        retriever = db.as_retriever()\n",
    "        \n",
    "        # Run and evaluate\n",
    "        result,results_df = run_and_evaluate(f\"Chunk {chunk_size}, overlap {overlap_percentage}%\", retriever, prompt, llm, results_df)\n",
    "        print(f\"CHUNK SIZE {chunk_size}, {overlap_percentage}% overlap:\")\n",
    "        print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>System</th>\n",
       "      <th>Faithfulness</th>\n",
       "      <th>Answer Relevancy</th>\n",
       "      <th>Context Precision</th>\n",
       "      <th>Context Recall</th>\n",
       "      <th>Answer Similarity</th>\n",
       "      <th>Answer Correctness</th>\n",
       "      <th>Average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GPT-3.5</td>\n",
       "      <td>0.947090</td>\n",
       "      <td>0.463838</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.900371</td>\n",
       "      <td>0.468007</td>\n",
       "      <td>0.639884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GPT-4</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.287687</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.909879</td>\n",
       "      <td>0.536392</td>\n",
       "      <td>0.632326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Naive</td>\n",
       "      <td>0.966518</td>\n",
       "      <td>0.917530</td>\n",
       "      <td>0.983333</td>\n",
       "      <td>0.975000</td>\n",
       "      <td>0.963399</td>\n",
       "      <td>0.776985</td>\n",
       "      <td>0.930461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Recursive</td>\n",
       "      <td>0.966518</td>\n",
       "      <td>0.737454</td>\n",
       "      <td>0.983333</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>0.963403</td>\n",
       "      <td>0.773308</td>\n",
       "      <td>0.897336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Chunk 500, overlap 0%</td>\n",
       "      <td>0.983333</td>\n",
       "      <td>0.925543</td>\n",
       "      <td>0.991667</td>\n",
       "      <td>0.946429</td>\n",
       "      <td>0.961035</td>\n",
       "      <td>0.671918</td>\n",
       "      <td>0.913321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Chunk 500, overlap 5%</td>\n",
       "      <td>0.974603</td>\n",
       "      <td>0.932008</td>\n",
       "      <td>0.991667</td>\n",
       "      <td>0.902778</td>\n",
       "      <td>0.960365</td>\n",
       "      <td>0.710475</td>\n",
       "      <td>0.911983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Chunk 500, overlap 10%</td>\n",
       "      <td>0.943386</td>\n",
       "      <td>0.807349</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.943333</td>\n",
       "      <td>0.962567</td>\n",
       "      <td>0.714292</td>\n",
       "      <td>0.886821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Chunk 500, overlap 15%</td>\n",
       "      <td>0.982143</td>\n",
       "      <td>0.898565</td>\n",
       "      <td>0.963889</td>\n",
       "      <td>0.977778</td>\n",
       "      <td>0.961660</td>\n",
       "      <td>0.667948</td>\n",
       "      <td>0.908664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Chunk 500, overlap 20%</td>\n",
       "      <td>0.954861</td>\n",
       "      <td>0.912232</td>\n",
       "      <td>0.955556</td>\n",
       "      <td>0.977778</td>\n",
       "      <td>0.961260</td>\n",
       "      <td>0.681888</td>\n",
       "      <td>0.907262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Chunk 1000, overlap 0%</td>\n",
       "      <td>0.987654</td>\n",
       "      <td>0.907493</td>\n",
       "      <td>0.983333</td>\n",
       "      <td>0.955000</td>\n",
       "      <td>0.959331</td>\n",
       "      <td>0.757576</td>\n",
       "      <td>0.925065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Chunk 1000, overlap 5%</td>\n",
       "      <td>0.984127</td>\n",
       "      <td>0.891685</td>\n",
       "      <td>0.975000</td>\n",
       "      <td>0.940000</td>\n",
       "      <td>0.961574</td>\n",
       "      <td>0.718890</td>\n",
       "      <td>0.911879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Chunk 1000, overlap 10%</td>\n",
       "      <td>0.987654</td>\n",
       "      <td>0.889549</td>\n",
       "      <td>0.983333</td>\n",
       "      <td>0.940000</td>\n",
       "      <td>0.961549</td>\n",
       "      <td>0.693724</td>\n",
       "      <td>0.909302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Chunk 1000, overlap 15%</td>\n",
       "      <td>0.987654</td>\n",
       "      <td>0.900701</td>\n",
       "      <td>0.983333</td>\n",
       "      <td>0.955000</td>\n",
       "      <td>0.962723</td>\n",
       "      <td>0.736066</td>\n",
       "      <td>0.920913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Chunk 1000, overlap 20%</td>\n",
       "      <td>0.953086</td>\n",
       "      <td>0.937404</td>\n",
       "      <td>0.983333</td>\n",
       "      <td>0.940000</td>\n",
       "      <td>0.962642</td>\n",
       "      <td>0.693313</td>\n",
       "      <td>0.911630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Chunk 2000, overlap 0%</td>\n",
       "      <td>0.949735</td>\n",
       "      <td>0.867421</td>\n",
       "      <td>0.975000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.963794</td>\n",
       "      <td>0.725964</td>\n",
       "      <td>0.913653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Chunk 2000, overlap 5%</td>\n",
       "      <td>0.968254</td>\n",
       "      <td>0.876055</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.971429</td>\n",
       "      <td>0.963941</td>\n",
       "      <td>0.751386</td>\n",
       "      <td>0.916289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Chunk 2000, overlap 10%</td>\n",
       "      <td>0.968750</td>\n",
       "      <td>0.769901</td>\n",
       "      <td>0.975000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.964368</td>\n",
       "      <td>0.706562</td>\n",
       "      <td>0.897430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Chunk 2000, overlap 15%</td>\n",
       "      <td>0.943452</td>\n",
       "      <td>0.781496</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.983333</td>\n",
       "      <td>0.964392</td>\n",
       "      <td>0.695192</td>\n",
       "      <td>0.889089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Chunk 2000, overlap 20%</td>\n",
       "      <td>0.964286</td>\n",
       "      <td>0.868970</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.963397</td>\n",
       "      <td>0.719633</td>\n",
       "      <td>0.913825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Chunk 3000, overlap 0%</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.853019</td>\n",
       "      <td>0.975000</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.963986</td>\n",
       "      <td>0.732118</td>\n",
       "      <td>0.909417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Chunk 3000, overlap 5%</td>\n",
       "      <td>0.968750</td>\n",
       "      <td>0.834882</td>\n",
       "      <td>0.975000</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.963353</td>\n",
       "      <td>0.715653</td>\n",
       "      <td>0.906273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Chunk 3000, overlap 10%</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.829536</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.965752</td>\n",
       "      <td>0.752239</td>\n",
       "      <td>0.906374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Chunk 3000, overlap 15%</td>\n",
       "      <td>0.873469</td>\n",
       "      <td>0.843047</td>\n",
       "      <td>0.975000</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.963603</td>\n",
       "      <td>0.701967</td>\n",
       "      <td>0.889515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Chunk 3000, overlap 20%</td>\n",
       "      <td>0.951389</td>\n",
       "      <td>0.856902</td>\n",
       "      <td>0.975000</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.965436</td>\n",
       "      <td>0.705722</td>\n",
       "      <td>0.905742</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     System  Faithfulness  Answer Relevancy  \\\n",
       "0                   GPT-3.5      0.947090          0.463838   \n",
       "1                     GPT-4      1.000000          0.287687   \n",
       "2                     Naive      0.966518          0.917530   \n",
       "3                 Recursive      0.966518          0.737454   \n",
       "4     Chunk 500, overlap 0%      0.983333          0.925543   \n",
       "5     Chunk 500, overlap 5%      0.974603          0.932008   \n",
       "6    Chunk 500, overlap 10%      0.943386          0.807349   \n",
       "7    Chunk 500, overlap 15%      0.982143          0.898565   \n",
       "8    Chunk 500, overlap 20%      0.954861          0.912232   \n",
       "9    Chunk 1000, overlap 0%      0.987654          0.907493   \n",
       "10   Chunk 1000, overlap 5%      0.984127          0.891685   \n",
       "11  Chunk 1000, overlap 10%      0.987654          0.889549   \n",
       "12  Chunk 1000, overlap 15%      0.987654          0.900701   \n",
       "13  Chunk 1000, overlap 20%      0.953086          0.937404   \n",
       "14   Chunk 2000, overlap 0%      0.949735          0.867421   \n",
       "15   Chunk 2000, overlap 5%      0.968254          0.876055   \n",
       "16  Chunk 2000, overlap 10%      0.968750          0.769901   \n",
       "17  Chunk 2000, overlap 15%      0.943452          0.781496   \n",
       "18  Chunk 2000, overlap 20%      0.964286          0.868970   \n",
       "19   Chunk 3000, overlap 0%      0.952381          0.853019   \n",
       "20   Chunk 3000, overlap 5%      0.968750          0.834882   \n",
       "21  Chunk 3000, overlap 10%      0.952381          0.829536   \n",
       "22  Chunk 3000, overlap 15%      0.873469          0.843047   \n",
       "23  Chunk 3000, overlap 20%      0.951389          0.856902   \n",
       "\n",
       "    Context Precision  Context Recall  Answer Similarity  Answer Correctness  \\\n",
       "0                 NaN             NaN           0.900371            0.468007   \n",
       "1                 NaN             NaN           0.909879            0.536392   \n",
       "2            0.983333        0.975000           0.963399            0.776985   \n",
       "3            0.983333        0.960000           0.963403            0.773308   \n",
       "4            0.991667        0.946429           0.961035            0.671918   \n",
       "5            0.991667        0.902778           0.960365            0.710475   \n",
       "6            0.950000        0.943333           0.962567            0.714292   \n",
       "7            0.963889        0.977778           0.961660            0.667948   \n",
       "8            0.955556        0.977778           0.961260            0.681888   \n",
       "9            0.983333        0.955000           0.959331            0.757576   \n",
       "10           0.975000        0.940000           0.961574            0.718890   \n",
       "11           0.983333        0.940000           0.961549            0.693724   \n",
       "12           0.983333        0.955000           0.962723            0.736066   \n",
       "13           0.983333        0.940000           0.962642            0.693313   \n",
       "14           0.975000        1.000000           0.963794            0.725964   \n",
       "15           0.966667        0.971429           0.963941            0.751386   \n",
       "16           0.975000        1.000000           0.964368            0.706562   \n",
       "17           0.966667        0.983333           0.964392            0.695192   \n",
       "18           0.966667        1.000000           0.963397            0.719633   \n",
       "19           0.975000        0.980000           0.963986            0.732118   \n",
       "20           0.975000        0.980000           0.963353            0.715653   \n",
       "21           0.958333        0.980000           0.965752            0.752239   \n",
       "22           0.975000        0.980000           0.963603            0.701967   \n",
       "23           0.975000        0.980000           0.965436            0.705722   \n",
       "\n",
       "     Average  \n",
       "0   0.639884  \n",
       "1   0.632326  \n",
       "2   0.930461  \n",
       "3   0.897336  \n",
       "4   0.913321  \n",
       "5   0.911983  \n",
       "6   0.886821  \n",
       "7   0.908664  \n",
       "8   0.907262  \n",
       "9   0.925065  \n",
       "10  0.911879  \n",
       "11  0.909302  \n",
       "12  0.920913  \n",
       "13  0.911630  \n",
       "14  0.913653  \n",
       "15  0.916289  \n",
       "16  0.897430  \n",
       "17  0.889089  \n",
       "18  0.913825  \n",
       "19  0.909417  \n",
       "20  0.906273  \n",
       "21  0.906374  \n",
       "22  0.889515  \n",
       "23  0.905742  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.to_csv(f\"../news/results/results_summary.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9304607912730924"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "highest_average = results_df[\"Average\"].max()\n",
    "highest_average"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "chunk = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # THE FIRST TIME RUN THIS, AFTER RUN THE NEXT CELL\n",
    "# text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(chunk_size = 1000, chunk_overlap = 100)\n",
    "# chunks_1000 = text_splitter.split_documents(documents)\n",
    "# print(len(chunks_1000))\n",
    "# db_1000 = Chroma.from_documents(chunks_1000, embeddings_client, persist_directory = \"../news/vectordb/recursive_1000\")\n",
    "# db_1000.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# db_1000 = Chroma(persist_directory = \"../news/vectordb/recursive_1000\", embedding_function=embeddings_client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "passing column names as 'ground_truths' is deprecated and will be removed in the next version, please use 'ground_truth' instead. Note that `ground_truth` should be of type string and not Sequence[string] like `ground_truths`\n",
      "Evaluating: 100%|██████████| 60/60 [00:14<00:00,  4.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHUNK SIZE 1000\n",
      "{'faithfulness': 0.9841, 'answer_relevancy': 0.8044, 'context_precision': 0.9750, 'context_recall': 0.9550, 'answer_similarity': 0.9614, 'answer_correctness': 0.6946}\n"
     ]
    }
   ],
   "source": [
    "# retriever_1000 = db_1000.as_retriever()\n",
    "# result_1000 = run_and_evaluate(retriever_1000, prompt, llm)\n",
    "# print(\"CHUNK SIZE 1000\")\n",
    "# print(result_1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "chunk = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107\n"
     ]
    }
   ],
   "source": [
    "# # THE FIRST TIME RUN THIS, AFTER RUN THE NEXT CELL\n",
    "# text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(chunk_size = 500, chunk_overlap = 50)\n",
    "# chunks_500 = text_splitter.split_documents(documents)\n",
    "# print(len(chunks_500))\n",
    "# db_500 = Chroma.from_documents(chunks_500, embeddings_client, persist_directory = \"../news/vectordb/recursive_500\")\n",
    "# db_500.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# db_500 = Chroma(persist_directory = \"../news/vectordb/recursive_500\", embedding_function=embeddings_client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "passing column names as 'ground_truths' is deprecated and will be removed in the next version, please use 'ground_truth' instead. Note that `ground_truth` should be of type string and not Sequence[string] like `ground_truths`\n",
      "Evaluating: 100%|██████████| 60/60 [00:12<00:00,  4.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHUNK SIZE 500\n",
      "{'faithfulness': 0.9378, 'answer_relevancy': 0.7268, 'context_precision': 0.9500, 'context_recall': 0.9472, 'answer_similarity': 0.9616, 'answer_correctness': 0.7098}\n"
     ]
    }
   ],
   "source": [
    "# retriever_500 = db_500.as_retriever()\n",
    "# result_500 = run_and_evaluate(retriever_500, prompt, llm)\n",
    "# print(\"CHUNK SIZE 500\")\n",
    "# print(result_500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "chunk = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37\n"
     ]
    }
   ],
   "source": [
    "# text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(chunk_size = 2000, chunk_overlap = 200)\n",
    "# chunks_2000 = text_splitter.split_documents(documents)\n",
    "# print(len(chunks_2000))\n",
    "# db_2000 = Chroma.from_documents(chunks_2000, embeddings_client, persist_directory = \"../news/vectordb/recursive_2000\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# db_2000 = Chroma(persist_directory = \"../news/vectordb/recursive_2000\", embedding_function=embeddings_client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "passing column names as 'ground_truths' is deprecated and will be removed in the next version, please use 'ground_truth' instead. Note that `ground_truth` should be of type string and not Sequence[string] like `ground_truths`\n",
      "Evaluating: 100%|██████████| 60/60 [00:14<00:00,  4.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHUNK SIZE 2000\n",
      "{'faithfulness': 0.9435, 'answer_relevancy': 0.8731, 'context_precision': 0.9750, 'context_recall': 1.0000, 'answer_similarity': 0.9636, 'answer_correctness': 0.7390}\n"
     ]
    }
   ],
   "source": [
    "# retriever_2000 = db_2000.as_retriever()\n",
    "# result_2000 = run_and_evaluate(retriever_2000, prompt, llm)\n",
    "# print(\"CHUNK SIZE 2000\")\n",
    "# print(result_2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "chunk = 3000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n"
     ]
    }
   ],
   "source": [
    "# text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(chunk_size = 3000, chunk_overlap = 300)\n",
    "# chunks_3000 = text_splitter.split_documents(documents)\n",
    "# print(len(chunks_3000))\n",
    "# db_3000 = Chroma.from_documents(chunks_3000, embeddings_client, persist_directory = \"../news/vectordb/recursive_3000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# db_3000 = Chroma(persist_directory = \"../news/vectordb/recursive_3000\", embedding_function=embeddings_client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "passing column names as 'ground_truths' is deprecated and will be removed in the next version, please use 'ground_truth' instead. Note that `ground_truth` should be of type string and not Sequence[string] like `ground_truths`\n",
      "Evaluating: 100%|██████████| 60/60 [00:13<00:00,  4.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHUNK SIZE 3000\n",
      "{'faithfulness': 0.9592, 'answer_relevancy': 0.7520, 'context_precision': 0.9583, 'context_recall': 0.9800, 'answer_similarity': 0.9645, 'answer_correctness': 0.7113}\n"
     ]
    }
   ],
   "source": [
    "# retriever_3000 = db_3000.as_retriever()\n",
    "# result_3000 = run_and_evaluate(retriever_3000, prompt, llm)\n",
    "# print(\"CHUNK SIZE 3000\")\n",
    "# print(result_3000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### now time to look for different top-k\n",
    "\n",
    "Note: We continue with the size chunk of 2000 as it had the highest average score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "passing column names as 'ground_truths' is deprecated and will be removed in the next version, please use 'ground_truth' instead. Note that `ground_truth` should be of type string and not Sequence[string] like `ground_truths`\n",
      "Evaluating: 100%|██████████| 60/60 [00:08<00:00,  6.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average score is: 0.8950808134091349\n",
      "Results for K=2:\n",
      "                              System  Faithfulness  Answer Relevancy  \\\n",
      "0  Chunk size 3000, overlap 20%, K=2      0.965608          0.814959   \n",
      "\n",
      "   Context Precision  Context Recall  Answer Similarity  Answer Correctness  \\\n",
      "0                1.0        0.857778           0.961771            0.770368   \n",
      "\n",
      "    Average  \n",
      "0  0.895081  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "passing column names as 'ground_truths' is deprecated and will be removed in the next version, please use 'ground_truth' instead. Note that `ground_truth` should be of type string and not Sequence[string] like `ground_truths`\n",
      "Evaluating: 100%|██████████| 60/60 [00:09<00:00,  6.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average score is: 0.9012849460805582\n",
      "Results for K=3:\n",
      "                              System  Faithfulness  Answer Relevancy  \\\n",
      "0  Chunk size 3000, overlap 20%, K=3      0.945833          0.906465   \n",
      "\n",
      "   Context Precision  Context Recall  Answer Similarity  Answer Correctness  \\\n",
      "0           0.983333        0.877222           0.963646            0.731209   \n",
      "\n",
      "    Average  \n",
      "0  0.901285  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "passing column names as 'ground_truths' is deprecated and will be removed in the next version, please use 'ground_truth' instead. Note that `ground_truth` should be of type string and not Sequence[string] like `ground_truths`\n",
      "Evaluating: 100%|██████████| 60/60 [00:10<00:00,  5.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average score is: 0.8511285114372145\n",
      "Results for K=5:\n",
      "                              System  Faithfulness  Answer Relevancy  \\\n",
      "0  Chunk size 3000, overlap 20%, K=5      0.864198          0.705882   \n",
      "\n",
      "   Context Precision  Context Recall  Answer Similarity  Answer Correctness  \\\n",
      "0           0.969306        0.971429           0.957138             0.63882   \n",
      "\n",
      "    Average  \n",
      "0  0.851129  \n"
     ]
    }
   ],
   "source": [
    "k_values = [2, 3, 5]\n",
    "\n",
    "# Iterate over different k values\n",
    "for k in k_values:\n",
    "    # Create retriever with k value\n",
    "    retriever = db_naive.as_retriever(search_kwargs={\"k\": k})\n",
    "    \n",
    "    # Run and evaluate\n",
    "    result,results_df = run_and_evaluate(f\"Chunk size {chunk_size}, overlap {overlap_percentage}%, K={k}\", retriever, prompt, llm, results_df)\n",
    "    print(f\"Results for K={k}:\")\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>System</th>\n",
       "      <th>Faithfulness</th>\n",
       "      <th>Answer Relevancy</th>\n",
       "      <th>Context Precision</th>\n",
       "      <th>Context Recall</th>\n",
       "      <th>Answer Similarity</th>\n",
       "      <th>Answer Correctness</th>\n",
       "      <th>Average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GPT-3.5</td>\n",
       "      <td>0.947090</td>\n",
       "      <td>0.463838</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.900371</td>\n",
       "      <td>0.468007</td>\n",
       "      <td>0.639884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GPT-4</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.287687</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.909879</td>\n",
       "      <td>0.536392</td>\n",
       "      <td>0.632326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Naive</td>\n",
       "      <td>0.966518</td>\n",
       "      <td>0.917530</td>\n",
       "      <td>0.983333</td>\n",
       "      <td>0.975000</td>\n",
       "      <td>0.963399</td>\n",
       "      <td>0.776985</td>\n",
       "      <td>0.930461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Recursive</td>\n",
       "      <td>0.966518</td>\n",
       "      <td>0.737454</td>\n",
       "      <td>0.983333</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>0.963403</td>\n",
       "      <td>0.773308</td>\n",
       "      <td>0.897336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Chunk 500, overlap 0%</td>\n",
       "      <td>0.983333</td>\n",
       "      <td>0.925543</td>\n",
       "      <td>0.991667</td>\n",
       "      <td>0.946429</td>\n",
       "      <td>0.961035</td>\n",
       "      <td>0.671918</td>\n",
       "      <td>0.913321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Chunk 500, overlap 5%</td>\n",
       "      <td>0.974603</td>\n",
       "      <td>0.932008</td>\n",
       "      <td>0.991667</td>\n",
       "      <td>0.902778</td>\n",
       "      <td>0.960365</td>\n",
       "      <td>0.710475</td>\n",
       "      <td>0.911983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Chunk 500, overlap 10%</td>\n",
       "      <td>0.943386</td>\n",
       "      <td>0.807349</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.943333</td>\n",
       "      <td>0.962567</td>\n",
       "      <td>0.714292</td>\n",
       "      <td>0.886821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Chunk 500, overlap 15%</td>\n",
       "      <td>0.982143</td>\n",
       "      <td>0.898565</td>\n",
       "      <td>0.963889</td>\n",
       "      <td>0.977778</td>\n",
       "      <td>0.961660</td>\n",
       "      <td>0.667948</td>\n",
       "      <td>0.908664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Chunk 500, overlap 20%</td>\n",
       "      <td>0.954861</td>\n",
       "      <td>0.912232</td>\n",
       "      <td>0.955556</td>\n",
       "      <td>0.977778</td>\n",
       "      <td>0.961260</td>\n",
       "      <td>0.681888</td>\n",
       "      <td>0.907262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Chunk 1000, overlap 0%</td>\n",
       "      <td>0.987654</td>\n",
       "      <td>0.907493</td>\n",
       "      <td>0.983333</td>\n",
       "      <td>0.955000</td>\n",
       "      <td>0.959331</td>\n",
       "      <td>0.757576</td>\n",
       "      <td>0.925065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Chunk 1000, overlap 5%</td>\n",
       "      <td>0.984127</td>\n",
       "      <td>0.891685</td>\n",
       "      <td>0.975000</td>\n",
       "      <td>0.940000</td>\n",
       "      <td>0.961574</td>\n",
       "      <td>0.718890</td>\n",
       "      <td>0.911879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Chunk 1000, overlap 10%</td>\n",
       "      <td>0.987654</td>\n",
       "      <td>0.889549</td>\n",
       "      <td>0.983333</td>\n",
       "      <td>0.940000</td>\n",
       "      <td>0.961549</td>\n",
       "      <td>0.693724</td>\n",
       "      <td>0.909302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Chunk 1000, overlap 15%</td>\n",
       "      <td>0.987654</td>\n",
       "      <td>0.900701</td>\n",
       "      <td>0.983333</td>\n",
       "      <td>0.955000</td>\n",
       "      <td>0.962723</td>\n",
       "      <td>0.736066</td>\n",
       "      <td>0.920913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Chunk 1000, overlap 20%</td>\n",
       "      <td>0.953086</td>\n",
       "      <td>0.937404</td>\n",
       "      <td>0.983333</td>\n",
       "      <td>0.940000</td>\n",
       "      <td>0.962642</td>\n",
       "      <td>0.693313</td>\n",
       "      <td>0.911630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Chunk 2000, overlap 0%</td>\n",
       "      <td>0.949735</td>\n",
       "      <td>0.867421</td>\n",
       "      <td>0.975000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.963794</td>\n",
       "      <td>0.725964</td>\n",
       "      <td>0.913653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Chunk 2000, overlap 5%</td>\n",
       "      <td>0.968254</td>\n",
       "      <td>0.876055</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.971429</td>\n",
       "      <td>0.963941</td>\n",
       "      <td>0.751386</td>\n",
       "      <td>0.916289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Chunk 2000, overlap 10%</td>\n",
       "      <td>0.968750</td>\n",
       "      <td>0.769901</td>\n",
       "      <td>0.975000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.964368</td>\n",
       "      <td>0.706562</td>\n",
       "      <td>0.897430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Chunk 2000, overlap 15%</td>\n",
       "      <td>0.943452</td>\n",
       "      <td>0.781496</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.983333</td>\n",
       "      <td>0.964392</td>\n",
       "      <td>0.695192</td>\n",
       "      <td>0.889089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Chunk 2000, overlap 20%</td>\n",
       "      <td>0.964286</td>\n",
       "      <td>0.868970</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.963397</td>\n",
       "      <td>0.719633</td>\n",
       "      <td>0.913825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Chunk 3000, overlap 0%</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.853019</td>\n",
       "      <td>0.975000</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.963986</td>\n",
       "      <td>0.732118</td>\n",
       "      <td>0.909417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Chunk 3000, overlap 5%</td>\n",
       "      <td>0.968750</td>\n",
       "      <td>0.834882</td>\n",
       "      <td>0.975000</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.963353</td>\n",
       "      <td>0.715653</td>\n",
       "      <td>0.906273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Chunk 3000, overlap 10%</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.829536</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.965752</td>\n",
       "      <td>0.752239</td>\n",
       "      <td>0.906374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Chunk 3000, overlap 15%</td>\n",
       "      <td>0.873469</td>\n",
       "      <td>0.843047</td>\n",
       "      <td>0.975000</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.963603</td>\n",
       "      <td>0.701967</td>\n",
       "      <td>0.889515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Chunk 3000, overlap 20%</td>\n",
       "      <td>0.951389</td>\n",
       "      <td>0.856902</td>\n",
       "      <td>0.975000</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.965436</td>\n",
       "      <td>0.705722</td>\n",
       "      <td>0.905742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Chunk size 3000, overlap 20%, K=2</td>\n",
       "      <td>0.965608</td>\n",
       "      <td>0.814959</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.857778</td>\n",
       "      <td>0.961771</td>\n",
       "      <td>0.770368</td>\n",
       "      <td>0.895081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Chunk size 3000, overlap 20%, K=3</td>\n",
       "      <td>0.945833</td>\n",
       "      <td>0.906465</td>\n",
       "      <td>0.983333</td>\n",
       "      <td>0.877222</td>\n",
       "      <td>0.963646</td>\n",
       "      <td>0.731209</td>\n",
       "      <td>0.901285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Chunk size 3000, overlap 20%, K=5</td>\n",
       "      <td>0.864198</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.969306</td>\n",
       "      <td>0.971429</td>\n",
       "      <td>0.957138</td>\n",
       "      <td>0.638820</td>\n",
       "      <td>0.851129</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               System  Faithfulness  Answer Relevancy  \\\n",
       "0                             GPT-3.5      0.947090          0.463838   \n",
       "1                               GPT-4      1.000000          0.287687   \n",
       "2                               Naive      0.966518          0.917530   \n",
       "3                           Recursive      0.966518          0.737454   \n",
       "4               Chunk 500, overlap 0%      0.983333          0.925543   \n",
       "5               Chunk 500, overlap 5%      0.974603          0.932008   \n",
       "6              Chunk 500, overlap 10%      0.943386          0.807349   \n",
       "7              Chunk 500, overlap 15%      0.982143          0.898565   \n",
       "8              Chunk 500, overlap 20%      0.954861          0.912232   \n",
       "9              Chunk 1000, overlap 0%      0.987654          0.907493   \n",
       "10             Chunk 1000, overlap 5%      0.984127          0.891685   \n",
       "11            Chunk 1000, overlap 10%      0.987654          0.889549   \n",
       "12            Chunk 1000, overlap 15%      0.987654          0.900701   \n",
       "13            Chunk 1000, overlap 20%      0.953086          0.937404   \n",
       "14             Chunk 2000, overlap 0%      0.949735          0.867421   \n",
       "15             Chunk 2000, overlap 5%      0.968254          0.876055   \n",
       "16            Chunk 2000, overlap 10%      0.968750          0.769901   \n",
       "17            Chunk 2000, overlap 15%      0.943452          0.781496   \n",
       "18            Chunk 2000, overlap 20%      0.964286          0.868970   \n",
       "19             Chunk 3000, overlap 0%      0.952381          0.853019   \n",
       "20             Chunk 3000, overlap 5%      0.968750          0.834882   \n",
       "21            Chunk 3000, overlap 10%      0.952381          0.829536   \n",
       "22            Chunk 3000, overlap 15%      0.873469          0.843047   \n",
       "23            Chunk 3000, overlap 20%      0.951389          0.856902   \n",
       "24  Chunk size 3000, overlap 20%, K=2      0.965608          0.814959   \n",
       "25  Chunk size 3000, overlap 20%, K=3      0.945833          0.906465   \n",
       "26  Chunk size 3000, overlap 20%, K=5      0.864198          0.705882   \n",
       "\n",
       "    Context Precision  Context Recall  Answer Similarity  Answer Correctness  \\\n",
       "0                 NaN             NaN           0.900371            0.468007   \n",
       "1                 NaN             NaN           0.909879            0.536392   \n",
       "2            0.983333        0.975000           0.963399            0.776985   \n",
       "3            0.983333        0.960000           0.963403            0.773308   \n",
       "4            0.991667        0.946429           0.961035            0.671918   \n",
       "5            0.991667        0.902778           0.960365            0.710475   \n",
       "6            0.950000        0.943333           0.962567            0.714292   \n",
       "7            0.963889        0.977778           0.961660            0.667948   \n",
       "8            0.955556        0.977778           0.961260            0.681888   \n",
       "9            0.983333        0.955000           0.959331            0.757576   \n",
       "10           0.975000        0.940000           0.961574            0.718890   \n",
       "11           0.983333        0.940000           0.961549            0.693724   \n",
       "12           0.983333        0.955000           0.962723            0.736066   \n",
       "13           0.983333        0.940000           0.962642            0.693313   \n",
       "14           0.975000        1.000000           0.963794            0.725964   \n",
       "15           0.966667        0.971429           0.963941            0.751386   \n",
       "16           0.975000        1.000000           0.964368            0.706562   \n",
       "17           0.966667        0.983333           0.964392            0.695192   \n",
       "18           0.966667        1.000000           0.963397            0.719633   \n",
       "19           0.975000        0.980000           0.963986            0.732118   \n",
       "20           0.975000        0.980000           0.963353            0.715653   \n",
       "21           0.958333        0.980000           0.965752            0.752239   \n",
       "22           0.975000        0.980000           0.963603            0.701967   \n",
       "23           0.975000        0.980000           0.965436            0.705722   \n",
       "24           1.000000        0.857778           0.961771            0.770368   \n",
       "25           0.983333        0.877222           0.963646            0.731209   \n",
       "26           0.969306        0.971429           0.957138            0.638820   \n",
       "\n",
       "     Average  \n",
       "0   0.639884  \n",
       "1   0.632326  \n",
       "2   0.930461  \n",
       "3   0.897336  \n",
       "4   0.913321  \n",
       "5   0.911983  \n",
       "6   0.886821  \n",
       "7   0.908664  \n",
       "8   0.907262  \n",
       "9   0.925065  \n",
       "10  0.911879  \n",
       "11  0.909302  \n",
       "12  0.920913  \n",
       "13  0.911630  \n",
       "14  0.913653  \n",
       "15  0.916289  \n",
       "16  0.897430  \n",
       "17  0.889089  \n",
       "18  0.913825  \n",
       "19  0.909417  \n",
       "20  0.906273  \n",
       "21  0.906374  \n",
       "22  0.889515  \n",
       "23  0.905742  \n",
       "24  0.895081  \n",
       "25  0.901285  \n",
       "26  0.851129  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "passing column names as 'ground_truths' is deprecated and will be removed in the next version, please use 'ground_truth' instead. Note that `ground_truth` should be of type string and not Sequence[string] like `ground_truths`\n",
      "Evaluating: 100%|██████████| 60/60 [00:10<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHUNK SIZE 1000, K=2\n",
      "{'faithfulness': 0.9306, 'answer_relevancy': 0.9134, 'context_precision': 1.0000, 'context_recall': 0.9289, 'answer_similarity': 0.9617, 'answer_correctness': 0.7467}\n"
     ]
    }
   ],
   "source": [
    "# retriever_2 = db_2000.as_retriever(search_kwargs={\"k\": 2})\n",
    "# result_2 = run_and_evaluate(retriever_2, prompt, llm)\n",
    "# print(\"CHUNK SIZE 1000, K=2\")\n",
    "# print(result_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "passing column names as 'ground_truths' is deprecated and will be removed in the next version, please use 'ground_truth' instead. Note that `ground_truth` should be of type string and not Sequence[string] like `ground_truths`\n",
      "Evaluating: 100%|██████████| 60/60 [00:09<00:00,  6.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHUNK SIZE 1000, K=3\n",
      "{'faithfulness': 0.9260, 'answer_relevancy': 0.8950, 'context_precision': 0.9833, 'context_recall': 0.9750, 'answer_similarity': 0.9641, 'answer_correctness': 0.7973}\n"
     ]
    }
   ],
   "source": [
    "# retriever_3 = db_2000.as_retriever(search_kwargs={\"k\": 3})\n",
    "# result_3 = run_and_evaluate(retriever_3, prompt, llm)\n",
    "# print(\"CHUNK SIZE 1000, K=3\")\n",
    "# print(result_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "passing column names as 'ground_truths' is deprecated and will be removed in the next version, please use 'ground_truth' instead. Note that `ground_truth` should be of type string and not Sequence[string] like `ground_truths`\n",
      "Evaluating: 100%|██████████| 60/60 [00:10<00:00,  5.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHUNK SIZE 1000, K=5\n",
      "{'faithfulness': 0.9688, 'answer_relevancy': 0.7442, 'context_precision': 0.9617, 'context_recall': 0.9714, 'answer_similarity': 0.9619, 'answer_correctness': 0.7390}\n"
     ]
    }
   ],
   "source": [
    "# retriever_5 = db_2000.as_retriever(search_kwargs={\"k\": 5})\n",
    "# result_5 = run_and_evaluate(retriever_5, prompt, llm)\n",
    "# print(\"CHUNK SIZE 1000, K=5\")\n",
    "# print(result_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "passing column names as 'ground_truths' is deprecated and will be removed in the next version, please use 'ground_truth' instead. Note that `ground_truth` should be of type string and not Sequence[string] like `ground_truths`\n",
      "Evaluating:  63%|██████▎   | 38/60 [00:06<00:02,  9.86it/s]Invalid JSON response. Expected dictionary with key 'Attributed'\n",
      "Evaluating:  97%|█████████▋| 58/60 [00:13<00:01,  1.38it/s]Runner in Executor raised an exception\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\ragas\\executor.py\", line 58, in _aresults\n",
      "    r = await future\n",
      "        ^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sigitalapina\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\tasks.py\", line 605, in _wait_for_one\n",
      "    return f.result()  # May raise f.exception().\n",
      "           ^^^^^^^^^^\n",
      "  File \"c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\ragas\\executor.py\", line 91, in wrapped_callable_async\n",
      "    return counter, await callable(*args, **kwargs)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\ragas\\metrics\\base.py\", line 91, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\ragas\\metrics\\base.py\", line 87, in ascore\n",
      "    score = await self._ascore(row=row, callbacks=group_cm, is_async=is_async)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py\", line 113, in _ascore\n",
      "    result = await self.llm.generate(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\ragas\\llms\\base.py\", line 92, in generate\n",
      "    return await agenerate_text_with_retry(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\tenacity\\_asyncio.py\", line 88, in async_wrapped\n",
      "    return await fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\tenacity\\_asyncio.py\", line 47, in __call__\n",
      "    do = self.iter(retry_state=retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\tenacity\\__init__.py\", line 325, in iter\n",
      "    raise retry_exc.reraise()\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\tenacity\\__init__.py\", line 158, in reraise\n",
      "    raise self.last_attempt.result()\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sigitalapina\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\concurrent\\futures\\_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sigitalapina\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\concurrent\\futures\\_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\tenacity\\_asyncio.py\", line 50, in __call__\n",
      "    result = await fn(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\ragas\\llms\\base.py\", line 169, in agenerate_text\n",
      "    return await self.langchain_llm.agenerate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 554, in agenerate_prompt\n",
      "    return await self.agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 514, in agenerate\n",
      "    raise exceptions[0]\n",
      "  File \"c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 617, in _agenerate_with_cache\n",
      "    return await self._agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 559, in _agenerate\n",
      "    response = await self.async_client.create(messages=message_dicts, **params)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1330, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1725, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1428, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1519, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'message': \"This model's maximum context length is 8192 tokens. However, your messages resulted in 8278 tokens. Please reduce the length of the messages.\", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}}\n",
      "Evaluating:  98%|█████████▊| 59/60 [01:43<00:18, 18.26s/it]Runner in Executor raised an exception\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\ragas\\executor.py\", line 58, in _aresults\n",
      "    r = await future\n",
      "        ^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sigitalapina\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\tasks.py\", line 605, in _wait_for_one\n",
      "    return f.result()  # May raise f.exception().\n",
      "           ^^^^^^^^^^\n",
      "  File \"c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\ragas\\executor.py\", line 91, in wrapped_callable_async\n",
      "    return counter, await callable(*args, **kwargs)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\ragas\\metrics\\base.py\", line 91, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\ragas\\metrics\\base.py\", line 87, in ascore\n",
      "    score = await self._ascore(row=row, callbacks=group_cm, is_async=is_async)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\ragas\\metrics\\_context_recall.py\", line 113, in _ascore\n",
      "    result = await self.llm.generate(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\ragas\\llms\\base.py\", line 92, in generate\n",
      "    return await agenerate_text_with_retry(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\tenacity\\_asyncio.py\", line 88, in async_wrapped\n",
      "    return await fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\tenacity\\_asyncio.py\", line 47, in __call__\n",
      "    do = self.iter(retry_state=retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\tenacity\\__init__.py\", line 325, in iter\n",
      "    raise retry_exc.reraise()\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\tenacity\\__init__.py\", line 158, in reraise\n",
      "    raise self.last_attempt.result()\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sigitalapina\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\concurrent\\futures\\_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sigitalapina\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\concurrent\\futures\\_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\tenacity\\_asyncio.py\", line 50, in __call__\n",
      "    result = await fn(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\ragas\\llms\\base.py\", line 169, in agenerate_text\n",
      "    return await self.langchain_llm.agenerate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 554, in agenerate_prompt\n",
      "    return await self.agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 514, in agenerate\n",
      "    raise exceptions[0]\n",
      "  File \"c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 617, in _agenerate_with_cache\n",
      "    return await self._agenerate(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 559, in _agenerate\n",
      "    response = await self.async_client.create(messages=message_dicts, **params)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1330, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1725, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1428, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1519, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'message': \"This model's maximum context length is 8192 tokens. However, your messages resulted in 8207 tokens. Please reduce the length of the messages.\", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}}\n",
      "Evaluating: 100%|██████████| 60/60 [02:19<00:00,  2.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHUNK SIZE 1000, K=5\n",
      "{'faithfulness': 0.7835, 'answer_relevancy': 0.8474, 'context_precision': 0.8161, 'context_recall': 0.9210, 'answer_similarity': 0.9402, 'answer_correctness': 0.8747}\n"
     ]
    }
   ],
   "source": [
    "# retriever_6= db_2000.as_retriever(search_kwargs={\"k\": 6})\n",
    "# result_6 = run_and_evaluate(retriever_6, prompt, llm)\n",
    "# print(\"CHUNK SIZE 1000, K=5\")\n",
    "# print(result_6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average score is: 0.8638028044818998\n"
     ]
    }
   ],
   "source": [
    "# dict_res6 = dict(result_6)\n",
    "# average_score = sum(dict_res6.values()) / len(dict_res6)\n",
    "# print(f\"The average score is: {average_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### look for different retrievers\n",
    "\n",
    "3 chunks was the best score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### parent document retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "passing column names as 'ground_truths' is deprecated and will be removed in the next version, please use 'ground_truth' instead. Note that `ground_truth` should be of type string and not Sequence[string] like `ground_truths`\n",
      "Evaluating: 100%|██████████| 60/60 [00:14<00:00,  4.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average score is: 0.897963075414468\n",
      "                      System  Faithfulness  Answer Relevancy  \\\n",
      "0  Parent Retriever 1000-200      0.973765          0.821909   \n",
      "\n",
      "   Context Precision  Context Recall  Answer Similarity  Answer Correctness  \\\n",
      "0                1.0        0.936111           0.961714            0.694279   \n",
      "\n",
      "    Average  \n",
      "0  0.897963  \n"
     ]
    }
   ],
   "source": [
    "from langchain.retrievers import ParentDocumentRetriever\n",
    "from langchain.storage import InMemoryStore\n",
    "\n",
    "parent_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(chunk_size=1000, chunk_overlap = 200)\n",
    "child_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(chunk_size=200, chunk_overlap = 0)\n",
    "\n",
    "vectorstore = Chroma(collection_name=\"split_parents\",persist_directory = \"../vectordb-edit/parent_summarize\", embedding_function=embeddings_client)\n",
    "store = InMemoryStore()\n",
    "parent_document_retriever = ParentDocumentRetriever(\n",
    "    vectorstore=vectorstore,\n",
    "    docstore=store,\n",
    "    child_splitter=child_splitter,\n",
    "    parent_splitter=parent_splitter,\n",
    ")\n",
    "parent_document_retriever.add_documents(documents)\n",
    "result_parent, results_df = run_and_evaluate(f\"Parent Retriever 1000-200\", parent_document_retriever, prompt, llm, results_df)\n",
    "print(result_parent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "passing column names as 'ground_truths' is deprecated and will be removed in the next version, please use 'ground_truth' instead. Note that `ground_truth` should be of type string and not Sequence[string] like `ground_truths`\n",
      "Evaluating: 100%|██████████| 60/60 [00:11<00:00,  5.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average score is: 0.914825196996499\n",
      "                     System  Faithfulness  Answer Relevancy  \\\n",
      "0  Parent Retriever 500-100      0.988889          0.912322   \n",
      "\n",
      "   Context Precision  Context Recall  Answer Similarity  Answer Correctness  \\\n",
      "0           0.941667        0.952778           0.962236            0.731059   \n",
      "\n",
      "    Average  \n",
      "0  0.914825  \n"
     ]
    }
   ],
   "source": [
    "parent_splitter_small = RecursiveCharacterTextSplitter.from_tiktoken_encoder(chunk_size=500, chunk_overlap = 50)\n",
    "child_splitter_small = RecursiveCharacterTextSplitter.from_tiktoken_encoder(chunk_size=100, chunk_overlap = 0)\n",
    "\n",
    "vectorstore = Chroma(collection_name=\"split_parents_small\",persist_directory = \"../vectordb-edit/parent_small_summarize\", embedding_function=embeddings_client)\n",
    "store = InMemoryStore()\n",
    "parent_document_retriever_small = ParentDocumentRetriever(\n",
    "    vectorstore=vectorstore,\n",
    "    docstore=store,\n",
    "    child_splitter=child_splitter_small,\n",
    "    parent_splitter=parent_splitter_small,\n",
    ")\n",
    "parent_document_retriever_small.add_documents(documents)\n",
    "result_parent_small, results_df = run_and_evaluate(f\"Parent Retriever 500-100\", parent_document_retriever_small, prompt, llm, results_df)\n",
    "print(result_parent_small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "passing column names as 'ground_truths' is deprecated and will be removed in the next version, please use 'ground_truth' instead. Note that `ground_truth` should be of type string and not Sequence[string] like `ground_truths`\n",
      "Evaluating: 100%|██████████| 60/60 [00:11<00:00,  5.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average score is: 0.8627504709173657\n",
      "                      System  Faithfulness  Answer Relevancy  \\\n",
      "0  Parent Retriever 1500-200        0.9875          0.643101   \n",
      "\n",
      "   Context Precision  Context Recall  Answer Similarity  Answer Correctness  \\\n",
      "0           0.941667        0.952778           0.962287            0.689171   \n",
      "\n",
      "   Average  \n",
      "0  0.86275  \n"
     ]
    }
   ],
   "source": [
    "parent_splitter_large = RecursiveCharacterTextSplitter.from_tiktoken_encoder(chunk_size=1500, chunk_overlap = 150)\n",
    "child_splitter_large = RecursiveCharacterTextSplitter.from_tiktoken_encoder(chunk_size=200, chunk_overlap = 0)\n",
    "\n",
    "vectorstore = Chroma(collection_name=\"split_parents_large\",persist_directory = \"../vectordb-edit/parent_large_summarize\", embedding_function=embeddings_client)\n",
    "store = InMemoryStore()\n",
    "parent_document_retriever_large = ParentDocumentRetriever(\n",
    "    vectorstore=vectorstore,\n",
    "    docstore=store,\n",
    "    child_splitter=child_splitter_large,\n",
    "    parent_splitter=parent_splitter_large,\n",
    ")\n",
    "parent_document_retriever_large.add_documents(documents)\n",
    "result_parent_large , results_df = run_and_evaluate(f\"Parent Retriever 1500-200\", parent_document_retriever_small, prompt, llm, results_df)\n",
    "print(result_parent_large)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>System</th>\n",
       "      <th>Faithfulness</th>\n",
       "      <th>Answer Relevancy</th>\n",
       "      <th>Context Precision</th>\n",
       "      <th>Context Recall</th>\n",
       "      <th>Answer Similarity</th>\n",
       "      <th>Answer Correctness</th>\n",
       "      <th>Average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GPT-3.5</td>\n",
       "      <td>0.947090</td>\n",
       "      <td>0.463838</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.900371</td>\n",
       "      <td>0.468007</td>\n",
       "      <td>0.639884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GPT-4</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.287687</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.909879</td>\n",
       "      <td>0.536392</td>\n",
       "      <td>0.632326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Naive</td>\n",
       "      <td>0.966518</td>\n",
       "      <td>0.917530</td>\n",
       "      <td>0.983333</td>\n",
       "      <td>0.975000</td>\n",
       "      <td>0.963399</td>\n",
       "      <td>0.776985</td>\n",
       "      <td>0.930461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Recursive</td>\n",
       "      <td>0.966518</td>\n",
       "      <td>0.737454</td>\n",
       "      <td>0.983333</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>0.963403</td>\n",
       "      <td>0.773308</td>\n",
       "      <td>0.897336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Chunk 500, overlap 0%</td>\n",
       "      <td>0.983333</td>\n",
       "      <td>0.925543</td>\n",
       "      <td>0.991667</td>\n",
       "      <td>0.946429</td>\n",
       "      <td>0.961035</td>\n",
       "      <td>0.671918</td>\n",
       "      <td>0.913321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Chunk 500, overlap 5%</td>\n",
       "      <td>0.974603</td>\n",
       "      <td>0.932008</td>\n",
       "      <td>0.991667</td>\n",
       "      <td>0.902778</td>\n",
       "      <td>0.960365</td>\n",
       "      <td>0.710475</td>\n",
       "      <td>0.911983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Chunk 500, overlap 10%</td>\n",
       "      <td>0.943386</td>\n",
       "      <td>0.807349</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.943333</td>\n",
       "      <td>0.962567</td>\n",
       "      <td>0.714292</td>\n",
       "      <td>0.886821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Chunk 500, overlap 15%</td>\n",
       "      <td>0.982143</td>\n",
       "      <td>0.898565</td>\n",
       "      <td>0.963889</td>\n",
       "      <td>0.977778</td>\n",
       "      <td>0.961660</td>\n",
       "      <td>0.667948</td>\n",
       "      <td>0.908664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Chunk 500, overlap 20%</td>\n",
       "      <td>0.954861</td>\n",
       "      <td>0.912232</td>\n",
       "      <td>0.955556</td>\n",
       "      <td>0.977778</td>\n",
       "      <td>0.961260</td>\n",
       "      <td>0.681888</td>\n",
       "      <td>0.907262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Chunk 1000, overlap 0%</td>\n",
       "      <td>0.987654</td>\n",
       "      <td>0.907493</td>\n",
       "      <td>0.983333</td>\n",
       "      <td>0.955000</td>\n",
       "      <td>0.959331</td>\n",
       "      <td>0.757576</td>\n",
       "      <td>0.925065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Chunk 1000, overlap 5%</td>\n",
       "      <td>0.984127</td>\n",
       "      <td>0.891685</td>\n",
       "      <td>0.975000</td>\n",
       "      <td>0.940000</td>\n",
       "      <td>0.961574</td>\n",
       "      <td>0.718890</td>\n",
       "      <td>0.911879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Chunk 1000, overlap 10%</td>\n",
       "      <td>0.987654</td>\n",
       "      <td>0.889549</td>\n",
       "      <td>0.983333</td>\n",
       "      <td>0.940000</td>\n",
       "      <td>0.961549</td>\n",
       "      <td>0.693724</td>\n",
       "      <td>0.909302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Chunk 1000, overlap 15%</td>\n",
       "      <td>0.987654</td>\n",
       "      <td>0.900701</td>\n",
       "      <td>0.983333</td>\n",
       "      <td>0.955000</td>\n",
       "      <td>0.962723</td>\n",
       "      <td>0.736066</td>\n",
       "      <td>0.920913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Chunk 1000, overlap 20%</td>\n",
       "      <td>0.953086</td>\n",
       "      <td>0.937404</td>\n",
       "      <td>0.983333</td>\n",
       "      <td>0.940000</td>\n",
       "      <td>0.962642</td>\n",
       "      <td>0.693313</td>\n",
       "      <td>0.911630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Chunk 2000, overlap 0%</td>\n",
       "      <td>0.949735</td>\n",
       "      <td>0.867421</td>\n",
       "      <td>0.975000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.963794</td>\n",
       "      <td>0.725964</td>\n",
       "      <td>0.913653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Chunk 2000, overlap 5%</td>\n",
       "      <td>0.968254</td>\n",
       "      <td>0.876055</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.971429</td>\n",
       "      <td>0.963941</td>\n",
       "      <td>0.751386</td>\n",
       "      <td>0.916289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Chunk 2000, overlap 10%</td>\n",
       "      <td>0.968750</td>\n",
       "      <td>0.769901</td>\n",
       "      <td>0.975000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.964368</td>\n",
       "      <td>0.706562</td>\n",
       "      <td>0.897430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Chunk 2000, overlap 15%</td>\n",
       "      <td>0.943452</td>\n",
       "      <td>0.781496</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.983333</td>\n",
       "      <td>0.964392</td>\n",
       "      <td>0.695192</td>\n",
       "      <td>0.889089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Chunk 2000, overlap 20%</td>\n",
       "      <td>0.964286</td>\n",
       "      <td>0.868970</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.963397</td>\n",
       "      <td>0.719633</td>\n",
       "      <td>0.913825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Chunk 3000, overlap 0%</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.853019</td>\n",
       "      <td>0.975000</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.963986</td>\n",
       "      <td>0.732118</td>\n",
       "      <td>0.909417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Chunk 3000, overlap 5%</td>\n",
       "      <td>0.968750</td>\n",
       "      <td>0.834882</td>\n",
       "      <td>0.975000</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.963353</td>\n",
       "      <td>0.715653</td>\n",
       "      <td>0.906273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Chunk 3000, overlap 10%</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.829536</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.965752</td>\n",
       "      <td>0.752239</td>\n",
       "      <td>0.906374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Chunk 3000, overlap 15%</td>\n",
       "      <td>0.873469</td>\n",
       "      <td>0.843047</td>\n",
       "      <td>0.975000</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.963603</td>\n",
       "      <td>0.701967</td>\n",
       "      <td>0.889515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Chunk 3000, overlap 20%</td>\n",
       "      <td>0.951389</td>\n",
       "      <td>0.856902</td>\n",
       "      <td>0.975000</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.965436</td>\n",
       "      <td>0.705722</td>\n",
       "      <td>0.905742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Chunk size 3000, overlap 20%, K=2</td>\n",
       "      <td>0.965608</td>\n",
       "      <td>0.814959</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.857778</td>\n",
       "      <td>0.961771</td>\n",
       "      <td>0.770368</td>\n",
       "      <td>0.895081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Chunk size 3000, overlap 20%, K=3</td>\n",
       "      <td>0.945833</td>\n",
       "      <td>0.906465</td>\n",
       "      <td>0.983333</td>\n",
       "      <td>0.877222</td>\n",
       "      <td>0.963646</td>\n",
       "      <td>0.731209</td>\n",
       "      <td>0.901285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Chunk size 3000, overlap 20%, K=5</td>\n",
       "      <td>0.864198</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.969306</td>\n",
       "      <td>0.971429</td>\n",
       "      <td>0.957138</td>\n",
       "      <td>0.638820</td>\n",
       "      <td>0.851129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Parent Retriever 1000-200</td>\n",
       "      <td>0.973765</td>\n",
       "      <td>0.821909</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.936111</td>\n",
       "      <td>0.961714</td>\n",
       "      <td>0.694279</td>\n",
       "      <td>0.897963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Parent Retriever 500-100</td>\n",
       "      <td>0.988889</td>\n",
       "      <td>0.912322</td>\n",
       "      <td>0.941667</td>\n",
       "      <td>0.952778</td>\n",
       "      <td>0.962236</td>\n",
       "      <td>0.731059</td>\n",
       "      <td>0.914825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Parent Retriever 1500-200</td>\n",
       "      <td>0.987500</td>\n",
       "      <td>0.643101</td>\n",
       "      <td>0.941667</td>\n",
       "      <td>0.952778</td>\n",
       "      <td>0.962287</td>\n",
       "      <td>0.689171</td>\n",
       "      <td>0.862750</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               System  Faithfulness  Answer Relevancy  \\\n",
       "0                             GPT-3.5      0.947090          0.463838   \n",
       "1                               GPT-4      1.000000          0.287687   \n",
       "2                               Naive      0.966518          0.917530   \n",
       "3                           Recursive      0.966518          0.737454   \n",
       "4               Chunk 500, overlap 0%      0.983333          0.925543   \n",
       "5               Chunk 500, overlap 5%      0.974603          0.932008   \n",
       "6              Chunk 500, overlap 10%      0.943386          0.807349   \n",
       "7              Chunk 500, overlap 15%      0.982143          0.898565   \n",
       "8              Chunk 500, overlap 20%      0.954861          0.912232   \n",
       "9              Chunk 1000, overlap 0%      0.987654          0.907493   \n",
       "10             Chunk 1000, overlap 5%      0.984127          0.891685   \n",
       "11            Chunk 1000, overlap 10%      0.987654          0.889549   \n",
       "12            Chunk 1000, overlap 15%      0.987654          0.900701   \n",
       "13            Chunk 1000, overlap 20%      0.953086          0.937404   \n",
       "14             Chunk 2000, overlap 0%      0.949735          0.867421   \n",
       "15             Chunk 2000, overlap 5%      0.968254          0.876055   \n",
       "16            Chunk 2000, overlap 10%      0.968750          0.769901   \n",
       "17            Chunk 2000, overlap 15%      0.943452          0.781496   \n",
       "18            Chunk 2000, overlap 20%      0.964286          0.868970   \n",
       "19             Chunk 3000, overlap 0%      0.952381          0.853019   \n",
       "20             Chunk 3000, overlap 5%      0.968750          0.834882   \n",
       "21            Chunk 3000, overlap 10%      0.952381          0.829536   \n",
       "22            Chunk 3000, overlap 15%      0.873469          0.843047   \n",
       "23            Chunk 3000, overlap 20%      0.951389          0.856902   \n",
       "24  Chunk size 3000, overlap 20%, K=2      0.965608          0.814959   \n",
       "25  Chunk size 3000, overlap 20%, K=3      0.945833          0.906465   \n",
       "26  Chunk size 3000, overlap 20%, K=5      0.864198          0.705882   \n",
       "27          Parent Retriever 1000-200      0.973765          0.821909   \n",
       "28           Parent Retriever 500-100      0.988889          0.912322   \n",
       "29          Parent Retriever 1500-200      0.987500          0.643101   \n",
       "\n",
       "    Context Precision  Context Recall  Answer Similarity  Answer Correctness  \\\n",
       "0                 NaN             NaN           0.900371            0.468007   \n",
       "1                 NaN             NaN           0.909879            0.536392   \n",
       "2            0.983333        0.975000           0.963399            0.776985   \n",
       "3            0.983333        0.960000           0.963403            0.773308   \n",
       "4            0.991667        0.946429           0.961035            0.671918   \n",
       "5            0.991667        0.902778           0.960365            0.710475   \n",
       "6            0.950000        0.943333           0.962567            0.714292   \n",
       "7            0.963889        0.977778           0.961660            0.667948   \n",
       "8            0.955556        0.977778           0.961260            0.681888   \n",
       "9            0.983333        0.955000           0.959331            0.757576   \n",
       "10           0.975000        0.940000           0.961574            0.718890   \n",
       "11           0.983333        0.940000           0.961549            0.693724   \n",
       "12           0.983333        0.955000           0.962723            0.736066   \n",
       "13           0.983333        0.940000           0.962642            0.693313   \n",
       "14           0.975000        1.000000           0.963794            0.725964   \n",
       "15           0.966667        0.971429           0.963941            0.751386   \n",
       "16           0.975000        1.000000           0.964368            0.706562   \n",
       "17           0.966667        0.983333           0.964392            0.695192   \n",
       "18           0.966667        1.000000           0.963397            0.719633   \n",
       "19           0.975000        0.980000           0.963986            0.732118   \n",
       "20           0.975000        0.980000           0.963353            0.715653   \n",
       "21           0.958333        0.980000           0.965752            0.752239   \n",
       "22           0.975000        0.980000           0.963603            0.701967   \n",
       "23           0.975000        0.980000           0.965436            0.705722   \n",
       "24           1.000000        0.857778           0.961771            0.770368   \n",
       "25           0.983333        0.877222           0.963646            0.731209   \n",
       "26           0.969306        0.971429           0.957138            0.638820   \n",
       "27           1.000000        0.936111           0.961714            0.694279   \n",
       "28           0.941667        0.952778           0.962236            0.731059   \n",
       "29           0.941667        0.952778           0.962287            0.689171   \n",
       "\n",
       "     Average  \n",
       "0   0.639884  \n",
       "1   0.632326  \n",
       "2   0.930461  \n",
       "3   0.897336  \n",
       "4   0.913321  \n",
       "5   0.911983  \n",
       "6   0.886821  \n",
       "7   0.908664  \n",
       "8   0.907262  \n",
       "9   0.925065  \n",
       "10  0.911879  \n",
       "11  0.909302  \n",
       "12  0.920913  \n",
       "13  0.911630  \n",
       "14  0.913653  \n",
       "15  0.916289  \n",
       "16  0.897430  \n",
       "17  0.889089  \n",
       "18  0.913825  \n",
       "19  0.909417  \n",
       "20  0.906273  \n",
       "21  0.906374  \n",
       "22  0.889515  \n",
       "23  0.905742  \n",
       "24  0.895081  \n",
       "25  0.901285  \n",
       "26  0.851129  \n",
       "27  0.897963  \n",
       "28  0.914825  \n",
       "29  0.862750  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9304607912730924"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "highest_average = results_df[\"Average\"].max()\n",
    "highest_average"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Maximum marginal relevance retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "passing column names as 'ground_truths' is deprecated and will be removed in the next version, please use 'ground_truth' instead. Note that `ground_truth` should be of type string and not Sequence[string] like `ground_truths`\n",
      "Evaluating:  18%|█▊        | 11/60 [00:05<00:21,  2.25it/s]Runner in Executor raised an exception\n",
      "TypeError: expected string or buffer\n",
      "Runner in Executor raised an exception\n",
      "TypeError: expected string or buffer\n",
      "Evaluating: 100%|██████████| 60/60 [00:10<00:00,  5.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average score is: 0.8414345596056197\n",
      "Marginal relevance\n",
      "  System  Faithfulness  Answer Relevancy  Context Precision  Context Recall  \\\n",
      "0    MMR      0.887066          0.616988           0.978668        0.783352   \n",
      "\n",
      "   Answer Similarity  Answer Correctness   Average  \n",
      "0            0.93808            0.844453  0.841435  \n"
     ]
    }
   ],
   "source": [
    "retriever_mmr = db_naive.as_retriever(search_type=\"mmr\")\n",
    "result_mmr, results_df = run_and_evaluate(f\"MMR\", retriever_mmr, prompt, llm, results_df)\n",
    "print(\"Marginal relevance\")\n",
    "print(result_mmr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BM25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 4589, which is longer than the specified 4000\n",
      "Created a chunk of size 4082, which is longer than the specified 4000\n"
     ]
    }
   ],
   "source": [
    "text_splitter = CharacterTextSplitter()\n",
    "chunks = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "passing column names as 'ground_truths' is deprecated and will be removed in the next version, please use 'ground_truth' instead. Note that `ground_truth` should be of type string and not Sequence[string] like `ground_truths`\n",
      "Evaluating: 100%|██████████| 60/60 [00:08<00:00,  7.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average score is: 0.9089806950408187\n",
      "BM25\n",
      "  System  Faithfulness  Answer Relevancy  Context Precision  Context Recall  \\\n",
      "0   BM25      0.981481          0.896899               0.95        0.958333   \n",
      "\n",
      "   Answer Similarity  Answer Correctness   Average  \n",
      "0           0.959879            0.707291  0.908981  \n"
     ]
    }
   ],
   "source": [
    "retriever_bm25 = BM25Retriever.from_documents(chunks)\n",
    "result_bm25, results_df = run_and_evaluate(f\"BM25\", retriever_bm25, prompt, llm, results_df)\n",
    "print(\"BM25\")\n",
    "print(result_bm25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ensambler - Hybrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "passing column names as 'ground_truths' is deprecated and will be removed in the next version, please use 'ground_truth' instead. Note that `ground_truth` should be of type string and not Sequence[string] like `ground_truths`\n",
      "Evaluating: 100%|██████████| 60/60 [00:09<00:00,  6.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average score is: 0.8964416058855433\n",
      "Ensambler\n",
      "        System  Faithfulness  Answer Relevancy  Context Precision  \\\n",
      "0  Ensambler 1      0.943603          0.875975              0.945   \n",
      "\n",
      "   Context Recall  Answer Similarity  Answer Correctness   Average  \n",
      "0           0.935           0.962835            0.716237  0.896442  \n"
     ]
    }
   ],
   "source": [
    "ensemble_retriever_1 = EnsembleRetriever(retrievers=[retriever_bm25, retriever_naive], weights=[0.75, 0.25])\n",
    "result_ensemble1, results_df = run_and_evaluate(f\"Ensambler 1\", ensemble_retriever_1, prompt, llm, results_df)\n",
    "print(\"Ensambler\")\n",
    "print(result_ensemble1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "passing column names as 'ground_truths' is deprecated and will be removed in the next version, please use 'ground_truth' instead. Note that `ground_truth` should be of type string and not Sequence[string] like `ground_truths`\n",
      "Evaluating:  22%|██▏       | 13/60 [00:05<00:19,  2.47it/s]Runner in Executor raised an exception\n",
      "TypeError: expected string or buffer\n",
      "Evaluating:  33%|███▎      | 20/60 [00:05<00:08,  4.66it/s]Invalid JSON response. Expected dictionary with key 'question'\n",
      "Evaluating: 100%|██████████| 60/60 [00:09<00:00,  6.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average score is: 0.8646735668077402\n",
      "Ensambler\n",
      "        System  Faithfulness  Answer Relevancy  Context Precision  \\\n",
      "0  Ensambler 2      0.798848          0.843394           0.791111   \n",
      "\n",
      "   Context Recall  Answer Similarity  Answer Correctness   Average  \n",
      "0        0.961667           0.958949            0.834073  0.864674  \n"
     ]
    }
   ],
   "source": [
    "ensemble_retriever_2 = EnsembleRetriever(retrievers=[retriever_bm25, retriever_naive], weights=[0.5, 0.5])\n",
    "result_ensemble2, results_df = run_and_evaluate(f\"Ensambler 2\", ensemble_retriever_2, prompt, llm, results_df)\n",
    "print(\"Ensambler\")\n",
    "print(result_ensemble2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "passing column names as 'ground_truths' is deprecated and will be removed in the next version, please use 'ground_truth' instead. Note that `ground_truth` should be of type string and not Sequence[string] like `ground_truths`\n",
      "Evaluating: 100%|██████████| 60/60 [00:12<00:00,  4.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average score is: 0.8706332328374514\n",
      "Ensambler\n",
      "        System  Faithfulness  Answer Relevancy  Context Precision  \\\n",
      "0  Ensambler 3      0.957386          0.690303           0.980556   \n",
      "\n",
      "   Context Recall  Answer Similarity  Answer Correctness   Average  \n",
      "0        0.946429           0.955261            0.693865  0.870633  \n"
     ]
    }
   ],
   "source": [
    "ensemble_retriever_3 = EnsembleRetriever(retrievers=[retriever_bm25, retriever_naive], weights=[0.25,0.75])\n",
    "result_ensemble3, results_df = run_and_evaluate(f\"Ensambler 3\", ensemble_retriever_3, prompt, llm, results_df)\n",
    "print(\"Ensambler\")\n",
    "print(result_ensemble3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multi-stage - reranker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"COHERE_API_KEY\"] = getpass.getpass(\"Cohere API Key:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "passing column names as 'ground_truths' is deprecated and will be removed in the next version, please use 'ground_truth' instead. Note that `ground_truth` should be of type string and not Sequence[string] like `ground_truths`\n",
      "Evaluating: 100%|██████████| 60/60 [00:15<00:00,  3.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reranker\n",
      "{'faithfulness': 0.8968, 'answer_relevancy': 0.8880, 'context_precision': 0.9417, 'context_recall': 0.9750, 'answer_similarity': 0.9576, 'answer_correctness': 0.6623}\n",
      "The average score is: 0.8868849276357208\n"
     ]
    }
   ],
   "source": [
    "retriever_context = retriever_2000\n",
    "compressor = CohereRerank(top_n = 3)\n",
    "compression_retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=compressor, base_retriever=retriever_context\n",
    ")\n",
    "\n",
    "result_compression = run_and_evaluate(compression_retriever, prompt, llm)\n",
    "print(\"Reranker\")\n",
    "print(result_compression)\n",
    "avg_result_compression = dictionary(result_compression)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### creating context by remaking the query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>System</th>\n",
       "      <th>Faithfulness</th>\n",
       "      <th>Answer Relevancy</th>\n",
       "      <th>Context Precision</th>\n",
       "      <th>Context Recall</th>\n",
       "      <th>Answer Similarity</th>\n",
       "      <th>Answer Correctness</th>\n",
       "      <th>Average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GPT-3.5</td>\n",
       "      <td>0.947090</td>\n",
       "      <td>0.463838</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.900371</td>\n",
       "      <td>0.468007</td>\n",
       "      <td>0.639884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GPT-4</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.287687</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.909879</td>\n",
       "      <td>0.536392</td>\n",
       "      <td>0.632326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Naive</td>\n",
       "      <td>0.966518</td>\n",
       "      <td>0.917530</td>\n",
       "      <td>0.983333</td>\n",
       "      <td>0.975000</td>\n",
       "      <td>0.963399</td>\n",
       "      <td>0.776985</td>\n",
       "      <td>0.930461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Recursive</td>\n",
       "      <td>0.966518</td>\n",
       "      <td>0.737454</td>\n",
       "      <td>0.983333</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>0.963403</td>\n",
       "      <td>0.773308</td>\n",
       "      <td>0.897336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Chunk 500, overlap 0%</td>\n",
       "      <td>0.983333</td>\n",
       "      <td>0.925543</td>\n",
       "      <td>0.991667</td>\n",
       "      <td>0.946429</td>\n",
       "      <td>0.961035</td>\n",
       "      <td>0.671918</td>\n",
       "      <td>0.913321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Chunk 500, overlap 5%</td>\n",
       "      <td>0.974603</td>\n",
       "      <td>0.932008</td>\n",
       "      <td>0.991667</td>\n",
       "      <td>0.902778</td>\n",
       "      <td>0.960365</td>\n",
       "      <td>0.710475</td>\n",
       "      <td>0.911983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Chunk 500, overlap 10%</td>\n",
       "      <td>0.943386</td>\n",
       "      <td>0.807349</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.943333</td>\n",
       "      <td>0.962567</td>\n",
       "      <td>0.714292</td>\n",
       "      <td>0.886821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Chunk 500, overlap 15%</td>\n",
       "      <td>0.982143</td>\n",
       "      <td>0.898565</td>\n",
       "      <td>0.963889</td>\n",
       "      <td>0.977778</td>\n",
       "      <td>0.961660</td>\n",
       "      <td>0.667948</td>\n",
       "      <td>0.908664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Chunk 500, overlap 20%</td>\n",
       "      <td>0.954861</td>\n",
       "      <td>0.912232</td>\n",
       "      <td>0.955556</td>\n",
       "      <td>0.977778</td>\n",
       "      <td>0.961260</td>\n",
       "      <td>0.681888</td>\n",
       "      <td>0.907262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Chunk 1000, overlap 0%</td>\n",
       "      <td>0.987654</td>\n",
       "      <td>0.907493</td>\n",
       "      <td>0.983333</td>\n",
       "      <td>0.955000</td>\n",
       "      <td>0.959331</td>\n",
       "      <td>0.757576</td>\n",
       "      <td>0.925065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Chunk 1000, overlap 5%</td>\n",
       "      <td>0.984127</td>\n",
       "      <td>0.891685</td>\n",
       "      <td>0.975000</td>\n",
       "      <td>0.940000</td>\n",
       "      <td>0.961574</td>\n",
       "      <td>0.718890</td>\n",
       "      <td>0.911879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Chunk 1000, overlap 10%</td>\n",
       "      <td>0.987654</td>\n",
       "      <td>0.889549</td>\n",
       "      <td>0.983333</td>\n",
       "      <td>0.940000</td>\n",
       "      <td>0.961549</td>\n",
       "      <td>0.693724</td>\n",
       "      <td>0.909302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Chunk 1000, overlap 15%</td>\n",
       "      <td>0.987654</td>\n",
       "      <td>0.900701</td>\n",
       "      <td>0.983333</td>\n",
       "      <td>0.955000</td>\n",
       "      <td>0.962723</td>\n",
       "      <td>0.736066</td>\n",
       "      <td>0.920913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Chunk 1000, overlap 20%</td>\n",
       "      <td>0.953086</td>\n",
       "      <td>0.937404</td>\n",
       "      <td>0.983333</td>\n",
       "      <td>0.940000</td>\n",
       "      <td>0.962642</td>\n",
       "      <td>0.693313</td>\n",
       "      <td>0.911630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Chunk 2000, overlap 0%</td>\n",
       "      <td>0.949735</td>\n",
       "      <td>0.867421</td>\n",
       "      <td>0.975000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.963794</td>\n",
       "      <td>0.725964</td>\n",
       "      <td>0.913653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Chunk 2000, overlap 5%</td>\n",
       "      <td>0.968254</td>\n",
       "      <td>0.876055</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.971429</td>\n",
       "      <td>0.963941</td>\n",
       "      <td>0.751386</td>\n",
       "      <td>0.916289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Chunk 2000, overlap 10%</td>\n",
       "      <td>0.968750</td>\n",
       "      <td>0.769901</td>\n",
       "      <td>0.975000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.964368</td>\n",
       "      <td>0.706562</td>\n",
       "      <td>0.897430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Chunk 2000, overlap 15%</td>\n",
       "      <td>0.943452</td>\n",
       "      <td>0.781496</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.983333</td>\n",
       "      <td>0.964392</td>\n",
       "      <td>0.695192</td>\n",
       "      <td>0.889089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Chunk 2000, overlap 20%</td>\n",
       "      <td>0.964286</td>\n",
       "      <td>0.868970</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.963397</td>\n",
       "      <td>0.719633</td>\n",
       "      <td>0.913825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Chunk 3000, overlap 0%</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.853019</td>\n",
       "      <td>0.975000</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.963986</td>\n",
       "      <td>0.732118</td>\n",
       "      <td>0.909417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Chunk 3000, overlap 5%</td>\n",
       "      <td>0.968750</td>\n",
       "      <td>0.834882</td>\n",
       "      <td>0.975000</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.963353</td>\n",
       "      <td>0.715653</td>\n",
       "      <td>0.906273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Chunk 3000, overlap 10%</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.829536</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.965752</td>\n",
       "      <td>0.752239</td>\n",
       "      <td>0.906374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Chunk 3000, overlap 15%</td>\n",
       "      <td>0.873469</td>\n",
       "      <td>0.843047</td>\n",
       "      <td>0.975000</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.963603</td>\n",
       "      <td>0.701967</td>\n",
       "      <td>0.889515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Chunk 3000, overlap 20%</td>\n",
       "      <td>0.951389</td>\n",
       "      <td>0.856902</td>\n",
       "      <td>0.975000</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.965436</td>\n",
       "      <td>0.705722</td>\n",
       "      <td>0.905742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Chunk size 3000, overlap 20%, K=2</td>\n",
       "      <td>0.965608</td>\n",
       "      <td>0.814959</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.857778</td>\n",
       "      <td>0.961771</td>\n",
       "      <td>0.770368</td>\n",
       "      <td>0.895081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Chunk size 3000, overlap 20%, K=3</td>\n",
       "      <td>0.945833</td>\n",
       "      <td>0.906465</td>\n",
       "      <td>0.983333</td>\n",
       "      <td>0.877222</td>\n",
       "      <td>0.963646</td>\n",
       "      <td>0.731209</td>\n",
       "      <td>0.901285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Chunk size 3000, overlap 20%, K=5</td>\n",
       "      <td>0.864198</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.969306</td>\n",
       "      <td>0.971429</td>\n",
       "      <td>0.957138</td>\n",
       "      <td>0.638820</td>\n",
       "      <td>0.851129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Parent Retriever 1000-200</td>\n",
       "      <td>0.973765</td>\n",
       "      <td>0.821909</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.936111</td>\n",
       "      <td>0.961714</td>\n",
       "      <td>0.694279</td>\n",
       "      <td>0.897963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Parent Retriever 500-100</td>\n",
       "      <td>0.988889</td>\n",
       "      <td>0.912322</td>\n",
       "      <td>0.941667</td>\n",
       "      <td>0.952778</td>\n",
       "      <td>0.962236</td>\n",
       "      <td>0.731059</td>\n",
       "      <td>0.914825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Parent Retriever 1500-200</td>\n",
       "      <td>0.987500</td>\n",
       "      <td>0.643101</td>\n",
       "      <td>0.941667</td>\n",
       "      <td>0.952778</td>\n",
       "      <td>0.962287</td>\n",
       "      <td>0.689171</td>\n",
       "      <td>0.862750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>MMR</td>\n",
       "      <td>0.887066</td>\n",
       "      <td>0.616988</td>\n",
       "      <td>0.978668</td>\n",
       "      <td>0.783352</td>\n",
       "      <td>0.938080</td>\n",
       "      <td>0.844453</td>\n",
       "      <td>0.841435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>BM25</td>\n",
       "      <td>0.981481</td>\n",
       "      <td>0.896899</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>0.959879</td>\n",
       "      <td>0.707291</td>\n",
       "      <td>0.908981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Ensambler 1</td>\n",
       "      <td>0.943603</td>\n",
       "      <td>0.875975</td>\n",
       "      <td>0.945000</td>\n",
       "      <td>0.935000</td>\n",
       "      <td>0.962835</td>\n",
       "      <td>0.716237</td>\n",
       "      <td>0.896442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Ensambler 2</td>\n",
       "      <td>0.798848</td>\n",
       "      <td>0.843394</td>\n",
       "      <td>0.791111</td>\n",
       "      <td>0.961667</td>\n",
       "      <td>0.958949</td>\n",
       "      <td>0.834073</td>\n",
       "      <td>0.864674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Ensambler 3</td>\n",
       "      <td>0.957386</td>\n",
       "      <td>0.690303</td>\n",
       "      <td>0.980556</td>\n",
       "      <td>0.946429</td>\n",
       "      <td>0.955261</td>\n",
       "      <td>0.693865</td>\n",
       "      <td>0.870633</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               System  Faithfulness  Answer Relevancy  \\\n",
       "0                             GPT-3.5      0.947090          0.463838   \n",
       "1                               GPT-4      1.000000          0.287687   \n",
       "2                               Naive      0.966518          0.917530   \n",
       "3                           Recursive      0.966518          0.737454   \n",
       "4               Chunk 500, overlap 0%      0.983333          0.925543   \n",
       "5               Chunk 500, overlap 5%      0.974603          0.932008   \n",
       "6              Chunk 500, overlap 10%      0.943386          0.807349   \n",
       "7              Chunk 500, overlap 15%      0.982143          0.898565   \n",
       "8              Chunk 500, overlap 20%      0.954861          0.912232   \n",
       "9              Chunk 1000, overlap 0%      0.987654          0.907493   \n",
       "10             Chunk 1000, overlap 5%      0.984127          0.891685   \n",
       "11            Chunk 1000, overlap 10%      0.987654          0.889549   \n",
       "12            Chunk 1000, overlap 15%      0.987654          0.900701   \n",
       "13            Chunk 1000, overlap 20%      0.953086          0.937404   \n",
       "14             Chunk 2000, overlap 0%      0.949735          0.867421   \n",
       "15             Chunk 2000, overlap 5%      0.968254          0.876055   \n",
       "16            Chunk 2000, overlap 10%      0.968750          0.769901   \n",
       "17            Chunk 2000, overlap 15%      0.943452          0.781496   \n",
       "18            Chunk 2000, overlap 20%      0.964286          0.868970   \n",
       "19             Chunk 3000, overlap 0%      0.952381          0.853019   \n",
       "20             Chunk 3000, overlap 5%      0.968750          0.834882   \n",
       "21            Chunk 3000, overlap 10%      0.952381          0.829536   \n",
       "22            Chunk 3000, overlap 15%      0.873469          0.843047   \n",
       "23            Chunk 3000, overlap 20%      0.951389          0.856902   \n",
       "24  Chunk size 3000, overlap 20%, K=2      0.965608          0.814959   \n",
       "25  Chunk size 3000, overlap 20%, K=3      0.945833          0.906465   \n",
       "26  Chunk size 3000, overlap 20%, K=5      0.864198          0.705882   \n",
       "27          Parent Retriever 1000-200      0.973765          0.821909   \n",
       "28           Parent Retriever 500-100      0.988889          0.912322   \n",
       "29          Parent Retriever 1500-200      0.987500          0.643101   \n",
       "30                                MMR      0.887066          0.616988   \n",
       "31                               BM25      0.981481          0.896899   \n",
       "32                        Ensambler 1      0.943603          0.875975   \n",
       "33                        Ensambler 2      0.798848          0.843394   \n",
       "34                        Ensambler 3      0.957386          0.690303   \n",
       "\n",
       "    Context Precision  Context Recall  Answer Similarity  Answer Correctness  \\\n",
       "0                 NaN             NaN           0.900371            0.468007   \n",
       "1                 NaN             NaN           0.909879            0.536392   \n",
       "2            0.983333        0.975000           0.963399            0.776985   \n",
       "3            0.983333        0.960000           0.963403            0.773308   \n",
       "4            0.991667        0.946429           0.961035            0.671918   \n",
       "5            0.991667        0.902778           0.960365            0.710475   \n",
       "6            0.950000        0.943333           0.962567            0.714292   \n",
       "7            0.963889        0.977778           0.961660            0.667948   \n",
       "8            0.955556        0.977778           0.961260            0.681888   \n",
       "9            0.983333        0.955000           0.959331            0.757576   \n",
       "10           0.975000        0.940000           0.961574            0.718890   \n",
       "11           0.983333        0.940000           0.961549            0.693724   \n",
       "12           0.983333        0.955000           0.962723            0.736066   \n",
       "13           0.983333        0.940000           0.962642            0.693313   \n",
       "14           0.975000        1.000000           0.963794            0.725964   \n",
       "15           0.966667        0.971429           0.963941            0.751386   \n",
       "16           0.975000        1.000000           0.964368            0.706562   \n",
       "17           0.966667        0.983333           0.964392            0.695192   \n",
       "18           0.966667        1.000000           0.963397            0.719633   \n",
       "19           0.975000        0.980000           0.963986            0.732118   \n",
       "20           0.975000        0.980000           0.963353            0.715653   \n",
       "21           0.958333        0.980000           0.965752            0.752239   \n",
       "22           0.975000        0.980000           0.963603            0.701967   \n",
       "23           0.975000        0.980000           0.965436            0.705722   \n",
       "24           1.000000        0.857778           0.961771            0.770368   \n",
       "25           0.983333        0.877222           0.963646            0.731209   \n",
       "26           0.969306        0.971429           0.957138            0.638820   \n",
       "27           1.000000        0.936111           0.961714            0.694279   \n",
       "28           0.941667        0.952778           0.962236            0.731059   \n",
       "29           0.941667        0.952778           0.962287            0.689171   \n",
       "30           0.978668        0.783352           0.938080            0.844453   \n",
       "31           0.950000        0.958333           0.959879            0.707291   \n",
       "32           0.945000        0.935000           0.962835            0.716237   \n",
       "33           0.791111        0.961667           0.958949            0.834073   \n",
       "34           0.980556        0.946429           0.955261            0.693865   \n",
       "\n",
       "     Average  \n",
       "0   0.639884  \n",
       "1   0.632326  \n",
       "2   0.930461  \n",
       "3   0.897336  \n",
       "4   0.913321  \n",
       "5   0.911983  \n",
       "6   0.886821  \n",
       "7   0.908664  \n",
       "8   0.907262  \n",
       "9   0.925065  \n",
       "10  0.911879  \n",
       "11  0.909302  \n",
       "12  0.920913  \n",
       "13  0.911630  \n",
       "14  0.913653  \n",
       "15  0.916289  \n",
       "16  0.897430  \n",
       "17  0.889089  \n",
       "18  0.913825  \n",
       "19  0.909417  \n",
       "20  0.906273  \n",
       "21  0.906374  \n",
       "22  0.889515  \n",
       "23  0.905742  \n",
       "24  0.895081  \n",
       "25  0.901285  \n",
       "26  0.851129  \n",
       "27  0.897963  \n",
       "28  0.914825  \n",
       "29  0.862750  \n",
       "30  0.841435  \n",
       "31  0.908981  \n",
       "32  0.896442  \n",
       "33  0.864674  \n",
       "34  0.870633  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "template_context = \"Generate a search query to fetch the relevant documents using the user's {question}. Craft a query that specifically targets the keywords in the question. In the answer provide only the query.\"\n",
    "prompt_context = ChatPromptTemplate.from_template(template_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "passing column names as 'ground_truths' is deprecated and will be removed in the next version, please use 'ground_truth' instead. Note that `ground_truth` should be of type string and not Sequence[string] like `ground_truths`\n",
      "Evaluating: 100%|██████████| 60/60 [00:10<00:00,  5.66it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'faithfulness': 0.9467, 'answer_relevancy': 0.9207, 'context_precision': 0.9833, 'context_recall': 0.9550, 'answer_similarity': 0.9637, 'answer_correctness': 0.7499}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers_final = []\n",
    "contexts_final = []\n",
    "# retriever_context_q = EnsembleRetriever(retrievers=[retriever_bm25, retriever_3], weights=[0.5, 0.5])\n",
    "llm_for_context =(\n",
    "    { \"question\": itemgetter(\"question\")}\n",
    "    | RunnablePassthrough()\n",
    "    | {\"response\": prompt_context | llm}\n",
    ")\n",
    "for query in questions:\n",
    "    response_check = llm_for_context.invoke({\"question\": query})\n",
    "    search_query = response_check[\"response\"].content\n",
    "    retrieval_augmented_qa_chain = (\n",
    "        {\"context\": itemgetter(\"context\"), \"question\": itemgetter(\"question\")}\n",
    "        | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
    "        | {\"response\": prompt | llm, \"context\": itemgetter(\"context\")}\n",
    ")\n",
    "    docs = retriever_naive.get_relevant_documents(search_query)\n",
    "    formatted_docs = []\n",
    "    for doc in docs:\n",
    "        resulting_doc = doc.page_content\n",
    "        formatted_docs.append(resulting_doc)\n",
    "    try:  \n",
    "            response = retrieval_augmented_qa_chain.invoke({\"context\": formatted_docs, \"question\": query})\n",
    "            # Access the response content\n",
    "            answers_final.append(response[\"response\"].content)\n",
    "            contexts_final.append(formatted_docs)  \n",
    "    except Exception as e:  \n",
    "            print(f\"Warning: {e}\" + \"on the following question: \" + query)  \n",
    "            answers_final.append(\"No answer\")\n",
    "            contexts_final.append(formatted_docs)\n",
    "\n",
    "\n",
    "result_search_query = evaluation_rag(questions, answers_final, contexts_final, ground_truths)\n",
    "result_search_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average score is: 0.9198853575339109\n"
     ]
    }
   ],
   "source": [
    "average = dictionary(result_search_query)\n",
    "    # Create a dictionary to store the results\n",
    "system_results = {\n",
    "        \"System\": \"Search query\",\n",
    "        \"Faithfulness\": result_search_query[\"faithfulness\"],\n",
    "        \"Answer Relevancy\": result_search_query[\"answer_relevancy\"],\n",
    "        \"Context Precision\": result_search_query[\"context_precision\"],\n",
    "        \"Context Recall\": result_search_query[\"context_recall\"],\n",
    "        \"Answer Similarity\": result_search_query[\"answer_similarity\"],\n",
    "        \"Answer Correctness\": result_search_query[\"answer_correctness\"],\n",
    "        \"Average\": average\n",
    "    }\n",
    "df_result_search_query = pd.DataFrame([system_results])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>System</th>\n",
       "      <th>Faithfulness</th>\n",
       "      <th>Answer Relevancy</th>\n",
       "      <th>Context Precision</th>\n",
       "      <th>Context Recall</th>\n",
       "      <th>Answer Similarity</th>\n",
       "      <th>Answer Correctness</th>\n",
       "      <th>Average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GPT-3.5</td>\n",
       "      <td>0.947090</td>\n",
       "      <td>0.463838</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.900371</td>\n",
       "      <td>0.468007</td>\n",
       "      <td>0.639884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GPT-4</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.287687</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.909879</td>\n",
       "      <td>0.536392</td>\n",
       "      <td>0.632326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Naive</td>\n",
       "      <td>0.966518</td>\n",
       "      <td>0.917530</td>\n",
       "      <td>0.983333</td>\n",
       "      <td>0.975000</td>\n",
       "      <td>0.963399</td>\n",
       "      <td>0.776985</td>\n",
       "      <td>0.930461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Recursive</td>\n",
       "      <td>0.966518</td>\n",
       "      <td>0.737454</td>\n",
       "      <td>0.983333</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>0.963403</td>\n",
       "      <td>0.773308</td>\n",
       "      <td>0.897336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Chunk 500, overlap 0%</td>\n",
       "      <td>0.983333</td>\n",
       "      <td>0.925543</td>\n",
       "      <td>0.991667</td>\n",
       "      <td>0.946429</td>\n",
       "      <td>0.961035</td>\n",
       "      <td>0.671918</td>\n",
       "      <td>0.913321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Chunk 500, overlap 5%</td>\n",
       "      <td>0.974603</td>\n",
       "      <td>0.932008</td>\n",
       "      <td>0.991667</td>\n",
       "      <td>0.902778</td>\n",
       "      <td>0.960365</td>\n",
       "      <td>0.710475</td>\n",
       "      <td>0.911983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Chunk 500, overlap 10%</td>\n",
       "      <td>0.943386</td>\n",
       "      <td>0.807349</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.943333</td>\n",
       "      <td>0.962567</td>\n",
       "      <td>0.714292</td>\n",
       "      <td>0.886821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Chunk 500, overlap 15%</td>\n",
       "      <td>0.982143</td>\n",
       "      <td>0.898565</td>\n",
       "      <td>0.963889</td>\n",
       "      <td>0.977778</td>\n",
       "      <td>0.961660</td>\n",
       "      <td>0.667948</td>\n",
       "      <td>0.908664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Chunk 500, overlap 20%</td>\n",
       "      <td>0.954861</td>\n",
       "      <td>0.912232</td>\n",
       "      <td>0.955556</td>\n",
       "      <td>0.977778</td>\n",
       "      <td>0.961260</td>\n",
       "      <td>0.681888</td>\n",
       "      <td>0.907262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Chunk 1000, overlap 0%</td>\n",
       "      <td>0.987654</td>\n",
       "      <td>0.907493</td>\n",
       "      <td>0.983333</td>\n",
       "      <td>0.955000</td>\n",
       "      <td>0.959331</td>\n",
       "      <td>0.757576</td>\n",
       "      <td>0.925065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Chunk 1000, overlap 5%</td>\n",
       "      <td>0.984127</td>\n",
       "      <td>0.891685</td>\n",
       "      <td>0.975000</td>\n",
       "      <td>0.940000</td>\n",
       "      <td>0.961574</td>\n",
       "      <td>0.718890</td>\n",
       "      <td>0.911879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Chunk 1000, overlap 10%</td>\n",
       "      <td>0.987654</td>\n",
       "      <td>0.889549</td>\n",
       "      <td>0.983333</td>\n",
       "      <td>0.940000</td>\n",
       "      <td>0.961549</td>\n",
       "      <td>0.693724</td>\n",
       "      <td>0.909302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Chunk 1000, overlap 15%</td>\n",
       "      <td>0.987654</td>\n",
       "      <td>0.900701</td>\n",
       "      <td>0.983333</td>\n",
       "      <td>0.955000</td>\n",
       "      <td>0.962723</td>\n",
       "      <td>0.736066</td>\n",
       "      <td>0.920913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Chunk 1000, overlap 20%</td>\n",
       "      <td>0.953086</td>\n",
       "      <td>0.937404</td>\n",
       "      <td>0.983333</td>\n",
       "      <td>0.940000</td>\n",
       "      <td>0.962642</td>\n",
       "      <td>0.693313</td>\n",
       "      <td>0.911630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Chunk 2000, overlap 0%</td>\n",
       "      <td>0.949735</td>\n",
       "      <td>0.867421</td>\n",
       "      <td>0.975000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.963794</td>\n",
       "      <td>0.725964</td>\n",
       "      <td>0.913653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Chunk 2000, overlap 5%</td>\n",
       "      <td>0.968254</td>\n",
       "      <td>0.876055</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.971429</td>\n",
       "      <td>0.963941</td>\n",
       "      <td>0.751386</td>\n",
       "      <td>0.916289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Chunk 2000, overlap 10%</td>\n",
       "      <td>0.968750</td>\n",
       "      <td>0.769901</td>\n",
       "      <td>0.975000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.964368</td>\n",
       "      <td>0.706562</td>\n",
       "      <td>0.897430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Chunk 2000, overlap 15%</td>\n",
       "      <td>0.943452</td>\n",
       "      <td>0.781496</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.983333</td>\n",
       "      <td>0.964392</td>\n",
       "      <td>0.695192</td>\n",
       "      <td>0.889089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Chunk 2000, overlap 20%</td>\n",
       "      <td>0.964286</td>\n",
       "      <td>0.868970</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.963397</td>\n",
       "      <td>0.719633</td>\n",
       "      <td>0.913825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Chunk 3000, overlap 0%</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.853019</td>\n",
       "      <td>0.975000</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.963986</td>\n",
       "      <td>0.732118</td>\n",
       "      <td>0.909417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Chunk 3000, overlap 5%</td>\n",
       "      <td>0.968750</td>\n",
       "      <td>0.834882</td>\n",
       "      <td>0.975000</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.963353</td>\n",
       "      <td>0.715653</td>\n",
       "      <td>0.906273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Chunk 3000, overlap 10%</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.829536</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.965752</td>\n",
       "      <td>0.752239</td>\n",
       "      <td>0.906374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Chunk 3000, overlap 15%</td>\n",
       "      <td>0.873469</td>\n",
       "      <td>0.843047</td>\n",
       "      <td>0.975000</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.963603</td>\n",
       "      <td>0.701967</td>\n",
       "      <td>0.889515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Chunk 3000, overlap 20%</td>\n",
       "      <td>0.951389</td>\n",
       "      <td>0.856902</td>\n",
       "      <td>0.975000</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.965436</td>\n",
       "      <td>0.705722</td>\n",
       "      <td>0.905742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Chunk size 3000, overlap 20%, K=2</td>\n",
       "      <td>0.965608</td>\n",
       "      <td>0.814959</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.857778</td>\n",
       "      <td>0.961771</td>\n",
       "      <td>0.770368</td>\n",
       "      <td>0.895081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Chunk size 3000, overlap 20%, K=3</td>\n",
       "      <td>0.945833</td>\n",
       "      <td>0.906465</td>\n",
       "      <td>0.983333</td>\n",
       "      <td>0.877222</td>\n",
       "      <td>0.963646</td>\n",
       "      <td>0.731209</td>\n",
       "      <td>0.901285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Chunk size 3000, overlap 20%, K=5</td>\n",
       "      <td>0.864198</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.969306</td>\n",
       "      <td>0.971429</td>\n",
       "      <td>0.957138</td>\n",
       "      <td>0.638820</td>\n",
       "      <td>0.851129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Parent Retriever 1000-200</td>\n",
       "      <td>0.973765</td>\n",
       "      <td>0.821909</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.936111</td>\n",
       "      <td>0.961714</td>\n",
       "      <td>0.694279</td>\n",
       "      <td>0.897963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Parent Retriever 500-100</td>\n",
       "      <td>0.988889</td>\n",
       "      <td>0.912322</td>\n",
       "      <td>0.941667</td>\n",
       "      <td>0.952778</td>\n",
       "      <td>0.962236</td>\n",
       "      <td>0.731059</td>\n",
       "      <td>0.914825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Parent Retriever 1500-200</td>\n",
       "      <td>0.987500</td>\n",
       "      <td>0.643101</td>\n",
       "      <td>0.941667</td>\n",
       "      <td>0.952778</td>\n",
       "      <td>0.962287</td>\n",
       "      <td>0.689171</td>\n",
       "      <td>0.862750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>MMR</td>\n",
       "      <td>0.887066</td>\n",
       "      <td>0.616988</td>\n",
       "      <td>0.978668</td>\n",
       "      <td>0.783352</td>\n",
       "      <td>0.938080</td>\n",
       "      <td>0.844453</td>\n",
       "      <td>0.841435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>BM25</td>\n",
       "      <td>0.981481</td>\n",
       "      <td>0.896899</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>0.959879</td>\n",
       "      <td>0.707291</td>\n",
       "      <td>0.908981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Ensambler 1</td>\n",
       "      <td>0.943603</td>\n",
       "      <td>0.875975</td>\n",
       "      <td>0.945000</td>\n",
       "      <td>0.935000</td>\n",
       "      <td>0.962835</td>\n",
       "      <td>0.716237</td>\n",
       "      <td>0.896442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Ensambler 2</td>\n",
       "      <td>0.798848</td>\n",
       "      <td>0.843394</td>\n",
       "      <td>0.791111</td>\n",
       "      <td>0.961667</td>\n",
       "      <td>0.958949</td>\n",
       "      <td>0.834073</td>\n",
       "      <td>0.864674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Ensambler 3</td>\n",
       "      <td>0.957386</td>\n",
       "      <td>0.690303</td>\n",
       "      <td>0.980556</td>\n",
       "      <td>0.946429</td>\n",
       "      <td>0.955261</td>\n",
       "      <td>0.693865</td>\n",
       "      <td>0.870633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Search query</td>\n",
       "      <td>0.946667</td>\n",
       "      <td>0.920721</td>\n",
       "      <td>0.983333</td>\n",
       "      <td>0.955000</td>\n",
       "      <td>0.963712</td>\n",
       "      <td>0.749879</td>\n",
       "      <td>0.919885</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               System  Faithfulness  Answer Relevancy  \\\n",
       "0                             GPT-3.5      0.947090          0.463838   \n",
       "1                               GPT-4      1.000000          0.287687   \n",
       "2                               Naive      0.966518          0.917530   \n",
       "3                           Recursive      0.966518          0.737454   \n",
       "4               Chunk 500, overlap 0%      0.983333          0.925543   \n",
       "5               Chunk 500, overlap 5%      0.974603          0.932008   \n",
       "6              Chunk 500, overlap 10%      0.943386          0.807349   \n",
       "7              Chunk 500, overlap 15%      0.982143          0.898565   \n",
       "8              Chunk 500, overlap 20%      0.954861          0.912232   \n",
       "9              Chunk 1000, overlap 0%      0.987654          0.907493   \n",
       "10             Chunk 1000, overlap 5%      0.984127          0.891685   \n",
       "11            Chunk 1000, overlap 10%      0.987654          0.889549   \n",
       "12            Chunk 1000, overlap 15%      0.987654          0.900701   \n",
       "13            Chunk 1000, overlap 20%      0.953086          0.937404   \n",
       "14             Chunk 2000, overlap 0%      0.949735          0.867421   \n",
       "15             Chunk 2000, overlap 5%      0.968254          0.876055   \n",
       "16            Chunk 2000, overlap 10%      0.968750          0.769901   \n",
       "17            Chunk 2000, overlap 15%      0.943452          0.781496   \n",
       "18            Chunk 2000, overlap 20%      0.964286          0.868970   \n",
       "19             Chunk 3000, overlap 0%      0.952381          0.853019   \n",
       "20             Chunk 3000, overlap 5%      0.968750          0.834882   \n",
       "21            Chunk 3000, overlap 10%      0.952381          0.829536   \n",
       "22            Chunk 3000, overlap 15%      0.873469          0.843047   \n",
       "23            Chunk 3000, overlap 20%      0.951389          0.856902   \n",
       "24  Chunk size 3000, overlap 20%, K=2      0.965608          0.814959   \n",
       "25  Chunk size 3000, overlap 20%, K=3      0.945833          0.906465   \n",
       "26  Chunk size 3000, overlap 20%, K=5      0.864198          0.705882   \n",
       "27          Parent Retriever 1000-200      0.973765          0.821909   \n",
       "28           Parent Retriever 500-100      0.988889          0.912322   \n",
       "29          Parent Retriever 1500-200      0.987500          0.643101   \n",
       "30                                MMR      0.887066          0.616988   \n",
       "31                               BM25      0.981481          0.896899   \n",
       "32                        Ensambler 1      0.943603          0.875975   \n",
       "33                        Ensambler 2      0.798848          0.843394   \n",
       "34                        Ensambler 3      0.957386          0.690303   \n",
       "35                       Search query      0.946667          0.920721   \n",
       "\n",
       "    Context Precision  Context Recall  Answer Similarity  Answer Correctness  \\\n",
       "0                 NaN             NaN           0.900371            0.468007   \n",
       "1                 NaN             NaN           0.909879            0.536392   \n",
       "2            0.983333        0.975000           0.963399            0.776985   \n",
       "3            0.983333        0.960000           0.963403            0.773308   \n",
       "4            0.991667        0.946429           0.961035            0.671918   \n",
       "5            0.991667        0.902778           0.960365            0.710475   \n",
       "6            0.950000        0.943333           0.962567            0.714292   \n",
       "7            0.963889        0.977778           0.961660            0.667948   \n",
       "8            0.955556        0.977778           0.961260            0.681888   \n",
       "9            0.983333        0.955000           0.959331            0.757576   \n",
       "10           0.975000        0.940000           0.961574            0.718890   \n",
       "11           0.983333        0.940000           0.961549            0.693724   \n",
       "12           0.983333        0.955000           0.962723            0.736066   \n",
       "13           0.983333        0.940000           0.962642            0.693313   \n",
       "14           0.975000        1.000000           0.963794            0.725964   \n",
       "15           0.966667        0.971429           0.963941            0.751386   \n",
       "16           0.975000        1.000000           0.964368            0.706562   \n",
       "17           0.966667        0.983333           0.964392            0.695192   \n",
       "18           0.966667        1.000000           0.963397            0.719633   \n",
       "19           0.975000        0.980000           0.963986            0.732118   \n",
       "20           0.975000        0.980000           0.963353            0.715653   \n",
       "21           0.958333        0.980000           0.965752            0.752239   \n",
       "22           0.975000        0.980000           0.963603            0.701967   \n",
       "23           0.975000        0.980000           0.965436            0.705722   \n",
       "24           1.000000        0.857778           0.961771            0.770368   \n",
       "25           0.983333        0.877222           0.963646            0.731209   \n",
       "26           0.969306        0.971429           0.957138            0.638820   \n",
       "27           1.000000        0.936111           0.961714            0.694279   \n",
       "28           0.941667        0.952778           0.962236            0.731059   \n",
       "29           0.941667        0.952778           0.962287            0.689171   \n",
       "30           0.978668        0.783352           0.938080            0.844453   \n",
       "31           0.950000        0.958333           0.959879            0.707291   \n",
       "32           0.945000        0.935000           0.962835            0.716237   \n",
       "33           0.791111        0.961667           0.958949            0.834073   \n",
       "34           0.980556        0.946429           0.955261            0.693865   \n",
       "35           0.983333        0.955000           0.963712            0.749879   \n",
       "\n",
       "     Average  \n",
       "0   0.639884  \n",
       "1   0.632326  \n",
       "2   0.930461  \n",
       "3   0.897336  \n",
       "4   0.913321  \n",
       "5   0.911983  \n",
       "6   0.886821  \n",
       "7   0.908664  \n",
       "8   0.907262  \n",
       "9   0.925065  \n",
       "10  0.911879  \n",
       "11  0.909302  \n",
       "12  0.920913  \n",
       "13  0.911630  \n",
       "14  0.913653  \n",
       "15  0.916289  \n",
       "16  0.897430  \n",
       "17  0.889089  \n",
       "18  0.913825  \n",
       "19  0.909417  \n",
       "20  0.906273  \n",
       "21  0.906374  \n",
       "22  0.889515  \n",
       "23  0.905742  \n",
       "24  0.895081  \n",
       "25  0.901285  \n",
       "26  0.851129  \n",
       "27  0.897963  \n",
       "28  0.914825  \n",
       "29  0.862750  \n",
       "30  0.841435  \n",
       "31  0.908981  \n",
       "32  0.896442  \n",
       "33  0.864674  \n",
       "34  0.870633  \n",
       "35  0.919885  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df = pd.concat([results_df, df_result_search_query], ignore_index=True)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### change model to GPT-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>System</th>\n",
       "      <th>Faithfulness</th>\n",
       "      <th>Answer Relevancy</th>\n",
       "      <th>Context Precision</th>\n",
       "      <th>Context Recall</th>\n",
       "      <th>Answer Similarity</th>\n",
       "      <th>Answer Correctness</th>\n",
       "      <th>Average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Naive</td>\n",
       "      <td>0.966518</td>\n",
       "      <td>0.917530</td>\n",
       "      <td>0.983333</td>\n",
       "      <td>0.975</td>\n",
       "      <td>0.963399</td>\n",
       "      <td>0.776985</td>\n",
       "      <td>0.930461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Chunk 1000, overlap 0%</td>\n",
       "      <td>0.987654</td>\n",
       "      <td>0.907493</td>\n",
       "      <td>0.983333</td>\n",
       "      <td>0.955</td>\n",
       "      <td>0.959331</td>\n",
       "      <td>0.757576</td>\n",
       "      <td>0.925065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Chunk 1000, overlap 15%</td>\n",
       "      <td>0.987654</td>\n",
       "      <td>0.900701</td>\n",
       "      <td>0.983333</td>\n",
       "      <td>0.955</td>\n",
       "      <td>0.962723</td>\n",
       "      <td>0.736066</td>\n",
       "      <td>0.920913</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     System  Faithfulness  Answer Relevancy  \\\n",
       "2                     Naive      0.966518          0.917530   \n",
       "9    Chunk 1000, overlap 0%      0.987654          0.907493   \n",
       "12  Chunk 1000, overlap 15%      0.987654          0.900701   \n",
       "\n",
       "    Context Precision  Context Recall  Answer Similarity  Answer Correctness  \\\n",
       "2            0.983333           0.975           0.963399            0.776985   \n",
       "9            0.983333           0.955           0.959331            0.757576   \n",
       "12           0.983333           0.955           0.962723            0.736066   \n",
       "\n",
       "     Average  \n",
       "2   0.930461  \n",
       "9   0.925065  \n",
       "12  0.920913  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_3_highest = results_df.nlargest(3, \"Average\")\n",
    "top_3_highest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_gpt4 = AzureChatOpenAI(model_name=OPENAI_MODEL_GPT4, azure_deployment=OPENAI_DEPLOYMENT_GPT4,temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "passing column names as 'ground_truths' is deprecated and will be removed in the next version, please use 'ground_truth' instead. Note that `ground_truth` should be of type string and not Sequence[string] like `ground_truths`\n",
      "Evaluating: 100%|██████████| 60/60 [00:12<00:00,  4.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average score is: 0.9256730362654243\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>System</th>\n",
       "      <th>Faithfulness</th>\n",
       "      <th>Answer Relevancy</th>\n",
       "      <th>Context Precision</th>\n",
       "      <th>Context Recall</th>\n",
       "      <th>Answer Similarity</th>\n",
       "      <th>Answer Correctness</th>\n",
       "      <th>Average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Naive retriever, GPT-4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.915748</td>\n",
       "      <td>0.991667</td>\n",
       "      <td>0.975</td>\n",
       "      <td>0.961886</td>\n",
       "      <td>0.709738</td>\n",
       "      <td>0.925673</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   System  Faithfulness  Answer Relevancy  Context Precision  \\\n",
       "0  Naive retriever, GPT-4           1.0          0.915748           0.991667   \n",
       "\n",
       "   Context Recall  Answer Similarity  Answer Correctness   Average  \n",
       "0           0.975           0.961886            0.709738  0.925673  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_gpt4_naive, results_df = run_and_evaluate(f\"Naive retriever, GPT-4\", retriever_naive, prompt, llm_gpt4, results_df)\n",
    "result_gpt4_naive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "passing column names as 'ground_truths' is deprecated and will be removed in the next version, please use 'ground_truth' instead. Note that `ground_truth` should be of type string and not Sequence[string] like `ground_truths`\n",
      "Evaluating: 100%|██████████| 60/60 [00:14<00:00,  4.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average score is: 0.9043818126079827\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>System</th>\n",
       "      <th>Faithfulness</th>\n",
       "      <th>Answer Relevancy</th>\n",
       "      <th>Context Precision</th>\n",
       "      <th>Context Recall</th>\n",
       "      <th>Answer Similarity</th>\n",
       "      <th>Answer Correctness</th>\n",
       "      <th>Average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Chunk 1000, overlap 0%, GPT-4</td>\n",
       "      <td>0.9875</td>\n",
       "      <td>0.814894</td>\n",
       "      <td>0.975</td>\n",
       "      <td>0.955</td>\n",
       "      <td>0.961471</td>\n",
       "      <td>0.732427</td>\n",
       "      <td>0.904382</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          System  Faithfulness  Answer Relevancy  \\\n",
       "0  Chunk 1000, overlap 0%, GPT-4        0.9875          0.814894   \n",
       "\n",
       "   Context Precision  Context Recall  Answer Similarity  Answer Correctness  \\\n",
       "0              0.975           0.955           0.961471            0.732427   \n",
       "\n",
       "    Average  \n",
       "0  0.904382  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db_0 = Chroma(persist_directory = \"../news/vectordb-edit/chunking_1000_0\", embedding_function=embeddings_client)\n",
    "ret_0 = db_0.as_retriever()\n",
    "result_1000_0_gpt4, results_df = run_and_evaluate(f\"Chunk 1000, overlap 0%, GPT-4\", ret_0, prompt, llm_gpt4, results_df)\n",
    "result_1000_0_gpt4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "passing column names as 'ground_truths' is deprecated and will be removed in the next version, please use 'ground_truth' instead. Note that `ground_truth` should be of type string and not Sequence[string] like `ground_truths`\n",
      "Evaluating: 100%|██████████| 60/60 [00:09<00:00,  6.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average score is: 0.9038339747221363\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>System</th>\n",
       "      <th>Faithfulness</th>\n",
       "      <th>Answer Relevancy</th>\n",
       "      <th>Context Precision</th>\n",
       "      <th>Context Recall</th>\n",
       "      <th>Answer Similarity</th>\n",
       "      <th>Answer Correctness</th>\n",
       "      <th>Average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Chunk 1000, overlap 15%, GPT-4</td>\n",
       "      <td>0.970833</td>\n",
       "      <td>0.882859</td>\n",
       "      <td>0.983333</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.964804</td>\n",
       "      <td>0.681174</td>\n",
       "      <td>0.903834</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           System  Faithfulness  Answer Relevancy  \\\n",
       "0  Chunk 1000, overlap 15%, GPT-4      0.970833          0.882859   \n",
       "\n",
       "   Context Precision  Context Recall  Answer Similarity  Answer Correctness  \\\n",
       "0           0.983333            0.94           0.964804            0.681174   \n",
       "\n",
       "    Average  \n",
       "0  0.903834  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db_15 = Chroma(persist_directory = \"../news/vectordb-edit/chunking_1000_15\", embedding_function=embeddings_client)\n",
    "ret_15 = db_15.as_retriever()\n",
    "result_1000_15_gpt4, results_df = run_and_evaluate(f\"Chunk 1000, overlap 15%, GPT-4\", ret_15, prompt, llm_gpt4, results_df)\n",
    "result_1000_15_gpt4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.to_csv(f\"../news/results/results_summary.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
