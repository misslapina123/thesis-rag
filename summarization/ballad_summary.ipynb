{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import dotenv\n",
    "from langchain.text_splitter import CharacterTextSplitter, RecursiveCharacterTextSplitter\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.document_loaders import DirectoryLoader\n",
    "from langchain_openai import AzureOpenAIEmbeddings\n",
    "dotenv.load_dotenv()\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from ragas import evaluate\n",
    "from ragas.metrics import (\n",
    "    faithfulness,\n",
    "    answer_relevancy,\n",
    "    context_recall,\n",
    "    context_precision,\n",
    "    answer_similarity,\n",
    "    answer_correctness,\n",
    ")\n",
    "from datasets import Dataset\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "from operator import itemgetter\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.tracebacklimit = 0\n",
    "from langchain_community.document_loaders import PyPDFLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_API_KEY = os.environ.get(\"OPENAI_API_KEY\")\n",
    "OPENAI_API_VERSION = os.environ.get(\"OPENAI_API_VERSION\")\n",
    "AZURE_OPENAI_ENDPOINT = os.environ.get(\"AZURE_OPENAI_ENDPOINT\")\n",
    "OPENAI_MODEL = os.environ.get(\"OPENAI_MODEL\")\n",
    "OPENAI_DEPLOYMENT = os.environ.get(\"OPENAI_DEPLOYMENT\")\n",
    "EMBEDDING_MODEL = os.environ.get(\"EMBEDDING_MODEL\")\n",
    "EMBEDDING_DEPLOYMENT = os.environ.get(\"EMBEDDING_DEPLOYMENT\")\n",
    "OPENAI_MODEL_GPT4 = os.environ.get(\"OPENAI_MODEL_GPT4\")\n",
    "OPENAI_DEPLOYMENT_GPT4 = os.environ.get(\"OPENAI_DEPLOYMENT_GPT4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_client = AzureOpenAIEmbeddings(\n",
    "    azure_deployment=EMBEDDING_DEPLOYMENT,\n",
    "    openai_api_version=OPENAI_API_VERSION)\n",
    "llm = AzureChatOpenAI(model_name=OPENAI_MODEL, azure_deployment=OPENAI_DEPLOYMENT,temperature=0)\n",
    "llm_gpt4 = AzureChatOpenAI(model_name=OPENAI_MODEL_GPT4, azure_deployment=OPENAI_DEPLOYMENT_GPT4,temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation_llm(questions, answers, contexts, ground_truths):\n",
    "    data = {\n",
    "        \"question\": questions,\n",
    "        \"answer\": answers,\n",
    "        \"contexts\": contexts,\n",
    "        \"ground_truths\": ground_truths\n",
    "    }\n",
    "    dataset = Dataset.from_dict(data)\n",
    "    azure_configs = {\n",
    "        \"base_url\": AZURE_OPENAI_ENDPOINT,\n",
    "        \"model_deployment\": OPENAI_DEPLOYMENT,\n",
    "        \"model_name\": OPENAI_MODEL,\n",
    "        \"embedding_deployment\": EMBEDDING_DEPLOYMENT,\n",
    "        \"embedding_name\": EMBEDDING_MODEL,  \n",
    "    }\n",
    "\n",
    "    azure_model = AzureChatOpenAI(\n",
    "        openai_api_version=OPENAI_API_VERSION,\n",
    "        azure_endpoint=azure_configs[\"base_url\"],\n",
    "        azure_deployment=azure_configs[\"model_deployment\"],\n",
    "        model=azure_configs[\"model_name\"],\n",
    "        validate_base_url=False,\n",
    "    )\n",
    "\n",
    "    azure_embeddings = AzureOpenAIEmbeddings(\n",
    "        openai_api_version=OPENAI_API_VERSION,\n",
    "        azure_endpoint=azure_configs[\"base_url\"],\n",
    "        azure_deployment=azure_configs[\"embedding_deployment\"],\n",
    "        model=azure_configs[\"embedding_name\"],\n",
    "    )\n",
    "    result = evaluate(\n",
    "        dataset = dataset, \n",
    "        metrics=[\n",
    "            faithfulness,\n",
    "            answer_relevancy,\n",
    "            answer_similarity,\n",
    "            answer_correctness,\n",
    "        ], \n",
    "        llm=azure_model, \n",
    "        embeddings=azure_embeddings,\n",
    "    )\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation_rag(questions, answers, contexts, ground_truths):\n",
    "    data = {\n",
    "        \"question\": questions,\n",
    "        \"answer\": answers,\n",
    "        \"contexts\": contexts,\n",
    "        \"ground_truths\": ground_truths\n",
    "    }\n",
    "    dataset = Dataset.from_dict(data)\n",
    "    azure_configs = {\n",
    "        \"base_url\": AZURE_OPENAI_ENDPOINT,\n",
    "        \"model_deployment\": OPENAI_DEPLOYMENT,\n",
    "        \"model_name\": OPENAI_MODEL,\n",
    "        \"embedding_deployment\": EMBEDDING_DEPLOYMENT,\n",
    "        \"embedding_name\": EMBEDDING_MODEL,  # most likely\n",
    "    }\n",
    "\n",
    "    azure_model = AzureChatOpenAI(\n",
    "        openai_api_version=OPENAI_API_VERSION,\n",
    "        azure_endpoint=azure_configs[\"base_url\"],\n",
    "        azure_deployment=azure_configs[\"model_deployment\"],\n",
    "        model=azure_configs[\"model_name\"],\n",
    "        validate_base_url=False,\n",
    "    )\n",
    "\n",
    "    azure_embeddings = AzureOpenAIEmbeddings(\n",
    "        openai_api_version=OPENAI_API_VERSION,\n",
    "        azure_endpoint=azure_configs[\"base_url\"],\n",
    "        azure_deployment=azure_configs[\"embedding_deployment\"],\n",
    "        model=azure_configs[\"embedding_name\"],\n",
    "    )\n",
    "    result = evaluate(\n",
    "        dataset = dataset, \n",
    "        metrics=[\n",
    "            faithfulness,\n",
    "            answer_relevancy,\n",
    "            context_precision,\n",
    "            context_recall,\n",
    "            answer_similarity,\n",
    "            answer_correctness,\n",
    "        ], \n",
    "        llm=azure_model, \n",
    "        embeddings=azure_embeddings,\n",
    "        raise_exceptions=False,\n",
    "    )\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\"System\", \"Faithfulness\", \"Answer Relevancy\", \"Context Precision\", \"Context Recall\", \"Answer Similarity\", \"Answer Correctness\"]\n",
    "results_df = pd.DataFrame(columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_average = 0\n",
    "def find_highest(average_score):\n",
    "    global max_average\n",
    "    if average_score > max_average:\n",
    "        max_average = average_score\n",
    "        print(\"This is the new best value!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dictionary(result):\n",
    "    dict_result = dict(result)\n",
    "    average_score = sum(dict_result.values()) / len(dict_result)\n",
    "    print(f\"The average score is: {average_score}\")\n",
    "    find_highest(average_score)\n",
    "    return average_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_system(system_name, questions, answers, contexts, ground_truths):\n",
    "    result = evaluation_rag(questions, answers, contexts, ground_truths)\n",
    "    average = dictionary(result)\n",
    "    # Create a dictionary to store the results\n",
    "    system_results = {\n",
    "        \"System\": system_name,\n",
    "        \"Faithfulness\": result[\"faithfulness\"],\n",
    "        \"Answer Relevancy\": result[\"answer_relevancy\"],\n",
    "        \"Context Precision\": result[\"context_precision\"],\n",
    "        \"Context Recall\": result[\"context_recall\"],\n",
    "        \"Answer Similarity\": result[\"answer_similarity\"],\n",
    "        \"Answer Correctness\": result[\"answer_correctness\"],\n",
    "        \"Average\": average\n",
    "    }\n",
    "    df_system_results = pd.DataFrame([system_results])\n",
    "    return df_system_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_LLM(system_name, questions, answers, contexts, ground_truths):\n",
    "    result = evaluation_rag(questions, answers, contexts, ground_truths)\n",
    "    average = dictionary(result)\n",
    "    # Create a dictionary to store the results\n",
    "    system_results = {\n",
    "        \"System\": system_name,\n",
    "        \"Faithfulness\": result[\"faithfulness\"],\n",
    "        \"Answer Relevancy\": result[\"answer_relevancy\"],\n",
    "        \"Context Precision\": np.nan,\n",
    "        \"Context Recall\": np.nan,\n",
    "        \"Answer Similarity\": result[\"answer_similarity\"],\n",
    "        \"Answer Correctness\": result[\"answer_correctness\"],\n",
    "        \"Average\": average\n",
    "    }\n",
    "    df_llm_results = pd.DataFrame([system_results])\n",
    "    return df_llm_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = [\n",
    "    \"Character analysis of Sejanus Plinth\",\n",
    "    \"Character analysis of Lucy Gray\",\n",
    "    \"Character analysis of Tigris Snow\",\n",
    "    \"What are the places 1-10 in the 10th Hunger Games?\",\n",
    "    \"How does Lucy Gray win the 10th Hunger games?\",\n",
    "    \"How and Who Came Up with the Hunger Games?\",\n",
    "    \"Why did Snow join the mentorship program in The Ballad of Songbirds and Snake?\",\n",
    "    \"What idea does Snow present to the Head Game Maker Volumnia Gaul?\",\n",
    "    \"What evidence does Snow secretly record and send to Dr. Gaul, and what is the result of that?\",\n",
    "    \"How do Snow and Lucy gain popularity in the Capitol?\"\n",
    "]\n",
    "\n",
    "\n",
    "ground_truths = [\n",
    "    [\"Sejanus is one of Coriolanus’s classmates and a mentor in the Hunger Games. Coriolanus and many of his classmates treat Sejanus coldly, as Sejanus isn’t Capitol-born. Rather, his father, a munitions magnate from District Two, bought his way into Capitol high society. Sejanus resents his father and hates the Capitol; like his mother, Ma, he still feels connected to District Two and considers the district home. Coriolanus gets drawn into Sejanus’s orbit when, during the reaping, Sejanus shares that his tribute from District Two, Marcus, is a former classmate. From this moment on, Coriolanus begins saving Sejanus from danger or embarrassment on many occasions. He takes on the role of Sejanus’s mentor, encouraging Sejanus to remain loyal to the Capitol and not step too far out of line in protesting the Games. However, Sejanus remains convinced that the Games are wrong, and he goes so far as to enter the arena on the first night. He expects the tributes to kill him and believes this will make a statement to the Capitol that the Games are inhumane. Sejanus ultimately agrees to leave the arena with Coriolanus and is unsuccessful in sending the message he intended. His actions, however, get him in trouble with the Capitol. Though Sejanus resents his father’s money, Strabo buys Sejanus’s way out of trouble and allows him to join the Peacekeepers. Sejanus goes into the Peacekeepers with characteristic optimism—he wants to train as a medic and help people. But when Sejanus learns he can’t be a medic if there’s no war, he instead falls in with rebels in District 12, helps plot an escape, and purchases guns for the rebel forces. He outright ignores Coriolanus’s attempts to keep him out of trouble—but Coriolanus does end up double-crossing Sejanus. He records Sejanus’s admission that he’s helping the rebels with a jabberjay, and Dr. Gaul eventually hears the message. Sejanus is ultimately executed for treason.\"],\n",
    "    [\"Lucy Gray is the female tribute from District 12. Lucy Gray proves herself to be a cutthroat performer when, at the reaping, she slips a snake down a girl’s dress and then sings a song onstage. She loves color—she usually wears a dress of rainbow ruffles—and often uses bird imagery when she speaks. As Coriolanus gets to know her, he learns that she’s an orphan. She’s a member of the Covey, a traveling band of musicians and performers that’s now permanently based in District 12. With this information, Coriolanus presents Lucy Gray as a tribute not from District 12, but as a person who’s more like people in the Capitol. This campaign is successful; Lucy Gray becomes the fan favorite. She and Coriolanus fall in love in the week before the Games, sharing a passionate kiss—and Coriolanus gives her his mother’s compact, both as a token of his affection and so she can sneak rat poison into the arena. Throughout the Games, Lucy Gray mostly stays hidden. She kills several people with rat poison and one person with one of the neon snakes Dr. Gaul drops in the arena. After she wins the Games, the Capitol sends her home, where she rejoins the Covey. She and Coriolanus attempt to keep their romance alive while Coriolanus is stationed there, but this becomes complicated. Many of Lucy Gray’s songs are about a former lover, Billy Taupe, whom she now hates but who is still in her life. However, when Lucy Gray starts to fear that the mayor (who incorrectly believes Lucy Gray killed his daughter) is going to hurt her, Lucy Gray and Coriolanus decide to run away. Lucy Gray prizes trust and friendship, so when she infers that Coriolanus is responsible for Sejanus’s death, she tries to run away. She sets a trap for Coriolanus that results in him being bitten by a snake. After this, Coriolanus shoots at her. He isn’t sure if he hits her, but he ultimately decides he doesn’t care. Though Lucy Gray mysteriously disappears after this, several songs she wrote persist—they appear 64 years later in the Hunger Games trilogy.Lucy Gray Baird Quotes in The Ballad of Songbir\"],\n",
    "    [\"Tigris is Coriolanus’s cousin. She’s a few years older than Coriolanus and has been living with him and the Grandma’am since the war, when she was also orphaned. Tigris is kind, caring, and intelligent. Tigris has always taken it upon herself to look out for Coriolanus. This meant that she learned to cook as a young child during the war—but she also implies that at several points, she’s turned to sex work to make ends meet. Her dream has always been to work in fashion, which she’s doing in the novel’s present. Though she’s supposedly working as an apprentice, Coriolanus suggests that her employer treats her more as a grunt, making her do unsavory or dirty tasks rather than teaching her how to make clothes. Despite this, Tigris is resourceful and excels at upcycling old garments—she manages to transform one of Crassus Snow’s stained old shirts into a gorgeous, classy garment for Coriolanus to wear to the reaping. As the Hunger Games approach and begin, Tigris becomes increasingly skeptical of the Games and of Coriolanus’s involvement in them. Particularly as she develops sympathy for Lucy Gray—and later, after she realizes Dr. Gaul forced Coriolanus into the arena, putting him in danger—she expresses that the Games are wrong and not fair to any of the children involved, mentors or tributes.\"],\n",
    "    [\"1. Lucy Gray (victor), 2. Reaper, 3. Treech, 4. Teslee, 5. Mizzen, 6. Coral, 7. Circ, 8. Wovey, 9. Tanner, 10. Lamina\"],\n",
    "    [\"Lucy Gray plays the long game once that year’s tournament begins. She spends the first day in hiding after running into the woods instead of picking from the weapons available, which ultimately leads to what is commonly known as the “blood bath.” She then uses water bottles, poison, and snakes to kill the other tributes, though she retains her humanity and comforts one of the tributes she kills by holding him and speaking to him softly. Lucy was, however, helped by her mentor from outside the arena—he slipped a handkerchief with Lucy’s scent into a tank of snakes that were later released into the Games. This meant that the snakes didn’t hunt Lucy, and she survived their arrival in the arena. In the end, after waiting it out and cleverly avoiding death, Lucy Gray is declared the winner of the 10th annual Hunger Games—a harrowing yet tremendous victory not only for her but Snow and her home, District 12, too.\"],\n",
    "    [\"One of the many tragic backstories in Ballad, Dean Casca Highbottom is the remorseful creator of the Hunger Games. He came up with the idea for a school project, but he was drunk and never meant for it to be put into practice. Unfortunately, his friend and partner for the project, Crassus Snow, submitted the idea to their teacher, Dr. Gaul, and, to Highbottom's horror, the Hunger Games were born. After his creation comes to life, Highbottom becomes a morphling addict.\"],\n",
    "    [\"Coriolanus Snow joined the mentorship program in 'The Ballad of Songbirds and Snakes' primarily motivated by his desire to restore his family's wealth and social standing. After losing both parents in the war, Snow's family becomes destitute, relying on food rations. Living in the Capitol with his grandmother and cousin Tigress, Snow sees the mentorship program as an opportunity to potentially win the cash prize and improve his family's dire situation. Despite initial reservations about mentoring the female tribute from District 12, the poorest district in Panem, Snow's motivation evolves as he develops a connection with Lucy Gray Baird. Over time, Snow's participation is influenced by his observations of the power dynamics and suffering within the Games, leading him to propose a betting and sponsorship program that shapes the future of the Hunger Games. The story unfolds as Snow's motivations become more complex, navigating personal ambition, family restoration, and a gradual realization of societal injustices within Panem.\"],\n",
    "    [\"Coriolanus Snow presents the idea of a betting and sponsorship program to the Head Game Maker Volumnia Gaul. Tasked with writing a paper about additions to the Hunger Games, Snow suggests this program to engage Capitol citizens in supporting their favorite tributes. He sees it as an opportunity to restore his family's wealth and secure his future. The concept adds a strategic layer to the Games, allowing tributes to attract sponsors by building alliances and performing well. Despite initial suspicions from Gaul, the idea proves successful, leading to increased sponsorships and support for Snow's tribute, Lucy Gray Baird. This idea becomes instrumental in the modern Hunger Games, marking a significant development in Snow's character as he navigates manipulation, moral dilemmas, and the power dynamics within Panem's society.\"],\n",
    "    [\"Coriolanus Snow secretly records and sends evidence to Dr. Gaul, the Head Game Maker, regarding Sejanus's plot to help District residents escape. Using a Jabberyjay, Snow captures Sejanus admitting to the plan and sends the message to Gaul. This information results in Sejanus's execution and the subsequent deaths of the Mayor's daughter and another citizen.\"],\n",
    "    [\"Coriolanus Snow and Lucy Gray Baird gain popularity in the Capitol through strategic actions and captivating performances. Despite their initial differences and the challenge of being paired together, Snow and Lucy find ways to captivate the citizens of the Capitol and become influential figures.One of the key strategies that Snow and Lucy employ to gain popularity is Lucy's talent as a singer and performer.\"]\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General answer by LLMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"{question}\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_chain =(\n",
    "    { \"question\": itemgetter(\"question\")}\n",
    "    | RunnablePassthrough()\n",
    "    | {\"response\": prompt | llm}\n",
    ")\n",
    "llm_chain_gpt4 =(\n",
    "    { \"question\": itemgetter(\"question\")}\n",
    "    | RunnablePassthrough()\n",
    "    | {\"response\": prompt | llm_gpt4}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "answers_llm = []\n",
    "contexts_llm = [[\"\"],[\"\"],[\"\"],[\"\"],[\"\"],[\"\"],[\"\"],[\"\"],[\"\"],[\"\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for query in questions:\n",
    "    response = llm_chain.invoke({\"question\": query})\n",
    "    answers_llm.append(response[\"response\"].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "passing column names as 'ground_truths' is deprecated and will be removed in the next version, please use 'ground_truth' instead. Note that `ground_truth` should be of type string and not Sequence[string] like `ground_truths`\n",
      "Evaluating: 100%|██████████| 60/60 [00:23<00:00,  2.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average score is: 0.6636103441664355\n",
      "This is the new best value!\n",
      "    System  Faithfulness  Answer Relevancy  Context Precision  Context Recall  \\\n",
      "0  GPT-3.5           1.0          0.379673                NaN             NaN   \n",
      "\n",
      "   Answer Similarity  Answer Correctness  Average  \n",
      "0           0.841376            0.410613  0.66361  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sigitalapina\\AppData\\Local\\Temp\\ipykernel_1660\\800954320.py:2: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  results_df = pd.concat([results_df, llm_results], ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "llm_results = evaluate_LLM(\"GPT-3.5\", questions, answers_llm, contexts_llm, ground_truths)\n",
    "results_df = pd.concat([results_df, llm_results], ignore_index=True)\n",
    "print(llm_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "passing column names as 'ground_truths' is deprecated and will be removed in the next version, please use 'ground_truth' instead. Note that `ground_truth` should be of type string and not Sequence[string] like `ground_truths`\n",
      "Evaluating: 100%|██████████| 60/60 [00:09<00:00,  6.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average score is: 0.7423882546501969\n",
      "This is the new best value!\n",
      "  System  Faithfulness  Answer Relevancy  Context Precision  Context Recall  \\\n",
      "0  GPT-4           1.0          0.695899                NaN             NaN   \n",
      "\n",
      "   Answer Similarity  Answer Correctness   Average  \n",
      "0           0.900098            0.492424  0.742388  \n"
     ]
    }
   ],
   "source": [
    "answers_llm_gpt4 = []\n",
    "for query in questions:\n",
    "    response = llm_chain_gpt4.invoke({\"question\": query})\n",
    "    answers_llm_gpt4.append(response[\"response\"].content)\n",
    "llm_results_gpt4 = evaluate_LLM(\"GPT-4\",questions, answers_llm_gpt4, contexts_llm, ground_truths)\n",
    "results_df = pd.concat([results_df, llm_results_gpt4], ignore_index=True)\n",
    "print(llm_results_gpt4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"User input {question}. \n",
    "Context {context}.\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieval_chain(prompt, retriever, llm):\n",
    "    retrieval_augmented_qa_chain = (\n",
    "        {\"context\": itemgetter(\"question\") | retriever, \"question\": itemgetter(\"question\")}\n",
    "        | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
    "        | {\"response\": prompt | llm, \"context\": itemgetter(\"context\")}\n",
    "    )\n",
    "    return retrieval_augmented_qa_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = PyPDFLoader(r\"..\\ballad\\the_ballad_of_songbirds_and_snakes.pdf\")\n",
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THE FIRST TIME RUN THIS, AFTER RUN THE NEXT CELL\n",
    "# text_splitter = CharacterTextSplitter()\n",
    "# chunks = text_splitter.split_documents(documents)\n",
    "# db_naive = Chroma.from_documents(chunks, embeddings_client, persist_directory = \"../ballad/vectordb/naive\")\n",
    "# db_naive.persist()\n",
    "# retriever_naive = db_naive.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_naive = Chroma(persist_directory = \"../ballad/vectordb-edit/naive\", embedding_function=embeddings_client)\n",
    "retriever_naive = db_naive.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "answers_naive = []\n",
    "contexts_naive = []\n",
    "for query in questions:\n",
    "    try:  \n",
    "        response = retrieval_chain(prompt, retriever_naive, llm).invoke({\"question\": query})\n",
    "        # Access the response content\n",
    "        answers_naive.append(response[\"response\"].content)\n",
    "        # Access the context content\n",
    "        context_content = [context.page_content for context in response[\"context\"]]\n",
    "        contexts_naive.append(context_content)  \n",
    "    except Exception as e:  \n",
    "        print(f\"Warning: {e}\" + \"on the following question: \" + query)  \n",
    "        answers_naive.append(\"No answer\")\n",
    "        context_full = retriever_naive.get_relevant_documents(query)\n",
    "        context_content = [context.page_content for context in context_full]\n",
    "        contexts_naive.append(context_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "passing column names as 'ground_truths' is deprecated and will be removed in the next version, please use 'ground_truth' instead. Note that `ground_truth` should be of type string and not Sequence[string] like `ground_truths`\n",
      "Evaluating: 100%|██████████| 60/60 [00:08<00:00,  7.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average score is: 0.7476229255841002\n",
      "This is the new best value!\n",
      "  System  Faithfulness  Answer Relevancy  Context Precision  Context Recall  \\\n",
      "0  Naive      0.944444          0.831993           0.597222        0.820833   \n",
      "\n",
      "   Answer Similarity  Answer Correctness   Average  \n",
      "0           0.878165             0.41308  0.747623  \n"
     ]
    }
   ],
   "source": [
    "result_naive_rag = evaluate_system(\"Naive\", questions, answers_naive, contexts_naive, ground_truths)\n",
    "results_df = pd.concat([results_df, result_naive_rag], ignore_index=True)\n",
    "print(result_naive_rag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### recursive splitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THE FIRST TIME RUN THIS, AFTER RUN THE NEXT CELL\n",
    "text_splitter = text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder()\n",
    "chunks_r = text_splitter.split_documents(documents)\n",
    "db_basic = Chroma.from_documents(chunks_r, embeddings_client, persist_directory = \"../ballad/vectordb/recursive_basic\")\n",
    "db_basic.persist()\n",
    "retriever_basic = db_basic.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_basic = Chroma(persist_directory = \"../ballad/vectordb/recursive_basic\", embedding_function=embeddings_client)\n",
    "retriever_basic = db_basic.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "answers_recursive = []\n",
    "contexts_recursive = []\n",
    "for query in questions:\n",
    "    try:  \n",
    "        response = retrieval_chain(prompt, retriever_basic, llm).invoke({\"question\": query})\n",
    "        # Access the response content\n",
    "        answers_recursive.append(response[\"response\"].content)\n",
    "        # Access the context content\n",
    "        context_content = [context.page_content for context in response[\"context\"]]\n",
    "        contexts_recursive.append(context_content)  \n",
    "    except Exception as e:  \n",
    "        print(f\"Warning: {e}\" + \"on the following question: \" + query)  \n",
    "        answers_recursive.append(\"No answer\")\n",
    "        context_full = retriever_basic.get_relevant_documents(query)\n",
    "        context_content = [context.page_content for context in context_full]\n",
    "        contexts_recursive.append(context_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "passing column names as 'ground_truths' is deprecated and will be removed in the next version, please use 'ground_truth' instead. Note that `ground_truth` should be of type string and not Sequence[string] like `ground_truths`\n",
      "Evaluating: 100%|██████████| 60/60 [00:10<00:00,  5.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average score is: 0.7384210404925194\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>System</th>\n",
       "      <th>Faithfulness</th>\n",
       "      <th>Answer Relevancy</th>\n",
       "      <th>Context Precision</th>\n",
       "      <th>Context Recall</th>\n",
       "      <th>Answer Similarity</th>\n",
       "      <th>Answer Correctness</th>\n",
       "      <th>Average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Recursive</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.837124</td>\n",
       "      <td>0.597222</td>\n",
       "      <td>0.771429</td>\n",
       "      <td>0.878165</td>\n",
       "      <td>0.402142</td>\n",
       "      <td>0.738421</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      System  Faithfulness  Answer Relevancy  Context Precision  \\\n",
       "0  Recursive      0.944444          0.837124           0.597222   \n",
       "\n",
       "   Context Recall  Answer Similarity  Answer Correctness   Average  \n",
       "0        0.771429           0.878165            0.402142  0.738421  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_recursive = evaluate_system(\"Recursive\", questions, answers_naive, contexts_naive, ground_truths)\n",
    "results_df = pd.concat([results_df, result_recursive], ignore_index=True)\n",
    "result_recursive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### chunk sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_and_evaluate(name, retriever, prompt, llm, results_df):\n",
    "    answers = []\n",
    "    contexts_extra = []\n",
    "\n",
    "    for query in questions:\n",
    "        try:  \n",
    "            response = retrieval_chain(prompt, retriever, llm).invoke({\"question\": query})\n",
    "            # Access the response content\n",
    "            answers.append(response[\"response\"].content)\n",
    "            # Access the context content\n",
    "            context_content = [context.page_content for context in response[\"context\"]]\n",
    "            contexts_extra.append(context_content)  \n",
    "        except Exception as e:  \n",
    "            print(f\"Warning: {e}\" + \"on the following question: \" + query)  \n",
    "            answers.append(\"No answer\")\n",
    "            context_full = retriever.get_relevant_documents(query)\n",
    "            context_content = [context.page_content for context in context_full]\n",
    "            contexts_extra.append(context_content)\n",
    "\n",
    "    result = evaluate_system(name, questions, answers, contexts_extra, ground_truths)\n",
    "    results_df = pd.concat([results_df, result], ignore_index=True)\n",
    "    return result, results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of chunks for chunk size 500, overlap 0%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "passing column names as 'ground_truths' is deprecated and will be removed in the next version, please use 'ground_truth' instead. Note that `ground_truth` should be of type string and not Sequence[string] like `ground_truths`\n",
      "Evaluating:   0%|          | 0/60 [00:00<?, ?it/s]Runner in Executor raised an exception\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400, 'innererror': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_result': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': True, 'severity': 'medium'}}}}}\n",
      "Evaluating:  48%|████▊     | 29/60 [00:19<00:11,  2.67it/s]Runner in Executor raised an exception\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400, 'innererror': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_result': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': True, 'severity': 'medium'}}}}}\n",
      "Evaluating: 100%|██████████| 60/60 [00:22<00:00,  2.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average score is: 0.7539822774150747\n",
      "This is the new best value!\n",
      "CHUNK SIZE 500, 0% overlap:\n",
      "                  System  Faithfulness  Answer Relevancy  Context Precision  \\\n",
      "0  Chunk 500, overlap 0%      0.532729          0.803469           0.907841   \n",
      "\n",
      "   Context Recall  Answer Similarity  Answer Correctness   Average  \n",
      "0        0.752864           0.731083            0.795908  0.753982  \n",
      "Number of chunks for chunk size 500, overlap 5%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "passing column names as 'ground_truths' is deprecated and will be removed in the next version, please use 'ground_truth' instead. Note that `ground_truth` should be of type string and not Sequence[string] like `ground_truths`\n",
      "Evaluating: 100%|██████████| 60/60 [00:15<00:00,  3.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average score is: 0.746531580778468\n",
      "CHUNK SIZE 500, 5% overlap:\n",
      "                  System  Faithfulness  Answer Relevancy  Context Precision  \\\n",
      "0  Chunk 500, overlap 5%          0.92          0.829388           0.597222   \n",
      "\n",
      "   Context Recall  Answer Similarity  Answer Correctness   Average  \n",
      "0        0.808333           0.882359            0.441887  0.746532  \n",
      "Number of chunks for chunk size 500, overlap 10%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "passing column names as 'ground_truths' is deprecated and will be removed in the next version, please use 'ground_truth' instead. Note that `ground_truth` should be of type string and not Sequence[string] like `ground_truths`\n",
      "Evaluating:   0%|          | 0/60 [00:00<?, ?it/s]Runner in Executor raised an exception\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400, 'innererror': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_result': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': True, 'severity': 'medium'}}}}}\n",
      "Evaluating:   2%|▏         | 1/60 [00:00<00:34,  1.72it/s]Runner in Executor raised an exception\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400, 'innererror': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_result': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': True, 'severity': 'medium'}}}}}\n",
      "Evaluating: 100%|██████████| 60/60 [00:08<00:00,  6.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average score is: 0.7503026934325662\n",
      "CHUNK SIZE 500, 10% overlap:\n",
      "                   System  Faithfulness  Answer Relevancy  Context Precision  \\\n",
      "0  Chunk 500, overlap 10%      0.531527          0.775393           0.907932   \n",
      "\n",
      "   Context Recall  Answer Similarity  Answer Correctness   Average  \n",
      "0        0.753544           0.731083            0.802336  0.750303  \n",
      "Number of chunks for chunk size 500, overlap 15%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "passing column names as 'ground_truths' is deprecated and will be removed in the next version, please use 'ground_truth' instead. Note that `ground_truth` should be of type string and not Sequence[string] like `ground_truths`\n",
      "Evaluating:   0%|          | 0/60 [00:00<?, ?it/s]Task exception was never retrieved\n",
      "future: <Task finished name='Task-500' coro=<AsyncClient.aclose() done, defined at c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\httpx\\_client.py:2011> exception=RuntimeError('Event loop is closed')>\n",
      "RuntimeError: Event loop is closed\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-501' coro=<AsyncClient.aclose() done, defined at c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\httpx\\_client.py:2011> exception=RuntimeError('Event loop is closed')>\n",
      "RuntimeError: Event loop is closed\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-502' coro=<AsyncClient.aclose() done, defined at c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\httpx\\_client.py:2011> exception=RuntimeError('Event loop is closed')>\n",
      "RuntimeError: Event loop is closed\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-503' coro=<AsyncClient.aclose() done, defined at c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\httpx\\_client.py:2011> exception=RuntimeError('Event loop is closed')>\n",
      "RuntimeError: Event loop is closed\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-504' coro=<AsyncClient.aclose() done, defined at c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\httpx\\_client.py:2011> exception=RuntimeError('Event loop is closed')>\n",
      "RuntimeError: Event loop is closed\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-505' coro=<AsyncClient.aclose() done, defined at c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\httpx\\_client.py:2011> exception=RuntimeError('Event loop is closed')>\n",
      "RuntimeError: Event loop is closed\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-506' coro=<AsyncClient.aclose() done, defined at c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\httpx\\_client.py:2011> exception=RuntimeError('Event loop is closed')>\n",
      "RuntimeError: Event loop is closed\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-507' coro=<AsyncClient.aclose() done, defined at c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\httpx\\_client.py:2011> exception=RuntimeError('Event loop is closed')>\n",
      "RuntimeError: Event loop is closed\n",
      "Runner in Executor raised an exception\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400, 'innererror': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_result': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': True, 'severity': 'medium'}}}}}\n",
      "Evaluating: 100%|██████████| 60/60 [00:13<00:00,  4.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average score is: 0.7639724254546479\n",
      "This is the new best value!\n",
      "CHUNK SIZE 500, 15% overlap:\n",
      "                   System  Faithfulness  Answer Relevancy  Context Precision  \\\n",
      "0  Chunk 500, overlap 15%      0.800333          0.951028           0.616525   \n",
      "\n",
      "   Context Recall  Answer Similarity  Answer Correctness   Average  \n",
      "0        0.783333           0.890919            0.541697  0.763972  \n",
      "Number of chunks for chunk size 500, overlap 20%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "passing column names as 'ground_truths' is deprecated and will be removed in the next version, please use 'ground_truth' instead. Note that `ground_truth` should be of type string and not Sequence[string] like `ground_truths`\n",
      "Evaluating:   0%|          | 0/60 [00:00<?, ?it/s]Runner in Executor raised an exception\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400, 'innererror': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_result': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': True, 'severity': 'medium'}}}}}\n",
      "Evaluating: 100%|██████████| 60/60 [00:12<00:00,  4.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average score is: 0.75935755583295\n",
      "CHUNK SIZE 500, 20% overlap:\n",
      "                   System  Faithfulness  Answer Relevancy  Context Precision  \\\n",
      "0  Chunk 500, overlap 20%      0.816002          0.950323           0.616575   \n",
      "\n",
      "   Context Recall  Answer Similarity  Answer Correctness   Average  \n",
      "0            0.75           0.890744            0.532502  0.759358  \n",
      "Number of chunks for chunk size 1000, overlap 0%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "passing column names as 'ground_truths' is deprecated and will be removed in the next version, please use 'ground_truth' instead. Note that `ground_truth` should be of type string and not Sequence[string] like `ground_truths`\n",
      "Evaluating:   0%|          | 0/60 [00:00<?, ?it/s]Runner in Executor raised an exception\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400, 'innererror': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_result': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': True, 'severity': 'medium'}}}}}\n",
      "Evaluating: 100%|██████████| 60/60 [00:08<00:00,  6.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average score is: 0.764096212592404\n",
      "This is the new best value!\n",
      "CHUNK SIZE 1000, 0% overlap:\n",
      "                   System  Faithfulness  Answer Relevancy  Context Precision  \\\n",
      "0  Chunk 1000, overlap 0%      0.790545          0.932472           0.654176   \n",
      "\n",
      "   Context Recall  Answer Similarity  Answer Correctness   Average  \n",
      "0        0.783333           0.890744            0.533308  0.764096  \n",
      "Number of chunks for chunk size 1000, overlap 5%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "passing column names as 'ground_truths' is deprecated and will be removed in the next version, please use 'ground_truth' instead. Note that `ground_truth` should be of type string and not Sequence[string] like `ground_truths`\n",
      "Evaluating:   0%|          | 0/60 [00:00<?, ?it/s]Runner in Executor raised an exception\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400, 'innererror': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_result': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': True, 'severity': 'medium'}}}}}\n",
      "Evaluating: 100%|██████████| 60/60 [00:08<00:00,  6.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average score is: 0.7494286899321573\n",
      "CHUNK SIZE 1000, 5% overlap:\n",
      "                   System  Faithfulness  Answer Relevancy  Context Precision  \\\n",
      "0  Chunk 1000, overlap 5%      0.757331          0.951969           0.582974   \n",
      "\n",
      "   Context Recall  Answer Similarity  Answer Correctness   Average  \n",
      "0        0.783333           0.878419            0.542546  0.749429  \n",
      "Number of chunks for chunk size 1000, overlap 10%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "passing column names as 'ground_truths' is deprecated and will be removed in the next version, please use 'ground_truth' instead. Note that `ground_truth` should be of type string and not Sequence[string] like `ground_truths`\n",
      "Evaluating: 100%|██████████| 60/60 [00:13<00:00,  4.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average score is: 0.7144231231949257\n",
      "CHUNK SIZE 1000, 10% overlap:\n",
      "                    System  Faithfulness  Answer Relevancy  Context Precision  \\\n",
      "0  Chunk 1000, overlap 10%      0.854167          0.746491           0.597222   \n",
      "\n",
      "   Context Recall  Answer Similarity  Answer Correctness   Average  \n",
      "0           0.775           0.880496            0.433163  0.714423  \n",
      "Number of chunks for chunk size 1000, overlap 15%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "passing column names as 'ground_truths' is deprecated and will be removed in the next version, please use 'ground_truth' instead. Note that `ground_truth` should be of type string and not Sequence[string] like `ground_truths`\n",
      "Evaluating:   0%|          | 0/60 [00:00<?, ?it/s]Runner in Executor raised an exception\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400, 'innererror': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_result': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': True, 'severity': 'medium'}}}}}\n",
      "Evaluating: 100%|██████████| 60/60 [00:08<00:00,  7.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average score is: 0.7551886731824956\n",
      "CHUNK SIZE 1000, 15% overlap:\n",
      "                    System  Faithfulness  Answer Relevancy  Context Precision  \\\n",
      "0  Chunk 1000, overlap 15%       0.76496          0.949421           0.654338   \n",
      "\n",
      "   Context Recall  Answer Similarity  Answer Correctness   Average  \n",
      "0            0.75           0.878244            0.534169  0.755189  \n",
      "Number of chunks for chunk size 1000, overlap 20%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "passing column names as 'ground_truths' is deprecated and will be removed in the next version, please use 'ground_truth' instead. Note that `ground_truth` should be of type string and not Sequence[string] like `ground_truths`\n",
      "Evaluating:   0%|          | 0/60 [00:00<?, ?it/s]Runner in Executor raised an exception\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400, 'innererror': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_result': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': True, 'severity': 'medium'}}}}}\n",
      "Evaluating: 100%|██████████| 60/60 [00:11<00:00,  5.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average score is: 0.7626237594141226\n",
      "CHUNK SIZE 1000, 20% overlap:\n",
      "                    System  Faithfulness  Answer Relevancy  Context Precision  \\\n",
      "0  Chunk 1000, overlap 20%      0.786958          0.951187           0.619133   \n",
      "\n",
      "   Context Recall  Answer Similarity  Answer Correctness   Average  \n",
      "0        0.783333           0.890919            0.544212  0.762624  \n",
      "Number of chunks for chunk size 2000, overlap 0%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "passing column names as 'ground_truths' is deprecated and will be removed in the next version, please use 'ground_truth' instead. Note that `ground_truth` should be of type string and not Sequence[string] like `ground_truths`\n",
      "Evaluating:   0%|          | 0/60 [00:00<?, ?it/s]Task exception was never retrieved\n",
      "future: <Task finished name='Task-968' coro=<AsyncClient.aclose() done, defined at c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\httpx\\_client.py:2011> exception=RuntimeError('Event loop is closed')>\n",
      "RuntimeError: Event loop is closed\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-969' coro=<AsyncClient.aclose() done, defined at c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\httpx\\_client.py:2011> exception=RuntimeError('Event loop is closed')>\n",
      "RuntimeError: Event loop is closed\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-970' coro=<AsyncClient.aclose() done, defined at c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\httpx\\_client.py:2011> exception=RuntimeError('Event loop is closed')>\n",
      "RuntimeError: Event loop is closed\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-971' coro=<AsyncClient.aclose() done, defined at c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\httpx\\_client.py:2011> exception=RuntimeError('Event loop is closed')>\n",
      "RuntimeError: Event loop is closed\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-972' coro=<AsyncClient.aclose() done, defined at c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\httpx\\_client.py:2011> exception=RuntimeError('Event loop is closed')>\n",
      "RuntimeError: Event loop is closed\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-973' coro=<AsyncClient.aclose() done, defined at c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\httpx\\_client.py:2011> exception=RuntimeError('Event loop is closed')>\n",
      "RuntimeError: Event loop is closed\n",
      "Runner in Executor raised an exception\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400, 'innererror': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_result': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': True, 'severity': 'medium'}}}}}\n",
      "Evaluating: 100%|██████████| 60/60 [00:13<00:00,  4.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average score is: 0.7517755819928807\n",
      "CHUNK SIZE 2000, 0% overlap:\n",
      "                   System  Faithfulness  Answer Relevancy  Context Precision  \\\n",
      "0  Chunk 2000, overlap 0%      0.753625          0.949662           0.616641   \n",
      "\n",
      "   Context Recall  Answer Similarity  Answer Correctness   Average  \n",
      "0        0.783333           0.864847            0.542546  0.751776  \n",
      "Number of chunks for chunk size 2000, overlap 5%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "passing column names as 'ground_truths' is deprecated and will be removed in the next version, please use 'ground_truth' instead. Note that `ground_truth` should be of type string and not Sequence[string] like `ground_truths`\n",
      "Evaluating:   2%|▏         | 1/60 [00:01<01:49,  1.85s/it]Runner in Executor raised an exception\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400, 'innererror': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_result': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': True, 'severity': 'medium'}, 'violence': {'filtered': False, 'severity': 'safe'}}}}}\n",
      "Evaluating: 100%|██████████| 60/60 [00:08<00:00,  6.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average score is: 0.7442605008007958\n",
      "CHUNK SIZE 2000, 5% overlap:\n",
      "                   System  Faithfulness  Answer Relevancy  Context Precision  \\\n",
      "0  Chunk 2000, overlap 5%      0.400117          0.928571           0.829433   \n",
      "\n",
      "   Context Recall  Answer Similarity  Answer Correctness   Average  \n",
      "0        0.633333           0.801053            0.873055  0.744261  \n",
      "Number of chunks for chunk size 2000, overlap 10%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "passing column names as 'ground_truths' is deprecated and will be removed in the next version, please use 'ground_truth' instead. Note that `ground_truth` should be of type string and not Sequence[string] like `ground_truths`\n",
      "Evaluating:   0%|          | 0/60 [00:00<?, ?it/s]Runner in Executor raised an exception\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400, 'innererror': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_result': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': True, 'severity': 'medium'}}}}}\n",
      "Evaluating: 100%|██████████| 60/60 [00:08<00:00,  6.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average score is: 0.761945684889143\n",
      "CHUNK SIZE 2000, 10% overlap:\n",
      "                    System  Faithfulness  Answer Relevancy  Context Precision  \\\n",
      "0  Chunk 2000, overlap 10%      0.769649            0.9406           0.655261   \n",
      "\n",
      "   Context Recall  Answer Similarity  Answer Correctness   Average  \n",
      "0        0.783333           0.878579            0.544252  0.761946  \n",
      "Number of chunks for chunk size 2000, overlap 15%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "passing column names as 'ground_truths' is deprecated and will be removed in the next version, please use 'ground_truth' instead. Note that `ground_truth` should be of type string and not Sequence[string] like `ground_truths`\n",
      "Evaluating:   0%|          | 0/60 [00:00<?, ?it/s]Runner in Executor raised an exception\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400, 'innererror': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_result': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': True, 'severity': 'medium'}}}}}\n",
      "Evaluating: 100%|██████████| 60/60 [00:09<00:00,  6.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average score is: 0.7625637949047773\n",
      "CHUNK SIZE 2000, 15% overlap:\n",
      "                    System  Faithfulness  Answer Relevancy  Context Precision  \\\n",
      "0  Chunk 2000, overlap 15%      0.784939          0.955299           0.652623   \n",
      "\n",
      "   Context Recall  Answer Similarity  Answer Correctness   Average  \n",
      "0            0.75           0.889133            0.543388  0.762564  \n",
      "Number of chunks for chunk size 2000, overlap 20%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "passing column names as 'ground_truths' is deprecated and will be removed in the next version, please use 'ground_truth' instead. Note that `ground_truth` should be of type string and not Sequence[string] like `ground_truths`\n",
      "Evaluating:   0%|          | 0/60 [00:00<?, ?it/s]Runner in Executor raised an exception\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400, 'innererror': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_result': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': True, 'severity': 'medium'}}}}}\n",
      "Evaluating: 100%|██████████| 60/60 [00:13<00:00,  4.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average score is: 0.7426846399383767\n",
      "CHUNK SIZE 2000, 20% overlap:\n",
      "                    System  Faithfulness  Answer Relevancy  Context Precision  \\\n",
      "0  Chunk 2000, overlap 20%      0.762311          0.944377           0.582052   \n",
      "\n",
      "   Context Recall  Answer Similarity  Answer Correctness   Average  \n",
      "0            0.75           0.874847            0.542521  0.742685  \n",
      "Number of chunks for chunk size 3000, overlap 0%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "passing column names as 'ground_truths' is deprecated and will be removed in the next version, please use 'ground_truth' instead. Note that `ground_truth` should be of type string and not Sequence[string] like `ground_truths`\n",
      "Evaluating:   0%|          | 0/60 [00:00<?, ?it/s]Runner in Executor raised an exception\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400, 'innererror': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_result': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': True, 'severity': 'medium'}}}}}\n",
      "Evaluating: 100%|██████████| 60/60 [00:08<00:00,  6.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average score is: 0.7569364199232673\n",
      "CHUNK SIZE 3000, 0% overlap:\n",
      "                   System  Faithfulness  Answer Relevancy  Context Precision  \\\n",
      "0  Chunk 3000, overlap 0%      0.779172          0.949059           0.652841   \n",
      "\n",
      "   Context Recall  Answer Similarity  Answer Correctness   Average  \n",
      "0            0.75           0.878084            0.532462  0.756936  \n",
      "Number of chunks for chunk size 3000, overlap 5%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "passing column names as 'ground_truths' is deprecated and will be removed in the next version, please use 'ground_truth' instead. Note that `ground_truth` should be of type string and not Sequence[string] like `ground_truths`\n",
      "Evaluating:   0%|          | 0/60 [00:00<?, ?it/s]Runner in Executor raised an exception\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400, 'innererror': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_result': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': True, 'severity': 'medium'}}}}}\n",
      "Evaluating: 100%|██████████| 60/60 [00:12<00:00,  4.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average score is: 0.7520124121631414\n",
      "CHUNK SIZE 3000, 5% overlap:\n",
      "                   System  Faithfulness  Answer Relevancy  Context Precision  \\\n",
      "0  Chunk 3000, overlap 5%      0.767551          0.942964           0.617704   \n",
      "\n",
      "   Context Recall  Answer Similarity  Answer Correctness   Average  \n",
      "0        0.783333           0.868084            0.532438  0.752012  \n",
      "Number of chunks for chunk size 3000, overlap 10%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "passing column names as 'ground_truths' is deprecated and will be removed in the next version, please use 'ground_truth' instead. Note that `ground_truth` should be of type string and not Sequence[string] like `ground_truths`\n",
      "Evaluating:   0%|          | 0/60 [00:00<?, ?it/s]Task exception was never retrieved\n",
      "future: <Task finished name='Task-1453' coro=<AsyncClient.aclose() done, defined at c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\httpx\\_client.py:2011> exception=RuntimeError('Event loop is closed')>\n",
      "RuntimeError: Event loop is closed\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1454' coro=<AsyncClient.aclose() done, defined at c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\httpx\\_client.py:2011> exception=RuntimeError('Event loop is closed')>\n",
      "RuntimeError: Event loop is closed\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1455' coro=<AsyncClient.aclose() done, defined at c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\httpx\\_client.py:2011> exception=RuntimeError('Event loop is closed')>\n",
      "RuntimeError: Event loop is closed\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1456' coro=<AsyncClient.aclose() done, defined at c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\httpx\\_client.py:2011> exception=RuntimeError('Event loop is closed')>\n",
      "RuntimeError: Event loop is closed\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1457' coro=<AsyncClient.aclose() done, defined at c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\httpx\\_client.py:2011> exception=RuntimeError('Event loop is closed')>\n",
      "RuntimeError: Event loop is closed\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1458' coro=<AsyncClient.aclose() done, defined at c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\httpx\\_client.py:2011> exception=RuntimeError('Event loop is closed')>\n",
      "RuntimeError: Event loop is closed\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1459' coro=<AsyncClient.aclose() done, defined at c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\httpx\\_client.py:2011> exception=RuntimeError('Event loop is closed')>\n",
      "RuntimeError: Event loop is closed\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1460' coro=<AsyncClient.aclose() done, defined at c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\httpx\\_client.py:2011> exception=RuntimeError('Event loop is closed')>\n",
      "RuntimeError: Event loop is closed\n",
      "Runner in Executor raised an exception\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400, 'innererror': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_result': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': True, 'severity': 'medium'}}}}}\n",
      "Evaluating: 100%|██████████| 60/60 [00:09<00:00,  6.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average score is: 0.7549361695598794\n",
      "CHUNK SIZE 3000, 10% overlap:\n",
      "                    System  Faithfulness  Answer Relevancy  Context Precision  \\\n",
      "0  Chunk 3000, overlap 10%      0.765109          0.949812            0.61915   \n",
      "\n",
      "   Context Recall  Answer Similarity  Answer Correctness   Average  \n",
      "0        0.783333           0.878084            0.534129  0.754936  \n",
      "Number of chunks for chunk size 3000, overlap 15%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "passing column names as 'ground_truths' is deprecated and will be removed in the next version, please use 'ground_truth' instead. Note that `ground_truth` should be of type string and not Sequence[string] like `ground_truths`\n",
      "Evaluating:   0%|          | 0/60 [00:00<?, ?it/s]Runner in Executor raised an exception\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400, 'innererror': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_result': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': True, 'severity': 'medium'}}}}}\n",
      "Evaluating:  18%|█▊        | 11/60 [00:08<00:24,  1.98it/s]Runner in Executor raised an exception\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400, 'innererror': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_result': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': True, 'severity': 'medium'}}}}}\n",
      "Evaluating: 100%|██████████| 60/60 [00:15<00:00,  3.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average score is: 0.7622618233196597\n",
      "CHUNK SIZE 3000, 15% overlap:\n",
      "                    System  Faithfulness  Answer Relevancy  Context Precision  \\\n",
      "0  Chunk 3000, overlap 15%      0.531527          0.796436           0.912243   \n",
      "\n",
      "   Context Recall  Answer Similarity  Answer Correctness   Average  \n",
      "0        0.752622           0.764752            0.815992  0.762262  \n",
      "Number of chunks for chunk size 3000, overlap 20%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "passing column names as 'ground_truths' is deprecated and will be removed in the next version, please use 'ground_truth' instead. Note that `ground_truth` should be of type string and not Sequence[string] like `ground_truths`\n",
      "Evaluating:   0%|          | 0/60 [00:00<?, ?it/s]Runner in Executor raised an exception\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400, 'innererror': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_result': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': True, 'severity': 'medium'}}}}}\n",
      "Evaluating:  33%|███▎      | 20/60 [00:04<00:08,  4.97it/s]Runner in Executor raised an exception\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400, 'innererror': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_result': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': True, 'severity': 'medium'}, 'violence': {'filtered': False, 'severity': 'safe'}}}}}\n",
      "Evaluating: 100%|██████████| 60/60 [00:09<00:00,  6.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average score is: 0.7425948215364686\n",
      "CHUNK SIZE 3000, 20% overlap:\n",
      "                    System  Faithfulness  Answer Relevancy  Context Precision  \\\n",
      "0  Chunk 3000, overlap 20%      0.509508          0.751365           0.939013   \n",
      "\n",
      "   Context Recall  Answer Similarity  Answer Correctness   Average  \n",
      "0        0.654342           0.742385            0.858955  0.742595  \n"
     ]
    }
   ],
   "source": [
    "chunk_sizes = [500, 1000, 2000, 3000]\n",
    "overlap_percentages = [0, 5, 10, 15, 20]\n",
    "\n",
    "for chunk_size in chunk_sizes:\n",
    "    for overlap_percentage in overlap_percentages:\n",
    "        # Calculate overlap based on percentage\n",
    "        chunk_overlap = int(chunk_size * overlap_percentage / 100)\n",
    "        \n",
    "        # Create text splitter\n",
    "        # text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
    "        \n",
    "        # # Split documents\n",
    "        # chunks = text_splitter.split_documents(documents)\n",
    "        \n",
    "        # Print number of chunks\n",
    "        print(f\"Number of chunks for chunk size {chunk_size}, overlap {overlap_percentage}%\")\n",
    "        \n",
    "        # Create Chroma database\n",
    "        # db = Chroma.from_documents(chunks, embeddings_client, persist_directory=f\"../ballad/vectordb-edit/chunking_{chunk_size}_{overlap_percentage}\")\n",
    "        db = Chroma(persist_directory = \"../ballad/vectordb/recursive_basic\", embedding_function=embeddings_client)\n",
    "        # db.persist()\n",
    "        \n",
    "        # Create retriever\n",
    "        retriever = db.as_retriever()\n",
    "        \n",
    "        # Run and evaluate\n",
    "        result,results_df = run_and_evaluate(f\"Chunk {chunk_size}, overlap {overlap_percentage}%\", retriever, prompt, llm, results_df)\n",
    "        print(f\"CHUNK SIZE {chunk_size}, {overlap_percentage}% overlap:\")\n",
    "        print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "chunk = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # THE FIRST TIME RUN THIS, AFTER RUN THE NEXT CELL\n",
    "# text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(chunk_size = 1000, chunk_overlap = 100)\n",
    "# chunks_1000 = text_splitter.split_documents(documents)\n",
    "# print(len(chunks_1000))\n",
    "# db_1000 = Chroma.from_documents(chunks_1000, embeddings_client, persist_directory = \"../ballad/vectordb/recursive_1000\")\n",
    "# db_1000.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# db_1000 = Chroma(persist_directory = \"../ballad/vectordb/recursive_1000\", embedding_function=embeddings_client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "passing column names as 'ground_truths' is deprecated and will be removed in the next version, please use 'ground_truth' instead. Note that `ground_truth` should be of type string and not Sequence[string] like `ground_truths`\n",
      "Evaluating: 100%|██████████| 60/60 [00:13<00:00,  4.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHUNK SIZE 1000\n",
      "{'faithfulness': 0.9429, 'answer_relevancy': 0.8294, 'context_precision': 0.5889, 'context_recall': 0.8208, 'answer_similarity': 0.8868, 'answer_correctness': 0.4487}\n"
     ]
    }
   ],
   "source": [
    "# retriever_1000 = db_1000.as_retriever()\n",
    "# result_1000 = run_and_evaluate(retriever_1000, prompt, llm)\n",
    "# print(\"CHUNK SIZE 1000\")\n",
    "# print(result_1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average score is: 0.752912607504265\n"
     ]
    }
   ],
   "source": [
    "# dict_result_1000 = dictionary(result_1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "chunk = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107\n"
     ]
    }
   ],
   "source": [
    "# # THE FIRST TIME RUN THIS, AFTER RUN THE NEXT CELL\n",
    "# text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(chunk_size = 500, chunk_overlap = 50)\n",
    "# chunks_500 = text_splitter.split_documents(documents)\n",
    "# print(len(chunks_500))\n",
    "# db_500 = Chroma.from_documents(chunks_500, embeddings_client, persist_directory = \"../ballad/vectordb/recursive_500\")\n",
    "# db_500.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# db_500 = Chroma(persist_directory = \"../ballad/vectordb/recursive_500\", embedding_function=embeddings_client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400, 'innererror': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_result': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': True, 'severity': 'medium'}}}}}on the following question: What are the places 1-10 in the 10th Hunger Games?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "passing column names as 'ground_truths' is deprecated and will be removed in the next version, please use 'ground_truth' instead. Note that `ground_truth` should be of type string and not Sequence[string] like `ground_truths`\n",
      "Evaluating:   0%|          | 0/60 [00:00<?, ?it/s]Task exception was never retrieved\n",
      "future: <Task finished name='Task-333' coro=<AsyncClient.aclose() done, defined at c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\httpx\\_client.py:2011> exception=RuntimeError('Event loop is closed')>\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\httpx\\_client.py\", line 2018, in aclose\n",
      "    await self._transport.aclose()\n",
      "  File \"c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\httpx\\_transports\\default.py\", line 385, in aclose\n",
      "    await self._pool.aclose()\n",
      "  File \"c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\httpcore\\_async\\connection_pool.py\", line 313, in aclose\n",
      "    await self._close_connections(closing_connections)\n",
      "  File \"c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\httpcore\\_async\\connection_pool.py\", line 305, in _close_connections\n",
      "    await connection.aclose()\n",
      "  File \"c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\httpcore\\_async\\connection.py\", line 171, in aclose\n",
      "    await self._connection.aclose()\n",
      "  File \"c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\httpcore\\_async\\http11.py\", line 265, in aclose\n",
      "    await self._network_stream.aclose()\n",
      "  File \"c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\httpcore\\_backends\\anyio.py\", line 54, in aclose\n",
      "    await self._stream.aclose()\n",
      "  File \"c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\anyio\\streams\\tls.py\", line 202, in aclose\n",
      "    await self.transport_stream.aclose()\n",
      "  File \"c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 1191, in aclose\n",
      "    self._transport.close()\n",
      "  File \"C:\\Users\\sigitalapina\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\selector_events.py\", line 860, in close\n",
      "    self._loop.call_soon(self._call_connection_lost, None)\n",
      "  File \"C:\\Users\\sigitalapina\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\base_events.py\", line 761, in call_soon\n",
      "    self._check_closed()\n",
      "  File \"C:\\Users\\sigitalapina\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\base_events.py\", line 519, in _check_closed\n",
      "    raise RuntimeError('Event loop is closed')\n",
      "RuntimeError: Event loop is closed\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-334' coro=<AsyncClient.aclose() done, defined at c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\httpx\\_client.py:2011> exception=RuntimeError('Event loop is closed')>\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\httpx\\_client.py\", line 2018, in aclose\n",
      "    await self._transport.aclose()\n",
      "  File \"c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\httpx\\_transports\\default.py\", line 385, in aclose\n",
      "    await self._pool.aclose()\n",
      "  File \"c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\httpcore\\_async\\connection_pool.py\", line 313, in aclose\n",
      "    await self._close_connections(closing_connections)\n",
      "  File \"c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\httpcore\\_async\\connection_pool.py\", line 305, in _close_connections\n",
      "    await connection.aclose()\n",
      "  File \"c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\httpcore\\_async\\connection.py\", line 171, in aclose\n",
      "    await self._connection.aclose()\n",
      "  File \"c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\httpcore\\_async\\http11.py\", line 265, in aclose\n",
      "    await self._network_stream.aclose()\n",
      "  File \"c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\httpcore\\_backends\\anyio.py\", line 54, in aclose\n",
      "    await self._stream.aclose()\n",
      "  File \"c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\anyio\\streams\\tls.py\", line 202, in aclose\n",
      "    await self.transport_stream.aclose()\n",
      "  File \"c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 1191, in aclose\n",
      "    self._transport.close()\n",
      "  File \"C:\\Users\\sigitalapina\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\selector_events.py\", line 860, in close\n",
      "    self._loop.call_soon(self._call_connection_lost, None)\n",
      "  File \"C:\\Users\\sigitalapina\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\base_events.py\", line 761, in call_soon\n",
      "    self._check_closed()\n",
      "  File \"C:\\Users\\sigitalapina\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\base_events.py\", line 519, in _check_closed\n",
      "    raise RuntimeError('Event loop is closed')\n",
      "RuntimeError: Event loop is closed\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-335' coro=<AsyncClient.aclose() done, defined at c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\httpx\\_client.py:2011> exception=RuntimeError('Event loop is closed')>\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\httpx\\_client.py\", line 2018, in aclose\n",
      "    await self._transport.aclose()\n",
      "  File \"c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\httpx\\_transports\\default.py\", line 385, in aclose\n",
      "    await self._pool.aclose()\n",
      "  File \"c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\httpcore\\_async\\connection_pool.py\", line 313, in aclose\n",
      "    await self._close_connections(closing_connections)\n",
      "  File \"c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\httpcore\\_async\\connection_pool.py\", line 305, in _close_connections\n",
      "    await connection.aclose()\n",
      "  File \"c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\httpcore\\_async\\connection.py\", line 171, in aclose\n",
      "    await self._connection.aclose()\n",
      "  File \"c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\httpcore\\_async\\http11.py\", line 265, in aclose\n",
      "    await self._network_stream.aclose()\n",
      "  File \"c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\httpcore\\_backends\\anyio.py\", line 54, in aclose\n",
      "    await self._stream.aclose()\n",
      "  File \"c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\anyio\\streams\\tls.py\", line 202, in aclose\n",
      "    await self.transport_stream.aclose()\n",
      "  File \"c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 1191, in aclose\n",
      "    self._transport.close()\n",
      "  File \"C:\\Users\\sigitalapina\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\selector_events.py\", line 860, in close\n",
      "    self._loop.call_soon(self._call_connection_lost, None)\n",
      "  File \"C:\\Users\\sigitalapina\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\base_events.py\", line 761, in call_soon\n",
      "    self._check_closed()\n",
      "  File \"C:\\Users\\sigitalapina\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\base_events.py\", line 519, in _check_closed\n",
      "    raise RuntimeError('Event loop is closed')\n",
      "RuntimeError: Event loop is closed\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-336' coro=<AsyncClient.aclose() done, defined at c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\httpx\\_client.py:2011> exception=RuntimeError('Event loop is closed')>\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\httpx\\_client.py\", line 2018, in aclose\n",
      "    await self._transport.aclose()\n",
      "  File \"c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\httpx\\_transports\\default.py\", line 385, in aclose\n",
      "    await self._pool.aclose()\n",
      "  File \"c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\httpcore\\_async\\connection_pool.py\", line 313, in aclose\n",
      "    await self._close_connections(closing_connections)\n",
      "  File \"c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\httpcore\\_async\\connection_pool.py\", line 305, in _close_connections\n",
      "    await connection.aclose()\n",
      "  File \"c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\httpcore\\_async\\connection.py\", line 171, in aclose\n",
      "    await self._connection.aclose()\n",
      "  File \"c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\httpcore\\_async\\http11.py\", line 265, in aclose\n",
      "    await self._network_stream.aclose()\n",
      "  File \"c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\httpcore\\_backends\\anyio.py\", line 54, in aclose\n",
      "    await self._stream.aclose()\n",
      "  File \"c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\anyio\\streams\\tls.py\", line 202, in aclose\n",
      "    await self.transport_stream.aclose()\n",
      "  File \"c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 1191, in aclose\n",
      "    self._transport.close()\n",
      "  File \"C:\\Users\\sigitalapina\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\selector_events.py\", line 860, in close\n",
      "    self._loop.call_soon(self._call_connection_lost, None)\n",
      "  File \"C:\\Users\\sigitalapina\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\base_events.py\", line 761, in call_soon\n",
      "    self._check_closed()\n",
      "  File \"C:\\Users\\sigitalapina\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\base_events.py\", line 519, in _check_closed\n",
      "    raise RuntimeError('Event loop is closed')\n",
      "RuntimeError: Event loop is closed\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-337' coro=<AsyncClient.aclose() done, defined at c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\httpx\\_client.py:2011> exception=RuntimeError('Event loop is closed')>\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\httpx\\_client.py\", line 2018, in aclose\n",
      "    await self._transport.aclose()\n",
      "  File \"c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\httpx\\_transports\\default.py\", line 385, in aclose\n",
      "    await self._pool.aclose()\n",
      "  File \"c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\httpcore\\_async\\connection_pool.py\", line 313, in aclose\n",
      "    await self._close_connections(closing_connections)\n",
      "  File \"c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\httpcore\\_async\\connection_pool.py\", line 305, in _close_connections\n",
      "    await connection.aclose()\n",
      "  File \"c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\httpcore\\_async\\connection.py\", line 171, in aclose\n",
      "    await self._connection.aclose()\n",
      "  File \"c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\httpcore\\_async\\http11.py\", line 265, in aclose\n",
      "    await self._network_stream.aclose()\n",
      "  File \"c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\httpcore\\_backends\\anyio.py\", line 54, in aclose\n",
      "    await self._stream.aclose()\n",
      "  File \"c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\anyio\\streams\\tls.py\", line 202, in aclose\n",
      "    await self.transport_stream.aclose()\n",
      "  File \"c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 1191, in aclose\n",
      "    self._transport.close()\n",
      "  File \"C:\\Users\\sigitalapina\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\selector_events.py\", line 860, in close\n",
      "    self._loop.call_soon(self._call_connection_lost, None)\n",
      "  File \"C:\\Users\\sigitalapina\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\base_events.py\", line 761, in call_soon\n",
      "    self._check_closed()\n",
      "  File \"C:\\Users\\sigitalapina\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\base_events.py\", line 519, in _check_closed\n",
      "    raise RuntimeError('Event loop is closed')\n",
      "RuntimeError: Event loop is closed\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-338' coro=<AsyncClient.aclose() done, defined at c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\httpx\\_client.py:2011> exception=RuntimeError('Event loop is closed')>\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\httpx\\_client.py\", line 2018, in aclose\n",
      "    await self._transport.aclose()\n",
      "  File \"c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\httpx\\_transports\\default.py\", line 385, in aclose\n",
      "    await self._pool.aclose()\n",
      "  File \"c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\httpcore\\_async\\connection_pool.py\", line 313, in aclose\n",
      "    await self._close_connections(closing_connections)\n",
      "  File \"c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\httpcore\\_async\\connection_pool.py\", line 305, in _close_connections\n",
      "    await connection.aclose()\n",
      "  File \"c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\httpcore\\_async\\connection.py\", line 171, in aclose\n",
      "    await self._connection.aclose()\n",
      "  File \"c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\httpcore\\_async\\http11.py\", line 265, in aclose\n",
      "    await self._network_stream.aclose()\n",
      "  File \"c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\httpcore\\_backends\\anyio.py\", line 54, in aclose\n",
      "    await self._stream.aclose()\n",
      "  File \"c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\anyio\\streams\\tls.py\", line 202, in aclose\n",
      "    await self.transport_stream.aclose()\n",
      "  File \"c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 1191, in aclose\n",
      "    self._transport.close()\n",
      "  File \"C:\\Users\\sigitalapina\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\selector_events.py\", line 860, in close\n",
      "    self._loop.call_soon(self._call_connection_lost, None)\n",
      "  File \"C:\\Users\\sigitalapina\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\base_events.py\", line 761, in call_soon\n",
      "    self._check_closed()\n",
      "  File \"C:\\Users\\sigitalapina\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\base_events.py\", line 519, in _check_closed\n",
      "    raise RuntimeError('Event loop is closed')\n",
      "RuntimeError: Event loop is closed\n",
      "Runner in Executor raised an exception\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\ragas\\executor.py\", line 58, in _aresults\n",
      "    r = await future\n",
      "        ^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sigitalapina\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\tasks.py\", line 605, in _wait_for_one\n",
      "    return f.result()  # May raise f.exception().\n",
      "           ^^^^^^^^^^\n",
      "  File \"c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\ragas\\executor.py\", line 91, in wrapped_callable_async\n",
      "    return counter, await callable(*args, **kwargs)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\ragas\\metrics\\base.py\", line 91, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\ragas\\metrics\\base.py\", line 87, in ascore\n",
      "    score = await self._ascore(row=row, callbacks=group_cm, is_async=is_async)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\ragas\\metrics\\_answer_relevance.py\", line 136, in _ascore\n",
      "    result = await self.llm.generate(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\ragas\\llms\\base.py\", line 110, in generate\n",
      "    return await loop.run_in_executor(None, generate_text)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sigitalapina\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\concurrent\\futures\\thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\tenacity\\__init__.py\", line 289, in wrapped_f\n",
      "    return self(f, *args, **kw)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\tenacity\\__init__.py\", line 379, in __call__\n",
      "    do = self.iter(retry_state=retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\tenacity\\__init__.py\", line 314, in iter\n",
      "    return fut.result()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sigitalapina\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\concurrent\\futures\\_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sigitalapina\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\concurrent\\futures\\_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\tenacity\\__init__.py\", line 382, in __call__\n",
      "    result = fn(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\ragas\\llms\\base.py\", line 139, in generate_text\n",
      "    return self.langchain_llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 544, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 408, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 398, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 577, in _generate_with_cache\n",
      "    return self._generate(\n",
      "           ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 462, in _generate\n",
      "    response = self.client.create(messages=message_dicts, **params)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 275, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 663, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1200, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 889, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 980, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400, 'innererror': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_result': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': True, 'severity': 'medium'}}}}}\n",
      "Evaluating:  18%|█▊        | 11/60 [00:02<00:08,  5.80it/s]Runner in Executor raised an exception\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\ragas\\executor.py\", line 58, in _aresults\n",
      "    r = await future\n",
      "        ^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sigitalapina\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\tasks.py\", line 605, in _wait_for_one\n",
      "    return f.result()  # May raise f.exception().\n",
      "           ^^^^^^^^^^\n",
      "  File \"c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\ragas\\executor.py\", line 91, in wrapped_callable_async\n",
      "    return counter, await callable(*args, **kwargs)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\ragas\\metrics\\base.py\", line 91, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\ragas\\metrics\\base.py\", line 87, in ascore\n",
      "    score = await self._ascore(row=row, callbacks=group_cm, is_async=is_async)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\ragas\\metrics\\_faithfulness.py\", line 192, in _ascore\n",
      "    nli_result = await self.llm.generate(p, callbacks=callbacks, is_async=is_async)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\ragas\\llms\\base.py\", line 110, in generate\n",
      "    return await loop.run_in_executor(None, generate_text)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sigitalapina\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\concurrent\\futures\\thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\tenacity\\__init__.py\", line 289, in wrapped_f\n",
      "    return self(f, *args, **kw)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\tenacity\\__init__.py\", line 379, in __call__\n",
      "    do = self.iter(retry_state=retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\tenacity\\__init__.py\", line 314, in iter\n",
      "    return fut.result()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sigitalapina\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\concurrent\\futures\\_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sigitalapina\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\concurrent\\futures\\_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\tenacity\\__init__.py\", line 382, in __call__\n",
      "    result = fn(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\ragas\\llms\\base.py\", line 139, in generate_text\n",
      "    return self.langchain_llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 544, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 408, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 398, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 577, in _generate_with_cache\n",
      "    return self._generate(\n",
      "           ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 462, in _generate\n",
      "    response = self.client.create(messages=message_dicts, **params)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 275, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 663, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1200, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 889, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 980, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400, 'innererror': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_result': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': True, 'severity': 'medium'}}}}}\n",
      "Evaluating: 100%|██████████| 60/60 [00:10<00:00,  5.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHUNK SIZE 500\n",
      "{'faithfulness': 0.6822, 'answer_relevancy': 0.7488, 'context_precision': 0.5967, 'context_recall': 0.7615, 'answer_similarity': 0.8450, 'answer_correctness': 0.6514}\n"
     ]
    }
   ],
   "source": [
    "# retriever_500 = db_500.as_retriever()\n",
    "# result_500 = run_and_evaluate(retriever_500, prompt, llm)\n",
    "# print(\"CHUNK SIZE 500\")\n",
    "# print(result_500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average score is: 0.7142606903567085\n"
     ]
    }
   ],
   "source": [
    "# dict_result_500 = dictionary(result_500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "chunk = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37\n"
     ]
    }
   ],
   "source": [
    "# text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(chunk_size = 2000, chunk_overlap = 200)\n",
    "# chunks_2000 = text_splitter.split_documents(documents)\n",
    "# print(len(chunks_2000))\n",
    "# db_2000 = Chroma.from_documents(chunks_2000, embeddings_client, persist_directory = \"../ballad/vectordb/recursive_2000\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# db_2000 = Chroma(persist_directory = \"../ballad/vectordb/recursive_2000\", embedding_function=embeddings_client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "passing column names as 'ground_truths' is deprecated and will be removed in the next version, please use 'ground_truth' instead. Note that `ground_truth` should be of type string and not Sequence[string] like `ground_truths`\n",
      "Evaluating: 100%|██████████| 60/60 [00:13<00:00,  4.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHUNK SIZE 2000\n",
      "{'faithfulness': 0.7667, 'answer_relevancy': 0.8230, 'context_precision': 0.5972, 'context_recall': 0.8208, 'answer_similarity': 0.8832, 'answer_correctness': 0.5073}\n"
     ]
    }
   ],
   "source": [
    "# retriever_2000 = db_2000.as_retriever()\n",
    "# result_2000 = run_and_evaluate(retriever_2000, prompt, llm)\n",
    "# print(\"CHUNK SIZE 2000\")\n",
    "# print(result_2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average score is: 0.7330396049761241\n"
     ]
    }
   ],
   "source": [
    "# dict_result_2000 = dictionary(result_2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "chunk = 3000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n"
     ]
    }
   ],
   "source": [
    "# text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(chunk_size = 3000, chunk_overlap = 300)\n",
    "# chunks_3000 = text_splitter.split_documents(documents)\n",
    "# print(len(chunks_3000))\n",
    "# db_3000 = Chroma.from_documents(chunks_3000, embeddings_client, persist_directory = \"../ballad/vectordb/recursive_3000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# db_3000 = Chroma(persist_directory = \"../ballad/vectordb/recursive_3000\", embedding_function=embeddings_client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "passing column names as 'ground_truths' is deprecated and will be removed in the next version, please use 'ground_truth' instead. Note that `ground_truth` should be of type string and not Sequence[string] like `ground_truths`\n",
      "Evaluating: 100%|██████████| 60/60 [00:14<00:00,  4.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHUNK SIZE 3000\n",
      "{'faithfulness': 0.8595, 'answer_relevancy': 0.8386, 'context_precision': 0.6333, 'context_recall': 0.8208, 'answer_similarity': 0.8843, 'answer_correctness': 0.4686}\n"
     ]
    }
   ],
   "source": [
    "# retriever_3000 = db_3000.as_retriever()\n",
    "# result_3000 = run_and_evaluate(retriever_3000, prompt, llm)\n",
    "# print(\"CHUNK SIZE 3000\")\n",
    "# print(result_3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average score is: 0.7508713801108652\n"
     ]
    }
   ],
   "source": [
    "# dict_result_3000 = dictionary(result_3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>System</th>\n",
       "      <th>Faithfulness</th>\n",
       "      <th>Answer Relevancy</th>\n",
       "      <th>Context Precision</th>\n",
       "      <th>Context Recall</th>\n",
       "      <th>Answer Similarity</th>\n",
       "      <th>Answer Correctness</th>\n",
       "      <th>Average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GPT-3.5</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.379673</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.841376</td>\n",
       "      <td>0.410613</td>\n",
       "      <td>0.663610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GPT-4</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.695899</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.900098</td>\n",
       "      <td>0.492424</td>\n",
       "      <td>0.742388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Naive</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.831993</td>\n",
       "      <td>0.597222</td>\n",
       "      <td>0.820833</td>\n",
       "      <td>0.878165</td>\n",
       "      <td>0.413080</td>\n",
       "      <td>0.747623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Recursive</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.837124</td>\n",
       "      <td>0.597222</td>\n",
       "      <td>0.771429</td>\n",
       "      <td>0.878165</td>\n",
       "      <td>0.402142</td>\n",
       "      <td>0.738421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Chunk 500, overlap 0%</td>\n",
       "      <td>0.532729</td>\n",
       "      <td>0.803469</td>\n",
       "      <td>0.907841</td>\n",
       "      <td>0.752864</td>\n",
       "      <td>0.731083</td>\n",
       "      <td>0.795908</td>\n",
       "      <td>0.753982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Chunk 500, overlap 5%</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>0.829388</td>\n",
       "      <td>0.597222</td>\n",
       "      <td>0.808333</td>\n",
       "      <td>0.882359</td>\n",
       "      <td>0.441887</td>\n",
       "      <td>0.746532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Chunk 500, overlap 10%</td>\n",
       "      <td>0.531527</td>\n",
       "      <td>0.775393</td>\n",
       "      <td>0.907932</td>\n",
       "      <td>0.753544</td>\n",
       "      <td>0.731083</td>\n",
       "      <td>0.802336</td>\n",
       "      <td>0.750303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Chunk 500, overlap 15%</td>\n",
       "      <td>0.800333</td>\n",
       "      <td>0.951028</td>\n",
       "      <td>0.616525</td>\n",
       "      <td>0.783333</td>\n",
       "      <td>0.890919</td>\n",
       "      <td>0.541697</td>\n",
       "      <td>0.763972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Chunk 500, overlap 20%</td>\n",
       "      <td>0.816002</td>\n",
       "      <td>0.950323</td>\n",
       "      <td>0.616575</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.890744</td>\n",
       "      <td>0.532502</td>\n",
       "      <td>0.759358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Chunk 1000, overlap 0%</td>\n",
       "      <td>0.790545</td>\n",
       "      <td>0.932472</td>\n",
       "      <td>0.654176</td>\n",
       "      <td>0.783333</td>\n",
       "      <td>0.890744</td>\n",
       "      <td>0.533308</td>\n",
       "      <td>0.764096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Chunk 1000, overlap 5%</td>\n",
       "      <td>0.757331</td>\n",
       "      <td>0.951969</td>\n",
       "      <td>0.582974</td>\n",
       "      <td>0.783333</td>\n",
       "      <td>0.878419</td>\n",
       "      <td>0.542546</td>\n",
       "      <td>0.749429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Chunk 1000, overlap 10%</td>\n",
       "      <td>0.854167</td>\n",
       "      <td>0.746491</td>\n",
       "      <td>0.597222</td>\n",
       "      <td>0.775000</td>\n",
       "      <td>0.880496</td>\n",
       "      <td>0.433163</td>\n",
       "      <td>0.714423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Chunk 1000, overlap 15%</td>\n",
       "      <td>0.764960</td>\n",
       "      <td>0.949421</td>\n",
       "      <td>0.654338</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.878244</td>\n",
       "      <td>0.534169</td>\n",
       "      <td>0.755189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Chunk 1000, overlap 20%</td>\n",
       "      <td>0.786958</td>\n",
       "      <td>0.951187</td>\n",
       "      <td>0.619133</td>\n",
       "      <td>0.783333</td>\n",
       "      <td>0.890919</td>\n",
       "      <td>0.544212</td>\n",
       "      <td>0.762624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Chunk 2000, overlap 0%</td>\n",
       "      <td>0.753625</td>\n",
       "      <td>0.949662</td>\n",
       "      <td>0.616641</td>\n",
       "      <td>0.783333</td>\n",
       "      <td>0.864847</td>\n",
       "      <td>0.542546</td>\n",
       "      <td>0.751776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Chunk 2000, overlap 5%</td>\n",
       "      <td>0.400117</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.829433</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>0.801053</td>\n",
       "      <td>0.873055</td>\n",
       "      <td>0.744261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Chunk 2000, overlap 10%</td>\n",
       "      <td>0.769649</td>\n",
       "      <td>0.940600</td>\n",
       "      <td>0.655261</td>\n",
       "      <td>0.783333</td>\n",
       "      <td>0.878579</td>\n",
       "      <td>0.544252</td>\n",
       "      <td>0.761946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Chunk 2000, overlap 15%</td>\n",
       "      <td>0.784939</td>\n",
       "      <td>0.955299</td>\n",
       "      <td>0.652623</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.889133</td>\n",
       "      <td>0.543388</td>\n",
       "      <td>0.762564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Chunk 2000, overlap 20%</td>\n",
       "      <td>0.762311</td>\n",
       "      <td>0.944377</td>\n",
       "      <td>0.582052</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.874847</td>\n",
       "      <td>0.542521</td>\n",
       "      <td>0.742685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Chunk 3000, overlap 0%</td>\n",
       "      <td>0.779172</td>\n",
       "      <td>0.949059</td>\n",
       "      <td>0.652841</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.878084</td>\n",
       "      <td>0.532462</td>\n",
       "      <td>0.756936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Chunk 3000, overlap 5%</td>\n",
       "      <td>0.767551</td>\n",
       "      <td>0.942964</td>\n",
       "      <td>0.617704</td>\n",
       "      <td>0.783333</td>\n",
       "      <td>0.868084</td>\n",
       "      <td>0.532438</td>\n",
       "      <td>0.752012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Chunk 3000, overlap 10%</td>\n",
       "      <td>0.765109</td>\n",
       "      <td>0.949812</td>\n",
       "      <td>0.619150</td>\n",
       "      <td>0.783333</td>\n",
       "      <td>0.878084</td>\n",
       "      <td>0.534129</td>\n",
       "      <td>0.754936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Chunk 3000, overlap 15%</td>\n",
       "      <td>0.531527</td>\n",
       "      <td>0.796436</td>\n",
       "      <td>0.912243</td>\n",
       "      <td>0.752622</td>\n",
       "      <td>0.764752</td>\n",
       "      <td>0.815992</td>\n",
       "      <td>0.762262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Chunk 3000, overlap 20%</td>\n",
       "      <td>0.509508</td>\n",
       "      <td>0.751365</td>\n",
       "      <td>0.939013</td>\n",
       "      <td>0.654342</td>\n",
       "      <td>0.742385</td>\n",
       "      <td>0.858955</td>\n",
       "      <td>0.742595</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     System  Faithfulness  Answer Relevancy  \\\n",
       "0                   GPT-3.5      1.000000          0.379673   \n",
       "1                     GPT-4      1.000000          0.695899   \n",
       "2                     Naive      0.944444          0.831993   \n",
       "3                 Recursive      0.944444          0.837124   \n",
       "4     Chunk 500, overlap 0%      0.532729          0.803469   \n",
       "5     Chunk 500, overlap 5%      0.920000          0.829388   \n",
       "6    Chunk 500, overlap 10%      0.531527          0.775393   \n",
       "7    Chunk 500, overlap 15%      0.800333          0.951028   \n",
       "8    Chunk 500, overlap 20%      0.816002          0.950323   \n",
       "9    Chunk 1000, overlap 0%      0.790545          0.932472   \n",
       "10   Chunk 1000, overlap 5%      0.757331          0.951969   \n",
       "11  Chunk 1000, overlap 10%      0.854167          0.746491   \n",
       "12  Chunk 1000, overlap 15%      0.764960          0.949421   \n",
       "13  Chunk 1000, overlap 20%      0.786958          0.951187   \n",
       "14   Chunk 2000, overlap 0%      0.753625          0.949662   \n",
       "15   Chunk 2000, overlap 5%      0.400117          0.928571   \n",
       "16  Chunk 2000, overlap 10%      0.769649          0.940600   \n",
       "17  Chunk 2000, overlap 15%      0.784939          0.955299   \n",
       "18  Chunk 2000, overlap 20%      0.762311          0.944377   \n",
       "19   Chunk 3000, overlap 0%      0.779172          0.949059   \n",
       "20   Chunk 3000, overlap 5%      0.767551          0.942964   \n",
       "21  Chunk 3000, overlap 10%      0.765109          0.949812   \n",
       "22  Chunk 3000, overlap 15%      0.531527          0.796436   \n",
       "23  Chunk 3000, overlap 20%      0.509508          0.751365   \n",
       "\n",
       "    Context Precision  Context Recall  Answer Similarity  Answer Correctness  \\\n",
       "0                 NaN             NaN           0.841376            0.410613   \n",
       "1                 NaN             NaN           0.900098            0.492424   \n",
       "2            0.597222        0.820833           0.878165            0.413080   \n",
       "3            0.597222        0.771429           0.878165            0.402142   \n",
       "4            0.907841        0.752864           0.731083            0.795908   \n",
       "5            0.597222        0.808333           0.882359            0.441887   \n",
       "6            0.907932        0.753544           0.731083            0.802336   \n",
       "7            0.616525        0.783333           0.890919            0.541697   \n",
       "8            0.616575        0.750000           0.890744            0.532502   \n",
       "9            0.654176        0.783333           0.890744            0.533308   \n",
       "10           0.582974        0.783333           0.878419            0.542546   \n",
       "11           0.597222        0.775000           0.880496            0.433163   \n",
       "12           0.654338        0.750000           0.878244            0.534169   \n",
       "13           0.619133        0.783333           0.890919            0.544212   \n",
       "14           0.616641        0.783333           0.864847            0.542546   \n",
       "15           0.829433        0.633333           0.801053            0.873055   \n",
       "16           0.655261        0.783333           0.878579            0.544252   \n",
       "17           0.652623        0.750000           0.889133            0.543388   \n",
       "18           0.582052        0.750000           0.874847            0.542521   \n",
       "19           0.652841        0.750000           0.878084            0.532462   \n",
       "20           0.617704        0.783333           0.868084            0.532438   \n",
       "21           0.619150        0.783333           0.878084            0.534129   \n",
       "22           0.912243        0.752622           0.764752            0.815992   \n",
       "23           0.939013        0.654342           0.742385            0.858955   \n",
       "\n",
       "     Average  \n",
       "0   0.663610  \n",
       "1   0.742388  \n",
       "2   0.747623  \n",
       "3   0.738421  \n",
       "4   0.753982  \n",
       "5   0.746532  \n",
       "6   0.750303  \n",
       "7   0.763972  \n",
       "8   0.759358  \n",
       "9   0.764096  \n",
       "10  0.749429  \n",
       "11  0.714423  \n",
       "12  0.755189  \n",
       "13  0.762624  \n",
       "14  0.751776  \n",
       "15  0.744261  \n",
       "16  0.761946  \n",
       "17  0.762564  \n",
       "18  0.742685  \n",
       "19  0.756936  \n",
       "20  0.752012  \n",
       "21  0.754936  \n",
       "22  0.762262  \n",
       "23  0.742595  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Highest average value: 0.764096212592404\n"
     ]
    }
   ],
   "source": [
    "highest_average = results_df[\"Average\"].max()\n",
    "print(\"Highest average value:\", highest_average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.to_csv(f\"../ballad/results/results_summarize.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### now time to look for different top-k\n",
    "\n",
    "Note: We continue with the size chunk of 1000 as it had the highest average score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_k = Chroma(persist_directory = \"../ballad/vectordb-edit/chunking_1000_0\", embedding_function=embeddings_client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "passing column names as 'ground_truths' is deprecated and will be removed in the next version, please use 'ground_truth' instead. Note that `ground_truth` should be of type string and not Sequence[string] like `ground_truths`\n",
      "Evaluating:   0%|          | 0/60 [00:00<?, ?it/s]Task exception was never retrieved\n",
      "future: <Task finished name='Task-1954' coro=<AsyncClient.aclose() done, defined at c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\httpx\\_client.py:2011> exception=RuntimeError('Event loop is closed')>\n",
      "RuntimeError: Event loop is closed\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1955' coro=<AsyncClient.aclose() done, defined at c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\httpx\\_client.py:2011> exception=RuntimeError('Event loop is closed')>\n",
      "RuntimeError: Event loop is closed\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1956' coro=<AsyncClient.aclose() done, defined at c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\httpx\\_client.py:2011> exception=RuntimeError('Event loop is closed')>\n",
      "RuntimeError: Event loop is closed\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1957' coro=<AsyncClient.aclose() done, defined at c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\httpx\\_client.py:2011> exception=RuntimeError('Event loop is closed')>\n",
      "RuntimeError: Event loop is closed\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1958' coro=<AsyncClient.aclose() done, defined at c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\httpx\\_client.py:2011> exception=RuntimeError('Event loop is closed')>\n",
      "RuntimeError: Event loop is closed\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1959' coro=<AsyncClient.aclose() done, defined at c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\httpx\\_client.py:2011> exception=RuntimeError('Event loop is closed')>\n",
      "RuntimeError: Event loop is closed\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1960' coro=<AsyncClient.aclose() done, defined at c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\httpx\\_client.py:2011> exception=RuntimeError('Event loop is closed')>\n",
      "RuntimeError: Event loop is closed\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1961' coro=<AsyncClient.aclose() done, defined at c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\httpx\\_client.py:2011> exception=RuntimeError('Event loop is closed')>\n",
      "RuntimeError: Event loop is closed\n",
      "Evaluating:  15%|█▌        | 9/60 [00:02<00:08,  5.89it/s]Runner in Executor raised an exception\n",
      "TypeError: expected string or buffer\n",
      "Evaluating: 100%|██████████| 60/60 [00:13<00:00,  4.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average score is: 0.781972560978867\n",
      "This is the new best value!\n",
      "Results for K=7:\n",
      "                              System  Faithfulness  Answer Relevancy  \\\n",
      "0  Chunk size 3000, overlap 20%, K=7      0.911223          0.825997   \n",
      "\n",
      "   Context Precision  Context Recall  Answer Similarity  Answer Correctness  \\\n",
      "0           0.635716        0.884008           0.913225            0.521667   \n",
      "\n",
      "    Average  \n",
      "0  0.781973  \n"
     ]
    }
   ],
   "source": [
    "k_values = [2, 3, 5, 6, 7]\n",
    "\n",
    "# Iterate over different k values\n",
    "for k in k_values:\n",
    "    # Create retriever with k value\n",
    "    retriever = db_k.as_retriever(search_kwargs={\"k\": k})\n",
    "    \n",
    "    # Run and evaluate\n",
    "    result,results_df = run_and_evaluate(f\"Chunk size 1000, overlap 0%, K={k}\", retriever, prompt, llm, results_df)\n",
    "    print(f\"Results for K={k}:\")\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400, 'innererror': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_result': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': True, 'severity': 'medium'}}}}}on the following question: What are the places 1-10 in the 10th Hunger Games?\n",
      "Warning: Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400, 'innererror': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_result': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': True, 'severity': 'medium'}}}}}on the following question: What evidence does Snow secretly record and send to Dr. Gaul, and what is the result of that?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "passing column names as 'ground_truths' is deprecated and will be removed in the next version, please use 'ground_truth' instead. Note that `ground_truth` should be of type string and not Sequence[string] like `ground_truths`\n",
      "Evaluating:  18%|█▊        | 11/60 [00:02<00:06,  7.10it/s]Runner in Executor raised an exception\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\ragas\\executor.py\", line 58, in _aresults\n",
      "    r = await future\n",
      "        ^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sigitalapina\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\tasks.py\", line 605, in _wait_for_one\n",
      "    return f.result()  # May raise f.exception().\n",
      "           ^^^^^^^^^^\n",
      "  File \"c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\ragas\\executor.py\", line 91, in wrapped_callable_async\n",
      "    return counter, await callable(*args, **kwargs)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\ragas\\metrics\\base.py\", line 91, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\ragas\\metrics\\base.py\", line 87, in ascore\n",
      "    score = await self._ascore(row=row, callbacks=group_cm, is_async=is_async)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\ragas\\metrics\\_answer_relevance.py\", line 147, in _ascore\n",
      "    return self._calculate_score(response, row)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\ragas\\metrics\\_answer_relevance.py\", line 123, in _calculate_score\n",
      "    cosine_sim = self.calculate_similarity(question, gen_questions)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\ragas\\metrics\\_answer_relevance.py\", line 93, in calculate_similarity\n",
      "    self.embeddings.embed_documents(generated_questions)\n",
      "  File \"c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\ragas\\embeddings\\base.py\", line 58, in embed_documents\n",
      "    return self.embeddings.embed_documents(texts)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\langchain_openai\\embeddings\\base.py\", line 508, in embed_documents\n",
      "    return self._get_len_safe_embeddings(texts, engine=engine)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\langchain_openai\\embeddings\\base.py\", line 301, in _get_len_safe_embeddings\n",
      "    token = encoding.encode(\n",
      "            ^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\tiktoken\\core.py\", line 116, in encode\n",
      "    if match := _special_token_regex(disallowed_special).search(text):\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: expected string or buffer\n",
      "Evaluating:  25%|██▌       | 15/60 [00:04<00:12,  3.69it/s]Runner in Executor raised an exception\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\ragas\\executor.py\", line 58, in _aresults\n",
      "    r = await future\n",
      "        ^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sigitalapina\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\tasks.py\", line 605, in _wait_for_one\n",
      "    return f.result()  # May raise f.exception().\n",
      "           ^^^^^^^^^^\n",
      "  File \"c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\ragas\\executor.py\", line 91, in wrapped_callable_async\n",
      "    return counter, await callable(*args, **kwargs)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\ragas\\metrics\\base.py\", line 91, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\ragas\\metrics\\base.py\", line 87, in ascore\n",
      "    score = await self._ascore(row=row, callbacks=group_cm, is_async=is_async)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\ragas\\metrics\\_answer_relevance.py\", line 147, in _ascore\n",
      "    return self._calculate_score(response, row)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\ragas\\metrics\\_answer_relevance.py\", line 123, in _calculate_score\n",
      "    cosine_sim = self.calculate_similarity(question, gen_questions)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\ragas\\metrics\\_answer_relevance.py\", line 93, in calculate_similarity\n",
      "    self.embeddings.embed_documents(generated_questions)\n",
      "  File \"c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\ragas\\embeddings\\base.py\", line 58, in embed_documents\n",
      "    return self.embeddings.embed_documents(texts)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\langchain_openai\\embeddings\\base.py\", line 508, in embed_documents\n",
      "    return self._get_len_safe_embeddings(texts, engine=engine)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\langchain_openai\\embeddings\\base.py\", line 301, in _get_len_safe_embeddings\n",
      "    token = encoding.encode(\n",
      "            ^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\tiktoken\\core.py\", line 116, in encode\n",
      "    if match := _special_token_regex(disallowed_special).search(text):\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: expected string or buffer\n",
      "Runner in Executor raised an exception\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\ragas\\executor.py\", line 58, in _aresults\n",
      "    r = await future\n",
      "        ^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sigitalapina\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\tasks.py\", line 605, in _wait_for_one\n",
      "    return f.result()  # May raise f.exception().\n",
      "           ^^^^^^^^^^\n",
      "  File \"c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\ragas\\executor.py\", line 91, in wrapped_callable_async\n",
      "    return counter, await callable(*args, **kwargs)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\ragas\\metrics\\base.py\", line 91, in ascore\n",
      "    raise e\n",
      "  File \"c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\ragas\\metrics\\base.py\", line 87, in ascore\n",
      "    score = await self._ascore(row=row, callbacks=group_cm, is_async=is_async)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\ragas\\metrics\\_faithfulness.py\", line 192, in _ascore\n",
      "    nli_result = await self.llm.generate(p, callbacks=callbacks, is_async=is_async)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\ragas\\llms\\base.py\", line 110, in generate\n",
      "    return await loop.run_in_executor(None, generate_text)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sigitalapina\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\concurrent\\futures\\thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\tenacity\\__init__.py\", line 289, in wrapped_f\n",
      "    return self(f, *args, **kw)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\tenacity\\__init__.py\", line 379, in __call__\n",
      "    do = self.iter(retry_state=retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\tenacity\\__init__.py\", line 314, in iter\n",
      "    return fut.result()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sigitalapina\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\concurrent\\futures\\_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sigitalapina\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\concurrent\\futures\\_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\tenacity\\__init__.py\", line 382, in __call__\n",
      "    result = fn(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\ragas\\llms\\base.py\", line 139, in generate_text\n",
      "    return self.langchain_llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 544, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 408, in generate\n",
      "    raise e\n",
      "  File \"c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 398, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 577, in _generate_with_cache\n",
      "    return self._generate(\n",
      "           ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py\", line 462, in _generate\n",
      "    response = self.client.create(messages=message_dicts, **params)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 275, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 663, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1200, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 889, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 980, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400, 'innererror': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_result': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': True, 'severity': 'medium'}}}}}\n",
      "Evaluating: 100%|██████████| 60/60 [00:12<00:00,  4.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHUNK SIZE 1000, K=3\n",
      "{'faithfulness': 0.5797, 'answer_relevancy': 0.7975, 'context_precision': 0.5393, 'context_recall': 0.6875, 'answer_similarity': 0.7113, 'answer_correctness': 0.7793}\n"
     ]
    }
   ],
   "source": [
    "# retriever_3 = db_1000.as_retriever(search_kwargs={\"k\": 3})\n",
    "# result_3 = run_and_evaluate(retriever_3, prompt, llm)\n",
    "# print(\"CHUNK SIZE 1000, K=3\")\n",
    "# print(result_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average score is: 0.6824532277442156\n"
     ]
    }
   ],
   "source": [
    "# dict_result_3 = dictionary(result_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "passing column names as 'ground_truths' is deprecated and will be removed in the next version, please use 'ground_truth' instead. Note that `ground_truth` should be of type string and not Sequence[string] like `ground_truths`\n",
      "Evaluating: 100%|██████████| 60/60 [00:14<00:00,  4.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHUNK SIZE 1000, K=5\n",
      "{'faithfulness': 0.8000, 'answer_relevancy': 0.8256, 'context_precision': 0.5815, 'context_recall': 0.7800, 'answer_similarity': 0.8859, 'answer_correctness': 0.4240}\n"
     ]
    }
   ],
   "source": [
    "# retriever_5 = db_1000.as_retriever(search_kwargs={\"k\": 5})\n",
    "# result_5 = run_and_evaluate(retriever_5, prompt, llm)\n",
    "# print(\"CHUNK SIZE 1000, K=5\")\n",
    "# print(result_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average score is: 0.7161788734282134\n"
     ]
    }
   ],
   "source": [
    "# dict_result_5 = dictionary(result_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "passing column names as 'ground_truths' is deprecated and will be removed in the next version, please use 'ground_truth' instead. Note that `ground_truth` should be of type string and not Sequence[string] like `ground_truths`\n",
      "Evaluating: 100%|██████████| 60/60 [00:15<00:00,  3.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHUNK SIZE 1000, K=5\n",
      "{'faithfulness': 0.8256, 'answer_relevancy': 0.8338, 'context_precision': 0.5782, 'context_recall': 0.8800, 'answer_similarity': 0.8907, 'answer_correctness': 0.5280}\n"
     ]
    }
   ],
   "source": [
    "# retriever_6= db_1000.as_retriever(search_kwargs={\"k\": 6})\n",
    "# result_6 = run_and_evaluate(retriever_6, prompt, llm)\n",
    "# print(\"CHUNK SIZE 1000, K=5\")\n",
    "# print(result_6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average score is: 0.7560586606303001\n"
     ]
    }
   ],
   "source": [
    "# dict_result_6 = dictionary(result_6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "passing column names as 'ground_truths' is deprecated and will be removed in the next version, please use 'ground_truth' instead. Note that `ground_truth` should be of type string and not Sequence[string] like `ground_truths`\n",
      "Evaluating: 100%|██████████| 60/60 [00:13<00:00,  4.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHUNK SIZE 1000, K=7\n",
      "{'faithfulness': 0.9429, 'answer_relevancy': 0.8166, 'context_precision': 0.5914, 'context_recall': 0.7633, 'answer_similarity': 0.8919, 'answer_correctness': 0.5029}\n",
      "The average score is: 0.751507469027492\n"
     ]
    }
   ],
   "source": [
    "# retriever_7= db_1000.as_retriever(search_kwargs={\"k\": 7})\n",
    "# result_7 = run_and_evaluate(retriever_7, prompt, llm)\n",
    "# print(\"CHUNK SIZE 1000, K=7\")\n",
    "# print(result_7)\n",
    "# dict_result_7 = dictionary(result_7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>System</th>\n",
       "      <th>Faithfulness</th>\n",
       "      <th>Answer Relevancy</th>\n",
       "      <th>Context Precision</th>\n",
       "      <th>Context Recall</th>\n",
       "      <th>Answer Similarity</th>\n",
       "      <th>Answer Correctness</th>\n",
       "      <th>Average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GPT-3.5</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.379673</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.841376</td>\n",
       "      <td>0.410613</td>\n",
       "      <td>0.663610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GPT-4</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.695899</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.900098</td>\n",
       "      <td>0.492424</td>\n",
       "      <td>0.742388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Naive</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.831993</td>\n",
       "      <td>0.597222</td>\n",
       "      <td>0.820833</td>\n",
       "      <td>0.878165</td>\n",
       "      <td>0.413080</td>\n",
       "      <td>0.747623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Recursive</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.837124</td>\n",
       "      <td>0.597222</td>\n",
       "      <td>0.771429</td>\n",
       "      <td>0.878165</td>\n",
       "      <td>0.402142</td>\n",
       "      <td>0.738421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Chunk 500, overlap 0%</td>\n",
       "      <td>0.532729</td>\n",
       "      <td>0.803469</td>\n",
       "      <td>0.907841</td>\n",
       "      <td>0.752864</td>\n",
       "      <td>0.731083</td>\n",
       "      <td>0.795908</td>\n",
       "      <td>0.753982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Chunk 500, overlap 5%</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>0.829388</td>\n",
       "      <td>0.597222</td>\n",
       "      <td>0.808333</td>\n",
       "      <td>0.882359</td>\n",
       "      <td>0.441887</td>\n",
       "      <td>0.746532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Chunk 500, overlap 10%</td>\n",
       "      <td>0.531527</td>\n",
       "      <td>0.775393</td>\n",
       "      <td>0.907932</td>\n",
       "      <td>0.753544</td>\n",
       "      <td>0.731083</td>\n",
       "      <td>0.802336</td>\n",
       "      <td>0.750303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Chunk 500, overlap 15%</td>\n",
       "      <td>0.800333</td>\n",
       "      <td>0.951028</td>\n",
       "      <td>0.616525</td>\n",
       "      <td>0.783333</td>\n",
       "      <td>0.890919</td>\n",
       "      <td>0.541697</td>\n",
       "      <td>0.763972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Chunk 500, overlap 20%</td>\n",
       "      <td>0.816002</td>\n",
       "      <td>0.950323</td>\n",
       "      <td>0.616575</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.890744</td>\n",
       "      <td>0.532502</td>\n",
       "      <td>0.759358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Chunk 1000, overlap 0%</td>\n",
       "      <td>0.790545</td>\n",
       "      <td>0.932472</td>\n",
       "      <td>0.654176</td>\n",
       "      <td>0.783333</td>\n",
       "      <td>0.890744</td>\n",
       "      <td>0.533308</td>\n",
       "      <td>0.764096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Chunk 1000, overlap 5%</td>\n",
       "      <td>0.757331</td>\n",
       "      <td>0.951969</td>\n",
       "      <td>0.582974</td>\n",
       "      <td>0.783333</td>\n",
       "      <td>0.878419</td>\n",
       "      <td>0.542546</td>\n",
       "      <td>0.749429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Chunk 1000, overlap 10%</td>\n",
       "      <td>0.854167</td>\n",
       "      <td>0.746491</td>\n",
       "      <td>0.597222</td>\n",
       "      <td>0.775000</td>\n",
       "      <td>0.880496</td>\n",
       "      <td>0.433163</td>\n",
       "      <td>0.714423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Chunk 1000, overlap 15%</td>\n",
       "      <td>0.764960</td>\n",
       "      <td>0.949421</td>\n",
       "      <td>0.654338</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.878244</td>\n",
       "      <td>0.534169</td>\n",
       "      <td>0.755189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Chunk 1000, overlap 20%</td>\n",
       "      <td>0.786958</td>\n",
       "      <td>0.951187</td>\n",
       "      <td>0.619133</td>\n",
       "      <td>0.783333</td>\n",
       "      <td>0.890919</td>\n",
       "      <td>0.544212</td>\n",
       "      <td>0.762624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Chunk 2000, overlap 0%</td>\n",
       "      <td>0.753625</td>\n",
       "      <td>0.949662</td>\n",
       "      <td>0.616641</td>\n",
       "      <td>0.783333</td>\n",
       "      <td>0.864847</td>\n",
       "      <td>0.542546</td>\n",
       "      <td>0.751776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Chunk 2000, overlap 5%</td>\n",
       "      <td>0.400117</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.829433</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>0.801053</td>\n",
       "      <td>0.873055</td>\n",
       "      <td>0.744261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Chunk 2000, overlap 10%</td>\n",
       "      <td>0.769649</td>\n",
       "      <td>0.940600</td>\n",
       "      <td>0.655261</td>\n",
       "      <td>0.783333</td>\n",
       "      <td>0.878579</td>\n",
       "      <td>0.544252</td>\n",
       "      <td>0.761946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Chunk 2000, overlap 15%</td>\n",
       "      <td>0.784939</td>\n",
       "      <td>0.955299</td>\n",
       "      <td>0.652623</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.889133</td>\n",
       "      <td>0.543388</td>\n",
       "      <td>0.762564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Chunk 2000, overlap 20%</td>\n",
       "      <td>0.762311</td>\n",
       "      <td>0.944377</td>\n",
       "      <td>0.582052</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.874847</td>\n",
       "      <td>0.542521</td>\n",
       "      <td>0.742685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Chunk 3000, overlap 0%</td>\n",
       "      <td>0.779172</td>\n",
       "      <td>0.949059</td>\n",
       "      <td>0.652841</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.878084</td>\n",
       "      <td>0.532462</td>\n",
       "      <td>0.756936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Chunk 3000, overlap 5%</td>\n",
       "      <td>0.767551</td>\n",
       "      <td>0.942964</td>\n",
       "      <td>0.617704</td>\n",
       "      <td>0.783333</td>\n",
       "      <td>0.868084</td>\n",
       "      <td>0.532438</td>\n",
       "      <td>0.752012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Chunk 3000, overlap 10%</td>\n",
       "      <td>0.765109</td>\n",
       "      <td>0.949812</td>\n",
       "      <td>0.619150</td>\n",
       "      <td>0.783333</td>\n",
       "      <td>0.878084</td>\n",
       "      <td>0.534129</td>\n",
       "      <td>0.754936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Chunk 3000, overlap 15%</td>\n",
       "      <td>0.531527</td>\n",
       "      <td>0.796436</td>\n",
       "      <td>0.912243</td>\n",
       "      <td>0.752622</td>\n",
       "      <td>0.764752</td>\n",
       "      <td>0.815992</td>\n",
       "      <td>0.762262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Chunk 3000, overlap 20%</td>\n",
       "      <td>0.509508</td>\n",
       "      <td>0.751365</td>\n",
       "      <td>0.939013</td>\n",
       "      <td>0.654342</td>\n",
       "      <td>0.742385</td>\n",
       "      <td>0.858955</td>\n",
       "      <td>0.742595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Chunk size 3000, overlap 20%, K=2</td>\n",
       "      <td>0.489705</td>\n",
       "      <td>0.611479</td>\n",
       "      <td>0.618746</td>\n",
       "      <td>0.730000</td>\n",
       "      <td>0.705053</td>\n",
       "      <td>0.576019</td>\n",
       "      <td>0.621834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Chunk size 3000, overlap 20%, K=3</td>\n",
       "      <td>0.524158</td>\n",
       "      <td>0.791466</td>\n",
       "      <td>0.615346</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>0.739531</td>\n",
       "      <td>0.773110</td>\n",
       "      <td>0.694306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Chunk size 3000, overlap 20%, K=5</td>\n",
       "      <td>0.891667</td>\n",
       "      <td>0.933137</td>\n",
       "      <td>0.578194</td>\n",
       "      <td>0.780000</td>\n",
       "      <td>0.893165</td>\n",
       "      <td>0.440939</td>\n",
       "      <td>0.752850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Chunk size 3000, overlap 20%, K=6</td>\n",
       "      <td>0.930060</td>\n",
       "      <td>0.933761</td>\n",
       "      <td>0.594889</td>\n",
       "      <td>0.737576</td>\n",
       "      <td>0.897546</td>\n",
       "      <td>0.498981</td>\n",
       "      <td>0.765469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Chunk size 3000, overlap 20%, K=7</td>\n",
       "      <td>0.911223</td>\n",
       "      <td>0.825997</td>\n",
       "      <td>0.635716</td>\n",
       "      <td>0.884008</td>\n",
       "      <td>0.913225</td>\n",
       "      <td>0.521667</td>\n",
       "      <td>0.781973</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               System  Faithfulness  Answer Relevancy  \\\n",
       "0                             GPT-3.5      1.000000          0.379673   \n",
       "1                               GPT-4      1.000000          0.695899   \n",
       "2                               Naive      0.944444          0.831993   \n",
       "3                           Recursive      0.944444          0.837124   \n",
       "4               Chunk 500, overlap 0%      0.532729          0.803469   \n",
       "5               Chunk 500, overlap 5%      0.920000          0.829388   \n",
       "6              Chunk 500, overlap 10%      0.531527          0.775393   \n",
       "7              Chunk 500, overlap 15%      0.800333          0.951028   \n",
       "8              Chunk 500, overlap 20%      0.816002          0.950323   \n",
       "9              Chunk 1000, overlap 0%      0.790545          0.932472   \n",
       "10             Chunk 1000, overlap 5%      0.757331          0.951969   \n",
       "11            Chunk 1000, overlap 10%      0.854167          0.746491   \n",
       "12            Chunk 1000, overlap 15%      0.764960          0.949421   \n",
       "13            Chunk 1000, overlap 20%      0.786958          0.951187   \n",
       "14             Chunk 2000, overlap 0%      0.753625          0.949662   \n",
       "15             Chunk 2000, overlap 5%      0.400117          0.928571   \n",
       "16            Chunk 2000, overlap 10%      0.769649          0.940600   \n",
       "17            Chunk 2000, overlap 15%      0.784939          0.955299   \n",
       "18            Chunk 2000, overlap 20%      0.762311          0.944377   \n",
       "19             Chunk 3000, overlap 0%      0.779172          0.949059   \n",
       "20             Chunk 3000, overlap 5%      0.767551          0.942964   \n",
       "21            Chunk 3000, overlap 10%      0.765109          0.949812   \n",
       "22            Chunk 3000, overlap 15%      0.531527          0.796436   \n",
       "23            Chunk 3000, overlap 20%      0.509508          0.751365   \n",
       "24  Chunk size 3000, overlap 20%, K=2      0.489705          0.611479   \n",
       "25  Chunk size 3000, overlap 20%, K=3      0.524158          0.791466   \n",
       "26  Chunk size 3000, overlap 20%, K=5      0.891667          0.933137   \n",
       "27  Chunk size 3000, overlap 20%, K=6      0.930060          0.933761   \n",
       "28  Chunk size 3000, overlap 20%, K=7      0.911223          0.825997   \n",
       "\n",
       "    Context Precision  Context Recall  Answer Similarity  Answer Correctness  \\\n",
       "0                 NaN             NaN           0.841376            0.410613   \n",
       "1                 NaN             NaN           0.900098            0.492424   \n",
       "2            0.597222        0.820833           0.878165            0.413080   \n",
       "3            0.597222        0.771429           0.878165            0.402142   \n",
       "4            0.907841        0.752864           0.731083            0.795908   \n",
       "5            0.597222        0.808333           0.882359            0.441887   \n",
       "6            0.907932        0.753544           0.731083            0.802336   \n",
       "7            0.616525        0.783333           0.890919            0.541697   \n",
       "8            0.616575        0.750000           0.890744            0.532502   \n",
       "9            0.654176        0.783333           0.890744            0.533308   \n",
       "10           0.582974        0.783333           0.878419            0.542546   \n",
       "11           0.597222        0.775000           0.880496            0.433163   \n",
       "12           0.654338        0.750000           0.878244            0.534169   \n",
       "13           0.619133        0.783333           0.890919            0.544212   \n",
       "14           0.616641        0.783333           0.864847            0.542546   \n",
       "15           0.829433        0.633333           0.801053            0.873055   \n",
       "16           0.655261        0.783333           0.878579            0.544252   \n",
       "17           0.652623        0.750000           0.889133            0.543388   \n",
       "18           0.582052        0.750000           0.874847            0.542521   \n",
       "19           0.652841        0.750000           0.878084            0.532462   \n",
       "20           0.617704        0.783333           0.868084            0.532438   \n",
       "21           0.619150        0.783333           0.878084            0.534129   \n",
       "22           0.912243        0.752622           0.764752            0.815992   \n",
       "23           0.939013        0.654342           0.742385            0.858955   \n",
       "24           0.618746        0.730000           0.705053            0.576019   \n",
       "25           0.615346        0.722222           0.739531            0.773110   \n",
       "26           0.578194        0.780000           0.893165            0.440939   \n",
       "27           0.594889        0.737576           0.897546            0.498981   \n",
       "28           0.635716        0.884008           0.913225            0.521667   \n",
       "\n",
       "     Average  \n",
       "0   0.663610  \n",
       "1   0.742388  \n",
       "2   0.747623  \n",
       "3   0.738421  \n",
       "4   0.753982  \n",
       "5   0.746532  \n",
       "6   0.750303  \n",
       "7   0.763972  \n",
       "8   0.759358  \n",
       "9   0.764096  \n",
       "10  0.749429  \n",
       "11  0.714423  \n",
       "12  0.755189  \n",
       "13  0.762624  \n",
       "14  0.751776  \n",
       "15  0.744261  \n",
       "16  0.761946  \n",
       "17  0.762564  \n",
       "18  0.742685  \n",
       "19  0.756936  \n",
       "20  0.752012  \n",
       "21  0.754936  \n",
       "22  0.762262  \n",
       "23  0.742595  \n",
       "24  0.621834  \n",
       "25  0.694306  \n",
       "26  0.752850  \n",
       "27  0.765469  \n",
       "28  0.781973  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### look for different retrievers\n",
    "\n",
    "6 chunks was the best score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### parent document retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "passing column names as 'ground_truths' is deprecated and will be removed in the next version, please use 'ground_truth' instead. Note that `ground_truth` should be of type string and not Sequence[string] like `ground_truths`\n",
      "Evaluating: 100%|██████████| 60/60 [00:08<00:00,  7.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average score is: 0.7190440237375887\n",
      "                      System  Faithfulness  Answer Relevancy  \\\n",
      "0  Parent Retriever 1000-200      0.733333           0.75333   \n",
      "\n",
      "   Context Precision  Context Recall  Answer Similarity  Answer Correctness  \\\n",
      "0           0.741667        0.726355           0.891473            0.468106   \n",
      "\n",
      "    Average  \n",
      "0  0.719044  \n"
     ]
    }
   ],
   "source": [
    "from langchain.retrievers import ParentDocumentRetriever\n",
    "from langchain.storage import InMemoryStore\n",
    "\n",
    "parent_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(chunk_size=1000, chunk_overlap = 200)\n",
    "child_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(chunk_size=200, chunk_overlap = 0)\n",
    "\n",
    "vectorstore = Chroma(collection_name=\"split_parents\",persist_directory = \"../ballad/vectordb-edit/parent-summary\", embedding_function=embeddings_client)\n",
    "store = InMemoryStore()\n",
    "parent_document_retriever = ParentDocumentRetriever(\n",
    "    vectorstore=vectorstore,\n",
    "    docstore=store,\n",
    "    child_splitter=child_splitter,\n",
    "    parent_splitter=parent_splitter,\n",
    ")\n",
    "parent_document_retriever.add_documents(documents)\n",
    "result_parent, results_df = run_and_evaluate(f\"Parent Retriever 1000-200\", parent_document_retriever, prompt, llm, results_df)\n",
    "print(result_parent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "passing column names as 'ground_truths' is deprecated and will be removed in the next version, please use 'ground_truth' instead. Note that `ground_truth` should be of type string and not Sequence[string] like `ground_truths`\n",
      "Evaluating:   0%|          | 0/60 [00:00<?, ?it/s]Task exception was never retrieved\n",
      "future: <Task finished name='Task-2077' coro=<AsyncClient.aclose() done, defined at c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\httpx\\_client.py:2011> exception=RuntimeError('Event loop is closed')>\n",
      "RuntimeError: Event loop is closed\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-2078' coro=<AsyncClient.aclose() done, defined at c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\httpx\\_client.py:2011> exception=RuntimeError('Event loop is closed')>\n",
      "RuntimeError: Event loop is closed\n",
      "Runner in Executor raised an exception\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400, 'innererror': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_result': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': True, 'severity': 'medium'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}}}\n",
      "Evaluating: 100%|██████████| 60/60 [00:13<00:00,  4.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average score is: 0.7334064668789292\n",
      "                     System  Faithfulness  Answer Relevancy  \\\n",
      "0  Parent Retriever 500-100      0.820649          0.835459   \n",
      "\n",
      "   Context Precision  Context Recall  Answer Similarity  Answer Correctness  \\\n",
      "0           0.570873        0.727381           0.905459            0.540618   \n",
      "\n",
      "    Average  \n",
      "0  0.733406  \n"
     ]
    }
   ],
   "source": [
    "parent_splitter_small = RecursiveCharacterTextSplitter.from_tiktoken_encoder(chunk_size=500, chunk_overlap = 50)\n",
    "child_splitter_small = RecursiveCharacterTextSplitter.from_tiktoken_encoder(chunk_size=100, chunk_overlap = 0)\n",
    "\n",
    "vectorstore = Chroma(collection_name=\"split_parents_small\",persist_directory = \"../ballad/vectordb-edit/parent_small-summary\", embedding_function=embeddings_client)\n",
    "store = InMemoryStore()\n",
    "parent_document_retriever_small = ParentDocumentRetriever(\n",
    "    vectorstore=vectorstore,\n",
    "    docstore=store,\n",
    "    child_splitter=child_splitter_small,\n",
    "    parent_splitter=parent_splitter_small,\n",
    ")\n",
    "parent_document_retriever_small.add_documents(documents)\n",
    "result_parent_small, results_df = run_and_evaluate(f\"Parent Retriever 500-100\", parent_document_retriever_small, prompt, llm, results_df)\n",
    "print(result_parent_small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "passing column names as 'ground_truths' is deprecated and will be removed in the next version, please use 'ground_truth' instead. Note that `ground_truth` should be of type string and not Sequence[string] like `ground_truths`\n",
      "Evaluating:   0%|          | 0/60 [00:00<?, ?it/s]Runner in Executor raised an exception\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400, 'innererror': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_result': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': True, 'severity': 'medium'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}}}\n",
      "Evaluating: 100%|██████████| 60/60 [00:09<00:00,  6.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average score is: 0.7352336975497553\n",
      "                      System  Faithfulness  Answer Relevancy  \\\n",
      "0  Parent Retriever 1500-200      0.817811           0.83528   \n",
      "\n",
      "   Context Precision  Context Recall  Answer Similarity  Answer Correctness  \\\n",
      "0            0.57652        0.735714           0.905459            0.540618   \n",
      "\n",
      "    Average  \n",
      "0  0.735234  \n"
     ]
    }
   ],
   "source": [
    "parent_splitter_large = RecursiveCharacterTextSplitter.from_tiktoken_encoder(chunk_size=1500, chunk_overlap = 150)\n",
    "child_splitter_large = RecursiveCharacterTextSplitter.from_tiktoken_encoder(chunk_size=200, chunk_overlap = 0)\n",
    "\n",
    "vectorstore = Chroma(collection_name=\"split_parents_large\",persist_directory = \"../ballad/vectordb-edit/parent_large-summary\", embedding_function=embeddings_client)\n",
    "store = InMemoryStore()\n",
    "parent_document_retriever_large = ParentDocumentRetriever(\n",
    "    vectorstore=vectorstore,\n",
    "    docstore=store,\n",
    "    child_splitter=child_splitter_large,\n",
    "    parent_splitter=parent_splitter_large,\n",
    ")\n",
    "parent_document_retriever_large.add_documents(documents)\n",
    "result_parent_large , results_df = run_and_evaluate(f\"Parent Retriever 1500-200\", parent_document_retriever_small, prompt, llm, results_df)\n",
    "print(result_parent_large)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Highest average value: 0.781972560978867\n"
     ]
    }
   ],
   "source": [
    "highest_average = results_df[\"Average\"].max()\n",
    "print(\"Highest average value:\", highest_average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>System</th>\n",
       "      <th>Faithfulness</th>\n",
       "      <th>Answer Relevancy</th>\n",
       "      <th>Context Precision</th>\n",
       "      <th>Context Recall</th>\n",
       "      <th>Answer Similarity</th>\n",
       "      <th>Answer Correctness</th>\n",
       "      <th>Average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GPT-3.5</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.379673</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.841376</td>\n",
       "      <td>0.410613</td>\n",
       "      <td>0.663610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GPT-4</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.695899</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.900098</td>\n",
       "      <td>0.492424</td>\n",
       "      <td>0.742388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Naive</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.831993</td>\n",
       "      <td>0.597222</td>\n",
       "      <td>0.820833</td>\n",
       "      <td>0.878165</td>\n",
       "      <td>0.413080</td>\n",
       "      <td>0.747623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Recursive</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.837124</td>\n",
       "      <td>0.597222</td>\n",
       "      <td>0.771429</td>\n",
       "      <td>0.878165</td>\n",
       "      <td>0.402142</td>\n",
       "      <td>0.738421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Chunk 500, overlap 0%</td>\n",
       "      <td>0.532729</td>\n",
       "      <td>0.803469</td>\n",
       "      <td>0.907841</td>\n",
       "      <td>0.752864</td>\n",
       "      <td>0.731083</td>\n",
       "      <td>0.795908</td>\n",
       "      <td>0.753982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Chunk 500, overlap 5%</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>0.829388</td>\n",
       "      <td>0.597222</td>\n",
       "      <td>0.808333</td>\n",
       "      <td>0.882359</td>\n",
       "      <td>0.441887</td>\n",
       "      <td>0.746532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Chunk 500, overlap 10%</td>\n",
       "      <td>0.531527</td>\n",
       "      <td>0.775393</td>\n",
       "      <td>0.907932</td>\n",
       "      <td>0.753544</td>\n",
       "      <td>0.731083</td>\n",
       "      <td>0.802336</td>\n",
       "      <td>0.750303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Chunk 500, overlap 15%</td>\n",
       "      <td>0.800333</td>\n",
       "      <td>0.951028</td>\n",
       "      <td>0.616525</td>\n",
       "      <td>0.783333</td>\n",
       "      <td>0.890919</td>\n",
       "      <td>0.541697</td>\n",
       "      <td>0.763972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Chunk 500, overlap 20%</td>\n",
       "      <td>0.816002</td>\n",
       "      <td>0.950323</td>\n",
       "      <td>0.616575</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.890744</td>\n",
       "      <td>0.532502</td>\n",
       "      <td>0.759358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Chunk 1000, overlap 0%</td>\n",
       "      <td>0.790545</td>\n",
       "      <td>0.932472</td>\n",
       "      <td>0.654176</td>\n",
       "      <td>0.783333</td>\n",
       "      <td>0.890744</td>\n",
       "      <td>0.533308</td>\n",
       "      <td>0.764096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Chunk 1000, overlap 5%</td>\n",
       "      <td>0.757331</td>\n",
       "      <td>0.951969</td>\n",
       "      <td>0.582974</td>\n",
       "      <td>0.783333</td>\n",
       "      <td>0.878419</td>\n",
       "      <td>0.542546</td>\n",
       "      <td>0.749429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Chunk 1000, overlap 10%</td>\n",
       "      <td>0.854167</td>\n",
       "      <td>0.746491</td>\n",
       "      <td>0.597222</td>\n",
       "      <td>0.775000</td>\n",
       "      <td>0.880496</td>\n",
       "      <td>0.433163</td>\n",
       "      <td>0.714423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Chunk 1000, overlap 15%</td>\n",
       "      <td>0.764960</td>\n",
       "      <td>0.949421</td>\n",
       "      <td>0.654338</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.878244</td>\n",
       "      <td>0.534169</td>\n",
       "      <td>0.755189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Chunk 1000, overlap 20%</td>\n",
       "      <td>0.786958</td>\n",
       "      <td>0.951187</td>\n",
       "      <td>0.619133</td>\n",
       "      <td>0.783333</td>\n",
       "      <td>0.890919</td>\n",
       "      <td>0.544212</td>\n",
       "      <td>0.762624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Chunk 2000, overlap 0%</td>\n",
       "      <td>0.753625</td>\n",
       "      <td>0.949662</td>\n",
       "      <td>0.616641</td>\n",
       "      <td>0.783333</td>\n",
       "      <td>0.864847</td>\n",
       "      <td>0.542546</td>\n",
       "      <td>0.751776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Chunk 2000, overlap 5%</td>\n",
       "      <td>0.400117</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.829433</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>0.801053</td>\n",
       "      <td>0.873055</td>\n",
       "      <td>0.744261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Chunk 2000, overlap 10%</td>\n",
       "      <td>0.769649</td>\n",
       "      <td>0.940600</td>\n",
       "      <td>0.655261</td>\n",
       "      <td>0.783333</td>\n",
       "      <td>0.878579</td>\n",
       "      <td>0.544252</td>\n",
       "      <td>0.761946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Chunk 2000, overlap 15%</td>\n",
       "      <td>0.784939</td>\n",
       "      <td>0.955299</td>\n",
       "      <td>0.652623</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.889133</td>\n",
       "      <td>0.543388</td>\n",
       "      <td>0.762564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Chunk 2000, overlap 20%</td>\n",
       "      <td>0.762311</td>\n",
       "      <td>0.944377</td>\n",
       "      <td>0.582052</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.874847</td>\n",
       "      <td>0.542521</td>\n",
       "      <td>0.742685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Chunk 3000, overlap 0%</td>\n",
       "      <td>0.779172</td>\n",
       "      <td>0.949059</td>\n",
       "      <td>0.652841</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.878084</td>\n",
       "      <td>0.532462</td>\n",
       "      <td>0.756936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Chunk 3000, overlap 5%</td>\n",
       "      <td>0.767551</td>\n",
       "      <td>0.942964</td>\n",
       "      <td>0.617704</td>\n",
       "      <td>0.783333</td>\n",
       "      <td>0.868084</td>\n",
       "      <td>0.532438</td>\n",
       "      <td>0.752012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Chunk 3000, overlap 10%</td>\n",
       "      <td>0.765109</td>\n",
       "      <td>0.949812</td>\n",
       "      <td>0.619150</td>\n",
       "      <td>0.783333</td>\n",
       "      <td>0.878084</td>\n",
       "      <td>0.534129</td>\n",
       "      <td>0.754936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Chunk 3000, overlap 15%</td>\n",
       "      <td>0.531527</td>\n",
       "      <td>0.796436</td>\n",
       "      <td>0.912243</td>\n",
       "      <td>0.752622</td>\n",
       "      <td>0.764752</td>\n",
       "      <td>0.815992</td>\n",
       "      <td>0.762262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Chunk 3000, overlap 20%</td>\n",
       "      <td>0.509508</td>\n",
       "      <td>0.751365</td>\n",
       "      <td>0.939013</td>\n",
       "      <td>0.654342</td>\n",
       "      <td>0.742385</td>\n",
       "      <td>0.858955</td>\n",
       "      <td>0.742595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Chunk size 3000, overlap 20%, K=2</td>\n",
       "      <td>0.489705</td>\n",
       "      <td>0.611479</td>\n",
       "      <td>0.618746</td>\n",
       "      <td>0.730000</td>\n",
       "      <td>0.705053</td>\n",
       "      <td>0.576019</td>\n",
       "      <td>0.621834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Chunk size 3000, overlap 20%, K=3</td>\n",
       "      <td>0.524158</td>\n",
       "      <td>0.791466</td>\n",
       "      <td>0.615346</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>0.739531</td>\n",
       "      <td>0.773110</td>\n",
       "      <td>0.694306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Chunk size 3000, overlap 20%, K=5</td>\n",
       "      <td>0.891667</td>\n",
       "      <td>0.933137</td>\n",
       "      <td>0.578194</td>\n",
       "      <td>0.780000</td>\n",
       "      <td>0.893165</td>\n",
       "      <td>0.440939</td>\n",
       "      <td>0.752850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Chunk size 3000, overlap 20%, K=6</td>\n",
       "      <td>0.930060</td>\n",
       "      <td>0.933761</td>\n",
       "      <td>0.594889</td>\n",
       "      <td>0.737576</td>\n",
       "      <td>0.897546</td>\n",
       "      <td>0.498981</td>\n",
       "      <td>0.765469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Chunk size 3000, overlap 20%, K=7</td>\n",
       "      <td>0.911223</td>\n",
       "      <td>0.825997</td>\n",
       "      <td>0.635716</td>\n",
       "      <td>0.884008</td>\n",
       "      <td>0.913225</td>\n",
       "      <td>0.521667</td>\n",
       "      <td>0.781973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Parent Retriever 1000-200</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.753330</td>\n",
       "      <td>0.741667</td>\n",
       "      <td>0.726355</td>\n",
       "      <td>0.891473</td>\n",
       "      <td>0.468106</td>\n",
       "      <td>0.719044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Parent Retriever 500-100</td>\n",
       "      <td>0.820649</td>\n",
       "      <td>0.835459</td>\n",
       "      <td>0.570873</td>\n",
       "      <td>0.727381</td>\n",
       "      <td>0.905459</td>\n",
       "      <td>0.540618</td>\n",
       "      <td>0.733406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Parent Retriever 1500-200</td>\n",
       "      <td>0.817811</td>\n",
       "      <td>0.835280</td>\n",
       "      <td>0.576520</td>\n",
       "      <td>0.735714</td>\n",
       "      <td>0.905459</td>\n",
       "      <td>0.540618</td>\n",
       "      <td>0.735234</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               System  Faithfulness  Answer Relevancy  \\\n",
       "0                             GPT-3.5      1.000000          0.379673   \n",
       "1                               GPT-4      1.000000          0.695899   \n",
       "2                               Naive      0.944444          0.831993   \n",
       "3                           Recursive      0.944444          0.837124   \n",
       "4               Chunk 500, overlap 0%      0.532729          0.803469   \n",
       "5               Chunk 500, overlap 5%      0.920000          0.829388   \n",
       "6              Chunk 500, overlap 10%      0.531527          0.775393   \n",
       "7              Chunk 500, overlap 15%      0.800333          0.951028   \n",
       "8              Chunk 500, overlap 20%      0.816002          0.950323   \n",
       "9              Chunk 1000, overlap 0%      0.790545          0.932472   \n",
       "10             Chunk 1000, overlap 5%      0.757331          0.951969   \n",
       "11            Chunk 1000, overlap 10%      0.854167          0.746491   \n",
       "12            Chunk 1000, overlap 15%      0.764960          0.949421   \n",
       "13            Chunk 1000, overlap 20%      0.786958          0.951187   \n",
       "14             Chunk 2000, overlap 0%      0.753625          0.949662   \n",
       "15             Chunk 2000, overlap 5%      0.400117          0.928571   \n",
       "16            Chunk 2000, overlap 10%      0.769649          0.940600   \n",
       "17            Chunk 2000, overlap 15%      0.784939          0.955299   \n",
       "18            Chunk 2000, overlap 20%      0.762311          0.944377   \n",
       "19             Chunk 3000, overlap 0%      0.779172          0.949059   \n",
       "20             Chunk 3000, overlap 5%      0.767551          0.942964   \n",
       "21            Chunk 3000, overlap 10%      0.765109          0.949812   \n",
       "22            Chunk 3000, overlap 15%      0.531527          0.796436   \n",
       "23            Chunk 3000, overlap 20%      0.509508          0.751365   \n",
       "24  Chunk size 3000, overlap 20%, K=2      0.489705          0.611479   \n",
       "25  Chunk size 3000, overlap 20%, K=3      0.524158          0.791466   \n",
       "26  Chunk size 3000, overlap 20%, K=5      0.891667          0.933137   \n",
       "27  Chunk size 3000, overlap 20%, K=6      0.930060          0.933761   \n",
       "28  Chunk size 3000, overlap 20%, K=7      0.911223          0.825997   \n",
       "29          Parent Retriever 1000-200      0.733333          0.753330   \n",
       "30           Parent Retriever 500-100      0.820649          0.835459   \n",
       "31          Parent Retriever 1500-200      0.817811          0.835280   \n",
       "\n",
       "    Context Precision  Context Recall  Answer Similarity  Answer Correctness  \\\n",
       "0                 NaN             NaN           0.841376            0.410613   \n",
       "1                 NaN             NaN           0.900098            0.492424   \n",
       "2            0.597222        0.820833           0.878165            0.413080   \n",
       "3            0.597222        0.771429           0.878165            0.402142   \n",
       "4            0.907841        0.752864           0.731083            0.795908   \n",
       "5            0.597222        0.808333           0.882359            0.441887   \n",
       "6            0.907932        0.753544           0.731083            0.802336   \n",
       "7            0.616525        0.783333           0.890919            0.541697   \n",
       "8            0.616575        0.750000           0.890744            0.532502   \n",
       "9            0.654176        0.783333           0.890744            0.533308   \n",
       "10           0.582974        0.783333           0.878419            0.542546   \n",
       "11           0.597222        0.775000           0.880496            0.433163   \n",
       "12           0.654338        0.750000           0.878244            0.534169   \n",
       "13           0.619133        0.783333           0.890919            0.544212   \n",
       "14           0.616641        0.783333           0.864847            0.542546   \n",
       "15           0.829433        0.633333           0.801053            0.873055   \n",
       "16           0.655261        0.783333           0.878579            0.544252   \n",
       "17           0.652623        0.750000           0.889133            0.543388   \n",
       "18           0.582052        0.750000           0.874847            0.542521   \n",
       "19           0.652841        0.750000           0.878084            0.532462   \n",
       "20           0.617704        0.783333           0.868084            0.532438   \n",
       "21           0.619150        0.783333           0.878084            0.534129   \n",
       "22           0.912243        0.752622           0.764752            0.815992   \n",
       "23           0.939013        0.654342           0.742385            0.858955   \n",
       "24           0.618746        0.730000           0.705053            0.576019   \n",
       "25           0.615346        0.722222           0.739531            0.773110   \n",
       "26           0.578194        0.780000           0.893165            0.440939   \n",
       "27           0.594889        0.737576           0.897546            0.498981   \n",
       "28           0.635716        0.884008           0.913225            0.521667   \n",
       "29           0.741667        0.726355           0.891473            0.468106   \n",
       "30           0.570873        0.727381           0.905459            0.540618   \n",
       "31           0.576520        0.735714           0.905459            0.540618   \n",
       "\n",
       "     Average  \n",
       "0   0.663610  \n",
       "1   0.742388  \n",
       "2   0.747623  \n",
       "3   0.738421  \n",
       "4   0.753982  \n",
       "5   0.746532  \n",
       "6   0.750303  \n",
       "7   0.763972  \n",
       "8   0.759358  \n",
       "9   0.764096  \n",
       "10  0.749429  \n",
       "11  0.714423  \n",
       "12  0.755189  \n",
       "13  0.762624  \n",
       "14  0.751776  \n",
       "15  0.744261  \n",
       "16  0.761946  \n",
       "17  0.762564  \n",
       "18  0.742685  \n",
       "19  0.756936  \n",
       "20  0.752012  \n",
       "21  0.754936  \n",
       "22  0.762262  \n",
       "23  0.742595  \n",
       "24  0.621834  \n",
       "25  0.694306  \n",
       "26  0.752850  \n",
       "27  0.765469  \n",
       "28  0.781973  \n",
       "29  0.719044  \n",
       "30  0.733406  \n",
       "31  0.735234  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Maximum marginal relevance retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "passing column names as 'ground_truths' is deprecated and will be removed in the next version, please use 'ground_truth' instead. Note that `ground_truth` should be of type string and not Sequence[string] like `ground_truths`\n",
      "Evaluating:  87%|████████▋ | 52/60 [00:13<00:04,  1.95it/s]Runner in Executor raised an exception\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400, 'innererror': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_result': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': True, 'severity': 'medium'}, 'violence': {'filtered': False, 'severity': 'safe'}}}}}\n",
      "Evaluating: 100%|██████████| 60/60 [00:21<00:00,  2.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average score is: 0.7462071896171293\n",
      "Marginal relevance\n",
      "  System  Faithfulness  Answer Relevancy  Context Precision  Context Recall  \\\n",
      "0    MMR      0.478823          0.873469           0.826085        0.699968   \n",
      "\n",
      "   Answer Similarity  Answer Correctness   Average  \n",
      "0            0.75447            0.844428  0.746207  \n"
     ]
    }
   ],
   "source": [
    "retriever_mmr = db_k.as_retriever(search_type=\"mmr\",search_kwargs={\"k\": 7})\n",
    "result_mmr, results_df = run_and_evaluate(f\"MMR\", retriever_mmr, prompt, llm, results_df)\n",
    "print(\"Marginal relevance\")\n",
    "print(result_mmr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "replacement_map = {\n",
    "    'Chunk size 3000, overlap 20%, K=2': 'Chunk size 1000, 0%, K=2',\n",
    "    'Chunk size 3000, overlap 20%, K=3': 'Chunk size 1000, 0%, K=3',\n",
    "    'Chunk size 3000, overlap 20%, K=5': 'Chunk size 1000, 0%, K=5',\n",
    "    'Chunk size 3000, overlap 20%, K=6': 'Chunk size 1000, 0%, K=6',\n",
    "    'Chunk size 3000, overlap 20%, K=7': 'Chunk size 1000, 0%, K=7'\n",
    "}\n",
    "results_df['System'] = results_df['System'].replace(replacement_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>System</th>\n",
       "      <th>Faithfulness</th>\n",
       "      <th>Answer Relevancy</th>\n",
       "      <th>Context Precision</th>\n",
       "      <th>Context Recall</th>\n",
       "      <th>Answer Similarity</th>\n",
       "      <th>Answer Correctness</th>\n",
       "      <th>Average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GPT-3.5</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.379673</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.841376</td>\n",
       "      <td>0.410613</td>\n",
       "      <td>0.663610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GPT-4</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.695899</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.900098</td>\n",
       "      <td>0.492424</td>\n",
       "      <td>0.742388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Naive</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.831993</td>\n",
       "      <td>0.597222</td>\n",
       "      <td>0.820833</td>\n",
       "      <td>0.878165</td>\n",
       "      <td>0.413080</td>\n",
       "      <td>0.747623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Recursive</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.837124</td>\n",
       "      <td>0.597222</td>\n",
       "      <td>0.771429</td>\n",
       "      <td>0.878165</td>\n",
       "      <td>0.402142</td>\n",
       "      <td>0.738421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Chunk 500, overlap 0%</td>\n",
       "      <td>0.532729</td>\n",
       "      <td>0.803469</td>\n",
       "      <td>0.907841</td>\n",
       "      <td>0.752864</td>\n",
       "      <td>0.731083</td>\n",
       "      <td>0.795908</td>\n",
       "      <td>0.753982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Chunk 500, overlap 5%</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>0.829388</td>\n",
       "      <td>0.597222</td>\n",
       "      <td>0.808333</td>\n",
       "      <td>0.882359</td>\n",
       "      <td>0.441887</td>\n",
       "      <td>0.746532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Chunk 500, overlap 10%</td>\n",
       "      <td>0.531527</td>\n",
       "      <td>0.775393</td>\n",
       "      <td>0.907932</td>\n",
       "      <td>0.753544</td>\n",
       "      <td>0.731083</td>\n",
       "      <td>0.802336</td>\n",
       "      <td>0.750303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Chunk 500, overlap 15%</td>\n",
       "      <td>0.800333</td>\n",
       "      <td>0.951028</td>\n",
       "      <td>0.616525</td>\n",
       "      <td>0.783333</td>\n",
       "      <td>0.890919</td>\n",
       "      <td>0.541697</td>\n",
       "      <td>0.763972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Chunk 500, overlap 20%</td>\n",
       "      <td>0.816002</td>\n",
       "      <td>0.950323</td>\n",
       "      <td>0.616575</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.890744</td>\n",
       "      <td>0.532502</td>\n",
       "      <td>0.759358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Chunk 1000, overlap 0%</td>\n",
       "      <td>0.790545</td>\n",
       "      <td>0.932472</td>\n",
       "      <td>0.654176</td>\n",
       "      <td>0.783333</td>\n",
       "      <td>0.890744</td>\n",
       "      <td>0.533308</td>\n",
       "      <td>0.764096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Chunk 1000, overlap 5%</td>\n",
       "      <td>0.757331</td>\n",
       "      <td>0.951969</td>\n",
       "      <td>0.582974</td>\n",
       "      <td>0.783333</td>\n",
       "      <td>0.878419</td>\n",
       "      <td>0.542546</td>\n",
       "      <td>0.749429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Chunk 1000, overlap 10%</td>\n",
       "      <td>0.854167</td>\n",
       "      <td>0.746491</td>\n",
       "      <td>0.597222</td>\n",
       "      <td>0.775000</td>\n",
       "      <td>0.880496</td>\n",
       "      <td>0.433163</td>\n",
       "      <td>0.714423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Chunk 1000, overlap 15%</td>\n",
       "      <td>0.764960</td>\n",
       "      <td>0.949421</td>\n",
       "      <td>0.654338</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.878244</td>\n",
       "      <td>0.534169</td>\n",
       "      <td>0.755189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Chunk 1000, overlap 20%</td>\n",
       "      <td>0.786958</td>\n",
       "      <td>0.951187</td>\n",
       "      <td>0.619133</td>\n",
       "      <td>0.783333</td>\n",
       "      <td>0.890919</td>\n",
       "      <td>0.544212</td>\n",
       "      <td>0.762624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Chunk 2000, overlap 0%</td>\n",
       "      <td>0.753625</td>\n",
       "      <td>0.949662</td>\n",
       "      <td>0.616641</td>\n",
       "      <td>0.783333</td>\n",
       "      <td>0.864847</td>\n",
       "      <td>0.542546</td>\n",
       "      <td>0.751776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Chunk 2000, overlap 5%</td>\n",
       "      <td>0.400117</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.829433</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>0.801053</td>\n",
       "      <td>0.873055</td>\n",
       "      <td>0.744261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Chunk 2000, overlap 10%</td>\n",
       "      <td>0.769649</td>\n",
       "      <td>0.940600</td>\n",
       "      <td>0.655261</td>\n",
       "      <td>0.783333</td>\n",
       "      <td>0.878579</td>\n",
       "      <td>0.544252</td>\n",
       "      <td>0.761946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Chunk 2000, overlap 15%</td>\n",
       "      <td>0.784939</td>\n",
       "      <td>0.955299</td>\n",
       "      <td>0.652623</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.889133</td>\n",
       "      <td>0.543388</td>\n",
       "      <td>0.762564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Chunk 2000, overlap 20%</td>\n",
       "      <td>0.762311</td>\n",
       "      <td>0.944377</td>\n",
       "      <td>0.582052</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.874847</td>\n",
       "      <td>0.542521</td>\n",
       "      <td>0.742685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Chunk 3000, overlap 0%</td>\n",
       "      <td>0.779172</td>\n",
       "      <td>0.949059</td>\n",
       "      <td>0.652841</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.878084</td>\n",
       "      <td>0.532462</td>\n",
       "      <td>0.756936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Chunk 3000, overlap 5%</td>\n",
       "      <td>0.767551</td>\n",
       "      <td>0.942964</td>\n",
       "      <td>0.617704</td>\n",
       "      <td>0.783333</td>\n",
       "      <td>0.868084</td>\n",
       "      <td>0.532438</td>\n",
       "      <td>0.752012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Chunk 3000, overlap 10%</td>\n",
       "      <td>0.765109</td>\n",
       "      <td>0.949812</td>\n",
       "      <td>0.619150</td>\n",
       "      <td>0.783333</td>\n",
       "      <td>0.878084</td>\n",
       "      <td>0.534129</td>\n",
       "      <td>0.754936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Chunk 3000, overlap 15%</td>\n",
       "      <td>0.531527</td>\n",
       "      <td>0.796436</td>\n",
       "      <td>0.912243</td>\n",
       "      <td>0.752622</td>\n",
       "      <td>0.764752</td>\n",
       "      <td>0.815992</td>\n",
       "      <td>0.762262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Chunk 3000, overlap 20%</td>\n",
       "      <td>0.509508</td>\n",
       "      <td>0.751365</td>\n",
       "      <td>0.939013</td>\n",
       "      <td>0.654342</td>\n",
       "      <td>0.742385</td>\n",
       "      <td>0.858955</td>\n",
       "      <td>0.742595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Chunk size 1000, 0%, K=2</td>\n",
       "      <td>0.489705</td>\n",
       "      <td>0.611479</td>\n",
       "      <td>0.618746</td>\n",
       "      <td>0.730000</td>\n",
       "      <td>0.705053</td>\n",
       "      <td>0.576019</td>\n",
       "      <td>0.621834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Chunk size 1000, 0%, K=3</td>\n",
       "      <td>0.524158</td>\n",
       "      <td>0.791466</td>\n",
       "      <td>0.615346</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>0.739531</td>\n",
       "      <td>0.773110</td>\n",
       "      <td>0.694306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Chunk size 1000, 0%, K=5</td>\n",
       "      <td>0.891667</td>\n",
       "      <td>0.933137</td>\n",
       "      <td>0.578194</td>\n",
       "      <td>0.780000</td>\n",
       "      <td>0.893165</td>\n",
       "      <td>0.440939</td>\n",
       "      <td>0.752850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Chunk size 1000, 0%, K=6</td>\n",
       "      <td>0.930060</td>\n",
       "      <td>0.933761</td>\n",
       "      <td>0.594889</td>\n",
       "      <td>0.737576</td>\n",
       "      <td>0.897546</td>\n",
       "      <td>0.498981</td>\n",
       "      <td>0.765469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Chunk size 1000, 0%, K=7</td>\n",
       "      <td>0.911223</td>\n",
       "      <td>0.825997</td>\n",
       "      <td>0.635716</td>\n",
       "      <td>0.884008</td>\n",
       "      <td>0.913225</td>\n",
       "      <td>0.521667</td>\n",
       "      <td>0.781973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Parent Retriever 1000-200</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.753330</td>\n",
       "      <td>0.741667</td>\n",
       "      <td>0.726355</td>\n",
       "      <td>0.891473</td>\n",
       "      <td>0.468106</td>\n",
       "      <td>0.719044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Parent Retriever 500-100</td>\n",
       "      <td>0.820649</td>\n",
       "      <td>0.835459</td>\n",
       "      <td>0.570873</td>\n",
       "      <td>0.727381</td>\n",
       "      <td>0.905459</td>\n",
       "      <td>0.540618</td>\n",
       "      <td>0.733406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Parent Retriever 1500-200</td>\n",
       "      <td>0.817811</td>\n",
       "      <td>0.835280</td>\n",
       "      <td>0.576520</td>\n",
       "      <td>0.735714</td>\n",
       "      <td>0.905459</td>\n",
       "      <td>0.540618</td>\n",
       "      <td>0.735234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>MMR</td>\n",
       "      <td>0.478823</td>\n",
       "      <td>0.873469</td>\n",
       "      <td>0.826085</td>\n",
       "      <td>0.699968</td>\n",
       "      <td>0.754470</td>\n",
       "      <td>0.844428</td>\n",
       "      <td>0.746207</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       System  Faithfulness  Answer Relevancy  \\\n",
       "0                     GPT-3.5      1.000000          0.379673   \n",
       "1                       GPT-4      1.000000          0.695899   \n",
       "2                       Naive      0.944444          0.831993   \n",
       "3                   Recursive      0.944444          0.837124   \n",
       "4       Chunk 500, overlap 0%      0.532729          0.803469   \n",
       "5       Chunk 500, overlap 5%      0.920000          0.829388   \n",
       "6      Chunk 500, overlap 10%      0.531527          0.775393   \n",
       "7      Chunk 500, overlap 15%      0.800333          0.951028   \n",
       "8      Chunk 500, overlap 20%      0.816002          0.950323   \n",
       "9      Chunk 1000, overlap 0%      0.790545          0.932472   \n",
       "10     Chunk 1000, overlap 5%      0.757331          0.951969   \n",
       "11    Chunk 1000, overlap 10%      0.854167          0.746491   \n",
       "12    Chunk 1000, overlap 15%      0.764960          0.949421   \n",
       "13    Chunk 1000, overlap 20%      0.786958          0.951187   \n",
       "14     Chunk 2000, overlap 0%      0.753625          0.949662   \n",
       "15     Chunk 2000, overlap 5%      0.400117          0.928571   \n",
       "16    Chunk 2000, overlap 10%      0.769649          0.940600   \n",
       "17    Chunk 2000, overlap 15%      0.784939          0.955299   \n",
       "18    Chunk 2000, overlap 20%      0.762311          0.944377   \n",
       "19     Chunk 3000, overlap 0%      0.779172          0.949059   \n",
       "20     Chunk 3000, overlap 5%      0.767551          0.942964   \n",
       "21    Chunk 3000, overlap 10%      0.765109          0.949812   \n",
       "22    Chunk 3000, overlap 15%      0.531527          0.796436   \n",
       "23    Chunk 3000, overlap 20%      0.509508          0.751365   \n",
       "24   Chunk size 1000, 0%, K=2      0.489705          0.611479   \n",
       "25   Chunk size 1000, 0%, K=3      0.524158          0.791466   \n",
       "26   Chunk size 1000, 0%, K=5      0.891667          0.933137   \n",
       "27   Chunk size 1000, 0%, K=6      0.930060          0.933761   \n",
       "28   Chunk size 1000, 0%, K=7      0.911223          0.825997   \n",
       "29  Parent Retriever 1000-200      0.733333          0.753330   \n",
       "30   Parent Retriever 500-100      0.820649          0.835459   \n",
       "31  Parent Retriever 1500-200      0.817811          0.835280   \n",
       "32                        MMR      0.478823          0.873469   \n",
       "\n",
       "    Context Precision  Context Recall  Answer Similarity  Answer Correctness  \\\n",
       "0                 NaN             NaN           0.841376            0.410613   \n",
       "1                 NaN             NaN           0.900098            0.492424   \n",
       "2            0.597222        0.820833           0.878165            0.413080   \n",
       "3            0.597222        0.771429           0.878165            0.402142   \n",
       "4            0.907841        0.752864           0.731083            0.795908   \n",
       "5            0.597222        0.808333           0.882359            0.441887   \n",
       "6            0.907932        0.753544           0.731083            0.802336   \n",
       "7            0.616525        0.783333           0.890919            0.541697   \n",
       "8            0.616575        0.750000           0.890744            0.532502   \n",
       "9            0.654176        0.783333           0.890744            0.533308   \n",
       "10           0.582974        0.783333           0.878419            0.542546   \n",
       "11           0.597222        0.775000           0.880496            0.433163   \n",
       "12           0.654338        0.750000           0.878244            0.534169   \n",
       "13           0.619133        0.783333           0.890919            0.544212   \n",
       "14           0.616641        0.783333           0.864847            0.542546   \n",
       "15           0.829433        0.633333           0.801053            0.873055   \n",
       "16           0.655261        0.783333           0.878579            0.544252   \n",
       "17           0.652623        0.750000           0.889133            0.543388   \n",
       "18           0.582052        0.750000           0.874847            0.542521   \n",
       "19           0.652841        0.750000           0.878084            0.532462   \n",
       "20           0.617704        0.783333           0.868084            0.532438   \n",
       "21           0.619150        0.783333           0.878084            0.534129   \n",
       "22           0.912243        0.752622           0.764752            0.815992   \n",
       "23           0.939013        0.654342           0.742385            0.858955   \n",
       "24           0.618746        0.730000           0.705053            0.576019   \n",
       "25           0.615346        0.722222           0.739531            0.773110   \n",
       "26           0.578194        0.780000           0.893165            0.440939   \n",
       "27           0.594889        0.737576           0.897546            0.498981   \n",
       "28           0.635716        0.884008           0.913225            0.521667   \n",
       "29           0.741667        0.726355           0.891473            0.468106   \n",
       "30           0.570873        0.727381           0.905459            0.540618   \n",
       "31           0.576520        0.735714           0.905459            0.540618   \n",
       "32           0.826085        0.699968           0.754470            0.844428   \n",
       "\n",
       "     Average  \n",
       "0   0.663610  \n",
       "1   0.742388  \n",
       "2   0.747623  \n",
       "3   0.738421  \n",
       "4   0.753982  \n",
       "5   0.746532  \n",
       "6   0.750303  \n",
       "7   0.763972  \n",
       "8   0.759358  \n",
       "9   0.764096  \n",
       "10  0.749429  \n",
       "11  0.714423  \n",
       "12  0.755189  \n",
       "13  0.762624  \n",
       "14  0.751776  \n",
       "15  0.744261  \n",
       "16  0.761946  \n",
       "17  0.762564  \n",
       "18  0.742685  \n",
       "19  0.756936  \n",
       "20  0.752012  \n",
       "21  0.754936  \n",
       "22  0.762262  \n",
       "23  0.742595  \n",
       "24  0.621834  \n",
       "25  0.694306  \n",
       "26  0.752850  \n",
       "27  0.765469  \n",
       "28  0.781973  \n",
       "29  0.719044  \n",
       "30  0.733406  \n",
       "31  0.735234  \n",
       "32  0.746207  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BM25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(chunk_size = 1000, chunk_overlap = 0)\n",
    "chunks_1000 = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "passing column names as 'ground_truths' is deprecated and will be removed in the next version, please use 'ground_truth' instead. Note that `ground_truth` should be of type string and not Sequence[string] like `ground_truths`\n",
      "Evaluating:   0%|          | 0/60 [00:00<?, ?it/s]Runner in Executor raised an exception\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400, 'innererror': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_result': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': True, 'severity': 'medium'}}}}}\n",
      "Evaluating: 100%|██████████| 60/60 [00:10<00:00,  5.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average score is: 0.5880465269428691\n",
      "BM25\n",
      "  System  Faithfulness  Answer Relevancy  Context Precision  Context Recall  \\\n",
      "0   BM25       0.47394          0.406398           0.661178        0.505556   \n",
      "\n",
      "   Answer Similarity  Answer Correctness   Average  \n",
      "0           0.722256            0.758951  0.588047  \n"
     ]
    }
   ],
   "source": [
    "from langchain.retrievers import BM25Retriever\n",
    "retriever_bm25 = BM25Retriever.from_documents(chunks_1000, search_kwargs={\"k\": 7})\n",
    "result_bm25, results_df = run_and_evaluate(f\"BM25\", retriever_bm25, prompt, llm, results_df)\n",
    "print(\"BM25\")\n",
    "print(result_bm25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>System</th>\n",
       "      <th>Faithfulness</th>\n",
       "      <th>Answer Relevancy</th>\n",
       "      <th>Context Precision</th>\n",
       "      <th>Context Recall</th>\n",
       "      <th>Answer Similarity</th>\n",
       "      <th>Answer Correctness</th>\n",
       "      <th>Average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GPT-3.5</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.379673</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.841376</td>\n",
       "      <td>0.410613</td>\n",
       "      <td>0.663610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GPT-4</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.695899</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.900098</td>\n",
       "      <td>0.492424</td>\n",
       "      <td>0.742388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Naive</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.831993</td>\n",
       "      <td>0.597222</td>\n",
       "      <td>0.820833</td>\n",
       "      <td>0.878165</td>\n",
       "      <td>0.413080</td>\n",
       "      <td>0.747623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Recursive</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.837124</td>\n",
       "      <td>0.597222</td>\n",
       "      <td>0.771429</td>\n",
       "      <td>0.878165</td>\n",
       "      <td>0.402142</td>\n",
       "      <td>0.738421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Chunk 500, overlap 0%</td>\n",
       "      <td>0.532729</td>\n",
       "      <td>0.803469</td>\n",
       "      <td>0.907841</td>\n",
       "      <td>0.752864</td>\n",
       "      <td>0.731083</td>\n",
       "      <td>0.795908</td>\n",
       "      <td>0.753982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Chunk 500, overlap 5%</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>0.829388</td>\n",
       "      <td>0.597222</td>\n",
       "      <td>0.808333</td>\n",
       "      <td>0.882359</td>\n",
       "      <td>0.441887</td>\n",
       "      <td>0.746532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Chunk 500, overlap 10%</td>\n",
       "      <td>0.531527</td>\n",
       "      <td>0.775393</td>\n",
       "      <td>0.907932</td>\n",
       "      <td>0.753544</td>\n",
       "      <td>0.731083</td>\n",
       "      <td>0.802336</td>\n",
       "      <td>0.750303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Chunk 500, overlap 15%</td>\n",
       "      <td>0.800333</td>\n",
       "      <td>0.951028</td>\n",
       "      <td>0.616525</td>\n",
       "      <td>0.783333</td>\n",
       "      <td>0.890919</td>\n",
       "      <td>0.541697</td>\n",
       "      <td>0.763972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Chunk 500, overlap 20%</td>\n",
       "      <td>0.816002</td>\n",
       "      <td>0.950323</td>\n",
       "      <td>0.616575</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.890744</td>\n",
       "      <td>0.532502</td>\n",
       "      <td>0.759358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Chunk 1000, overlap 0%</td>\n",
       "      <td>0.790545</td>\n",
       "      <td>0.932472</td>\n",
       "      <td>0.654176</td>\n",
       "      <td>0.783333</td>\n",
       "      <td>0.890744</td>\n",
       "      <td>0.533308</td>\n",
       "      <td>0.764096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Chunk 1000, overlap 5%</td>\n",
       "      <td>0.757331</td>\n",
       "      <td>0.951969</td>\n",
       "      <td>0.582974</td>\n",
       "      <td>0.783333</td>\n",
       "      <td>0.878419</td>\n",
       "      <td>0.542546</td>\n",
       "      <td>0.749429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Chunk 1000, overlap 10%</td>\n",
       "      <td>0.854167</td>\n",
       "      <td>0.746491</td>\n",
       "      <td>0.597222</td>\n",
       "      <td>0.775000</td>\n",
       "      <td>0.880496</td>\n",
       "      <td>0.433163</td>\n",
       "      <td>0.714423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Chunk 1000, overlap 15%</td>\n",
       "      <td>0.764960</td>\n",
       "      <td>0.949421</td>\n",
       "      <td>0.654338</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.878244</td>\n",
       "      <td>0.534169</td>\n",
       "      <td>0.755189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Chunk 1000, overlap 20%</td>\n",
       "      <td>0.786958</td>\n",
       "      <td>0.951187</td>\n",
       "      <td>0.619133</td>\n",
       "      <td>0.783333</td>\n",
       "      <td>0.890919</td>\n",
       "      <td>0.544212</td>\n",
       "      <td>0.762624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Chunk 2000, overlap 0%</td>\n",
       "      <td>0.753625</td>\n",
       "      <td>0.949662</td>\n",
       "      <td>0.616641</td>\n",
       "      <td>0.783333</td>\n",
       "      <td>0.864847</td>\n",
       "      <td>0.542546</td>\n",
       "      <td>0.751776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Chunk 2000, overlap 5%</td>\n",
       "      <td>0.400117</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.829433</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>0.801053</td>\n",
       "      <td>0.873055</td>\n",
       "      <td>0.744261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Chunk 2000, overlap 10%</td>\n",
       "      <td>0.769649</td>\n",
       "      <td>0.940600</td>\n",
       "      <td>0.655261</td>\n",
       "      <td>0.783333</td>\n",
       "      <td>0.878579</td>\n",
       "      <td>0.544252</td>\n",
       "      <td>0.761946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Chunk 2000, overlap 15%</td>\n",
       "      <td>0.784939</td>\n",
       "      <td>0.955299</td>\n",
       "      <td>0.652623</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.889133</td>\n",
       "      <td>0.543388</td>\n",
       "      <td>0.762564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Chunk 2000, overlap 20%</td>\n",
       "      <td>0.762311</td>\n",
       "      <td>0.944377</td>\n",
       "      <td>0.582052</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.874847</td>\n",
       "      <td>0.542521</td>\n",
       "      <td>0.742685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Chunk 3000, overlap 0%</td>\n",
       "      <td>0.779172</td>\n",
       "      <td>0.949059</td>\n",
       "      <td>0.652841</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.878084</td>\n",
       "      <td>0.532462</td>\n",
       "      <td>0.756936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Chunk 3000, overlap 5%</td>\n",
       "      <td>0.767551</td>\n",
       "      <td>0.942964</td>\n",
       "      <td>0.617704</td>\n",
       "      <td>0.783333</td>\n",
       "      <td>0.868084</td>\n",
       "      <td>0.532438</td>\n",
       "      <td>0.752012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Chunk 3000, overlap 10%</td>\n",
       "      <td>0.765109</td>\n",
       "      <td>0.949812</td>\n",
       "      <td>0.619150</td>\n",
       "      <td>0.783333</td>\n",
       "      <td>0.878084</td>\n",
       "      <td>0.534129</td>\n",
       "      <td>0.754936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Chunk 3000, overlap 15%</td>\n",
       "      <td>0.531527</td>\n",
       "      <td>0.796436</td>\n",
       "      <td>0.912243</td>\n",
       "      <td>0.752622</td>\n",
       "      <td>0.764752</td>\n",
       "      <td>0.815992</td>\n",
       "      <td>0.762262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Chunk 3000, overlap 20%</td>\n",
       "      <td>0.509508</td>\n",
       "      <td>0.751365</td>\n",
       "      <td>0.939013</td>\n",
       "      <td>0.654342</td>\n",
       "      <td>0.742385</td>\n",
       "      <td>0.858955</td>\n",
       "      <td>0.742595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Chunk size 1000, 0%, K=2</td>\n",
       "      <td>0.489705</td>\n",
       "      <td>0.611479</td>\n",
       "      <td>0.618746</td>\n",
       "      <td>0.730000</td>\n",
       "      <td>0.705053</td>\n",
       "      <td>0.576019</td>\n",
       "      <td>0.621834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Chunk size 1000, 0%, K=3</td>\n",
       "      <td>0.524158</td>\n",
       "      <td>0.791466</td>\n",
       "      <td>0.615346</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>0.739531</td>\n",
       "      <td>0.773110</td>\n",
       "      <td>0.694306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Chunk size 1000, 0%, K=5</td>\n",
       "      <td>0.891667</td>\n",
       "      <td>0.933137</td>\n",
       "      <td>0.578194</td>\n",
       "      <td>0.780000</td>\n",
       "      <td>0.893165</td>\n",
       "      <td>0.440939</td>\n",
       "      <td>0.752850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Chunk size 1000, 0%, K=6</td>\n",
       "      <td>0.930060</td>\n",
       "      <td>0.933761</td>\n",
       "      <td>0.594889</td>\n",
       "      <td>0.737576</td>\n",
       "      <td>0.897546</td>\n",
       "      <td>0.498981</td>\n",
       "      <td>0.765469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Chunk size 1000, 0%, K=7</td>\n",
       "      <td>0.911223</td>\n",
       "      <td>0.825997</td>\n",
       "      <td>0.635716</td>\n",
       "      <td>0.884008</td>\n",
       "      <td>0.913225</td>\n",
       "      <td>0.521667</td>\n",
       "      <td>0.781973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Parent Retriever 1000-200</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.753330</td>\n",
       "      <td>0.741667</td>\n",
       "      <td>0.726355</td>\n",
       "      <td>0.891473</td>\n",
       "      <td>0.468106</td>\n",
       "      <td>0.719044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Parent Retriever 500-100</td>\n",
       "      <td>0.820649</td>\n",
       "      <td>0.835459</td>\n",
       "      <td>0.570873</td>\n",
       "      <td>0.727381</td>\n",
       "      <td>0.905459</td>\n",
       "      <td>0.540618</td>\n",
       "      <td>0.733406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Parent Retriever 1500-200</td>\n",
       "      <td>0.817811</td>\n",
       "      <td>0.835280</td>\n",
       "      <td>0.576520</td>\n",
       "      <td>0.735714</td>\n",
       "      <td>0.905459</td>\n",
       "      <td>0.540618</td>\n",
       "      <td>0.735234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>MMR</td>\n",
       "      <td>0.478823</td>\n",
       "      <td>0.873469</td>\n",
       "      <td>0.826085</td>\n",
       "      <td>0.699968</td>\n",
       "      <td>0.754470</td>\n",
       "      <td>0.844428</td>\n",
       "      <td>0.746207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>BM25</td>\n",
       "      <td>0.802517</td>\n",
       "      <td>0.492892</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.627119</td>\n",
       "      <td>0.530574</td>\n",
       "      <td>0.647832</td>\n",
       "      <td>0.620989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>BM25</td>\n",
       "      <td>0.473940</td>\n",
       "      <td>0.406398</td>\n",
       "      <td>0.661178</td>\n",
       "      <td>0.505556</td>\n",
       "      <td>0.722256</td>\n",
       "      <td>0.758951</td>\n",
       "      <td>0.588047</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       System  Faithfulness  Answer Relevancy  \\\n",
       "0                     GPT-3.5      1.000000          0.379673   \n",
       "1                       GPT-4      1.000000          0.695899   \n",
       "2                       Naive      0.944444          0.831993   \n",
       "3                   Recursive      0.944444          0.837124   \n",
       "4       Chunk 500, overlap 0%      0.532729          0.803469   \n",
       "5       Chunk 500, overlap 5%      0.920000          0.829388   \n",
       "6      Chunk 500, overlap 10%      0.531527          0.775393   \n",
       "7      Chunk 500, overlap 15%      0.800333          0.951028   \n",
       "8      Chunk 500, overlap 20%      0.816002          0.950323   \n",
       "9      Chunk 1000, overlap 0%      0.790545          0.932472   \n",
       "10     Chunk 1000, overlap 5%      0.757331          0.951969   \n",
       "11    Chunk 1000, overlap 10%      0.854167          0.746491   \n",
       "12    Chunk 1000, overlap 15%      0.764960          0.949421   \n",
       "13    Chunk 1000, overlap 20%      0.786958          0.951187   \n",
       "14     Chunk 2000, overlap 0%      0.753625          0.949662   \n",
       "15     Chunk 2000, overlap 5%      0.400117          0.928571   \n",
       "16    Chunk 2000, overlap 10%      0.769649          0.940600   \n",
       "17    Chunk 2000, overlap 15%      0.784939          0.955299   \n",
       "18    Chunk 2000, overlap 20%      0.762311          0.944377   \n",
       "19     Chunk 3000, overlap 0%      0.779172          0.949059   \n",
       "20     Chunk 3000, overlap 5%      0.767551          0.942964   \n",
       "21    Chunk 3000, overlap 10%      0.765109          0.949812   \n",
       "22    Chunk 3000, overlap 15%      0.531527          0.796436   \n",
       "23    Chunk 3000, overlap 20%      0.509508          0.751365   \n",
       "24   Chunk size 1000, 0%, K=2      0.489705          0.611479   \n",
       "25   Chunk size 1000, 0%, K=3      0.524158          0.791466   \n",
       "26   Chunk size 1000, 0%, K=5      0.891667          0.933137   \n",
       "27   Chunk size 1000, 0%, K=6      0.930060          0.933761   \n",
       "28   Chunk size 1000, 0%, K=7      0.911223          0.825997   \n",
       "29  Parent Retriever 1000-200      0.733333          0.753330   \n",
       "30   Parent Retriever 500-100      0.820649          0.835459   \n",
       "31  Parent Retriever 1500-200      0.817811          0.835280   \n",
       "32                        MMR      0.478823          0.873469   \n",
       "33                       BM25      0.802517          0.492892   \n",
       "34                       BM25      0.473940          0.406398   \n",
       "\n",
       "    Context Precision  Context Recall  Answer Similarity  Answer Correctness  \\\n",
       "0                 NaN             NaN           0.841376            0.410613   \n",
       "1                 NaN             NaN           0.900098            0.492424   \n",
       "2            0.597222        0.820833           0.878165            0.413080   \n",
       "3            0.597222        0.771429           0.878165            0.402142   \n",
       "4            0.907841        0.752864           0.731083            0.795908   \n",
       "5            0.597222        0.808333           0.882359            0.441887   \n",
       "6            0.907932        0.753544           0.731083            0.802336   \n",
       "7            0.616525        0.783333           0.890919            0.541697   \n",
       "8            0.616575        0.750000           0.890744            0.532502   \n",
       "9            0.654176        0.783333           0.890744            0.533308   \n",
       "10           0.582974        0.783333           0.878419            0.542546   \n",
       "11           0.597222        0.775000           0.880496            0.433163   \n",
       "12           0.654338        0.750000           0.878244            0.534169   \n",
       "13           0.619133        0.783333           0.890919            0.544212   \n",
       "14           0.616641        0.783333           0.864847            0.542546   \n",
       "15           0.829433        0.633333           0.801053            0.873055   \n",
       "16           0.655261        0.783333           0.878579            0.544252   \n",
       "17           0.652623        0.750000           0.889133            0.543388   \n",
       "18           0.582052        0.750000           0.874847            0.542521   \n",
       "19           0.652841        0.750000           0.878084            0.532462   \n",
       "20           0.617704        0.783333           0.868084            0.532438   \n",
       "21           0.619150        0.783333           0.878084            0.534129   \n",
       "22           0.912243        0.752622           0.764752            0.815992   \n",
       "23           0.939013        0.654342           0.742385            0.858955   \n",
       "24           0.618746        0.730000           0.705053            0.576019   \n",
       "25           0.615346        0.722222           0.739531            0.773110   \n",
       "26           0.578194        0.780000           0.893165            0.440939   \n",
       "27           0.594889        0.737576           0.897546            0.498981   \n",
       "28           0.635716        0.884008           0.913225            0.521667   \n",
       "29           0.741667        0.726355           0.891473            0.468106   \n",
       "30           0.570873        0.727381           0.905459            0.540618   \n",
       "31           0.576520        0.735714           0.905459            0.540618   \n",
       "32           0.826085        0.699968           0.754470            0.844428   \n",
       "33           0.625000        0.627119           0.530574            0.647832   \n",
       "34           0.661178        0.505556           0.722256            0.758951   \n",
       "\n",
       "     Average  \n",
       "0   0.663610  \n",
       "1   0.742388  \n",
       "2   0.747623  \n",
       "3   0.738421  \n",
       "4   0.753982  \n",
       "5   0.746532  \n",
       "6   0.750303  \n",
       "7   0.763972  \n",
       "8   0.759358  \n",
       "9   0.764096  \n",
       "10  0.749429  \n",
       "11  0.714423  \n",
       "12  0.755189  \n",
       "13  0.762624  \n",
       "14  0.751776  \n",
       "15  0.744261  \n",
       "16  0.761946  \n",
       "17  0.762564  \n",
       "18  0.742685  \n",
       "19  0.756936  \n",
       "20  0.752012  \n",
       "21  0.754936  \n",
       "22  0.762262  \n",
       "23  0.742595  \n",
       "24  0.621834  \n",
       "25  0.694306  \n",
       "26  0.752850  \n",
       "27  0.765469  \n",
       "28  0.781973  \n",
       "29  0.719044  \n",
       "30  0.733406  \n",
       "31  0.735234  \n",
       "32  0.746207  \n",
       "33  0.620989  \n",
       "34  0.588047  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.drop(33,inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Highest average value: 0.781972560978867\n"
     ]
    }
   ],
   "source": [
    "highest_average = results_df[\"Average\"].max()\n",
    "print(\"Highest average value:\", highest_average)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ensambler - Hybrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever_7= db_k.as_retriever(search_kwargs={\"k\": 7})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "passing column names as 'ground_truths' is deprecated and will be removed in the next version, please use 'ground_truth' instead. Note that `ground_truth` should be of type string and not Sequence[string] like `ground_truths`\n",
      "Evaluating:   0%|          | 0/60 [00:00<?, ?it/s]Task exception was never retrieved\n",
      "future: <Task finished name='Task-2391' coro=<AsyncClient.aclose() done, defined at c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\httpx\\_client.py:2011> exception=RuntimeError('Event loop is closed')>\n",
      "RuntimeError: Event loop is closed\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-2392' coro=<AsyncClient.aclose() done, defined at c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\httpx\\_client.py:2011> exception=RuntimeError('Event loop is closed')>\n",
      "RuntimeError: Event loop is closed\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-2393' coro=<AsyncClient.aclose() done, defined at c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\httpx\\_client.py:2011> exception=RuntimeError('Event loop is closed')>\n",
      "RuntimeError: Event loop is closed\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-2394' coro=<AsyncClient.aclose() done, defined at c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\httpx\\_client.py:2011> exception=RuntimeError('Event loop is closed')>\n",
      "RuntimeError: Event loop is closed\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-2395' coro=<AsyncClient.aclose() done, defined at c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\httpx\\_client.py:2011> exception=RuntimeError('Event loop is closed')>\n",
      "RuntimeError: Event loop is closed\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-2396' coro=<AsyncClient.aclose() done, defined at c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\httpx\\_client.py:2011> exception=RuntimeError('Event loop is closed')>\n",
      "RuntimeError: Event loop is closed\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-2397' coro=<AsyncClient.aclose() done, defined at c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\httpx\\_client.py:2011> exception=RuntimeError('Event loop is closed')>\n",
      "RuntimeError: Event loop is closed\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-2398' coro=<AsyncClient.aclose() done, defined at c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\httpx\\_client.py:2011> exception=RuntimeError('Event loop is closed')>\n",
      "RuntimeError: Event loop is closed\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-2399' coro=<AsyncClient.aclose() done, defined at c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\httpx\\_client.py:2011> exception=RuntimeError('Event loop is closed')>\n",
      "RuntimeError: Event loop is closed\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-2400' coro=<AsyncClient.aclose() done, defined at c:\\Users\\sigitalapina\\OneDrive - KPMG\\Desktop\\thesis-rag\\.venv\\Lib\\site-packages\\httpx\\_client.py:2011> exception=RuntimeError('Event loop is closed')>\n",
      "RuntimeError: Event loop is closed\n",
      "Evaluating:  77%|███████▋  | 46/60 [00:06<00:01, 10.96it/s]Runner in Executor raised an exception\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400, 'innererror': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_result': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': True, 'severity': 'medium'}}}}}\n",
      "Evaluating: 100%|██████████| 60/60 [00:14<00:00,  4.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average score is: 0.7161630214461998\n",
      "Ensambler\n",
      "        System  Faithfulness  Answer Relevancy  Context Precision  \\\n",
      "0  Ensambler 1      0.505687          0.842514           0.708968   \n",
      "\n",
      "   Context Recall  Answer Similarity  Answer Correctness   Average  \n",
      "0         0.61043           0.784137            0.845242  0.716163  \n"
     ]
    }
   ],
   "source": [
    "from langchain.retrievers import EnsembleRetriever\n",
    "ensemble_retriever_1 = EnsembleRetriever(retrievers=[retriever_bm25, retriever_7], weights=[0.75, 0.25])\n",
    "result_ensemble1, results_df = run_and_evaluate(f\"Ensambler 1\", ensemble_retriever_1, prompt, llm, results_df)\n",
    "print(\"Ensambler\")\n",
    "print(result_ensemble1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "passing column names as 'ground_truths' is deprecated and will be removed in the next version, please use 'ground_truth' instead. Note that `ground_truth` should be of type string and not Sequence[string] like `ground_truths`\n",
      "Evaluating: 100%|██████████| 60/60 [00:15<00:00,  3.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average score is: 0.7449569324055525\n",
      "Ensambler\n",
      "        System  Faithfulness  Answer Relevancy  Context Precision  \\\n",
      "0  Ensambler 2        0.9125          0.821099           0.517745   \n",
      "\n",
      "   Context Recall  Answer Similarity  Answer Correctness   Average  \n",
      "0        0.785714            0.90548            0.527203  0.744957  \n"
     ]
    }
   ],
   "source": [
    "ensemble_retriever_2 = EnsembleRetriever(retrievers=[retriever_bm25, retriever_7], weights=[0.5, 0.5])\n",
    "result_ensemble2, results_df = run_and_evaluate(f\"Ensambler 2\", ensemble_retriever_2, prompt, llm, results_df)\n",
    "print(\"Ensambler\")\n",
    "print(result_ensemble2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "passing column names as 'ground_truths' is deprecated and will be removed in the next version, please use 'ground_truth' instead. Note that `ground_truth` should be of type string and not Sequence[string] like `ground_truths`\n",
      "Evaluating:   0%|          | 0/60 [00:00<?, ?it/s]Runner in Executor raised an exception\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400, 'innererror': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_result': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'low'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': True, 'severity': 'medium'}}}}}\n",
      "Evaluating:  47%|████▋     | 28/60 [00:04<00:03,  8.44it/s]Runner in Executor raised an exception\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400, 'innererror': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_result': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': True, 'severity': 'medium'}, 'violence': {'filtered': False, 'severity': 'safe'}}}}}\n",
      "Evaluating:  98%|█████████▊| 59/60 [00:14<00:00,  2.71it/s]Runner in Executor raised an exception\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400, 'innererror': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_result': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': True, 'severity': 'medium'}}}}}\n",
      "Evaluating: 100%|██████████| 60/60 [02:52<00:00,  2.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average score is: 0.7648733901009135\n",
      "Ensambler\n",
      "        System  Faithfulness  Answer Relevancy  Context Precision  \\\n",
      "0  Ensambler 3      0.896586          0.909414           0.523145   \n",
      "\n",
      "   Context Recall  Answer Similarity  Answer Correctness   Average  \n",
      "0         0.97619            0.62381            0.660094  0.764873  \n"
     ]
    }
   ],
   "source": [
    "ensemble_retriever_3 = EnsembleRetriever(retrievers=[retriever_bm25, retriever_7], weights=[0.25,0.75])\n",
    "result_ensemble3, results_df = run_and_evaluate(f\"Ensambler 3\", ensemble_retriever_3, prompt, llm, results_df)\n",
    "print(\"Ensambler\")\n",
    "print(result_ensemble3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multi-stage - reranker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"COHERE_API_KEY\"] = getpass.getpass(\"Cohere API Key:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "passing column names as 'ground_truths' is deprecated and will be removed in the next version, please use 'ground_truth' instead. Note that `ground_truth` should be of type string and not Sequence[string] like `ground_truths`\n",
      "Evaluating:  60%|██████    | 36/60 [00:06<00:02,  9.59it/s]Invalid JSON response. Expected dictionary with key 'question'\n",
      "Evaluating: 100%|██████████| 60/60 [00:10<00:00,  5.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reranker\n",
      "{'faithfulness': 0.7556, 'answer_relevancy': 0.6267, 'context_precision': 0.6985, 'context_recall': 0.9000, 'answer_similarity': 0.9001, 'answer_correctness': 0.5243}\n",
      "The average score is: 0.7341855512490597\n"
     ]
    }
   ],
   "source": [
    "retriever_context = retriever_mmr\n",
    "compressor = CohereRerank(top_n=6)\n",
    "compression_retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=compressor, base_retriever=retriever_context\n",
    ")\n",
    "\n",
    "result_compression = run_and_evaluate(compression_retriever, prompt, llm)\n",
    "print(\"Reranker\")\n",
    "print(result_compression)\n",
    "avg_result_compression = dictionary(result_compression)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### creating context by remaking the query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "template_context = \"Generate a search query to fetch the relevant documents using the user's {question}. Craft a query that specifically targets the keywords in the question. In the answer provide only the query.\"\n",
    "prompt_context = ChatPromptTemplate.from_template(template_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Highest average value: 0.781972560978867\n"
     ]
    }
   ],
   "source": [
    "highest_average = results_df[\"Average\"].max()\n",
    "print(\"Highest average value:\", highest_average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "passing column names as 'ground_truths' is deprecated and will be removed in the next version, please use 'ground_truth' instead. Note that `ground_truth` should be of type string and not Sequence[string] like `ground_truths`\n",
      "Evaluating:  25%|██▌       | 15/60 [00:04<00:11,  3.79it/s]Runner in Executor raised an exception\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400, 'innererror': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_result': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': True, 'severity': 'medium'}}}}}\n",
      "Invalid JSON response. Expected dictionary with key 'question'\n",
      "Evaluating:  87%|████████▋ | 52/60 [00:06<00:00,  8.06it/s]Runner in Executor raised an exception\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400, 'innererror': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_result': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': True, 'severity': 'medium'}, 'violence': {'filtered': False, 'severity': 'safe'}}}}}\n",
      "Evaluating:  97%|█████████▋| 58/60 [00:25<00:00,  5.97it/s]Runner in Executor raised an exception\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400, 'innererror': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_result': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': True, 'severity': 'medium'}, 'violence': {'filtered': False, 'severity': 'safe'}}}}}\n",
      "Evaluating: 100%|██████████| 60/60 [01:27<00:00,  1.46s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'faithfulness': 0.7412, 'answer_relevancy': 0.7963, 'context_precision': 0.4538, 'context_recall': 0.9988, 'answer_similarity': 0.6126, 'answer_correctness': 0.7061}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers_final = []\n",
    "contexts_final = []\n",
    "# retriever_context_q = EnsembleRetriever(retrievers=[retriever_bm25, retriever_3], weights=[0.5, 0.5])\n",
    "llm_for_context =(\n",
    "    { \"question\": itemgetter(\"question\")}\n",
    "    | RunnablePassthrough()\n",
    "    | {\"response\": prompt_context | llm}\n",
    ")\n",
    "for query in questions:\n",
    "    response_check = llm_for_context.invoke({\"question\": query})\n",
    "    search_query = response_check[\"response\"].content\n",
    "    retrieval_augmented_qa_chain = (\n",
    "        {\"context\": itemgetter(\"context\"), \"question\": itemgetter(\"question\")}\n",
    "        | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
    "        | {\"response\": prompt | llm, \"context\": itemgetter(\"context\")}\n",
    ")\n",
    "    docs = retriever_7.get_relevant_documents(search_query)\n",
    "    formatted_docs = []\n",
    "    for doc in docs:\n",
    "        resulting_doc = doc.page_content\n",
    "        formatted_docs.append(resulting_doc)\n",
    "    try:  \n",
    "            response = retrieval_augmented_qa_chain.invoke({\"context\": formatted_docs, \"question\": query})\n",
    "            # Access the response content\n",
    "            answers_final.append(response[\"response\"].content)\n",
    "            contexts_final.append(formatted_docs)  \n",
    "    except Exception as e:  \n",
    "            print(f\"Warning: {e}\" + \"on the following question: \" + query)  \n",
    "            answers_final.append(\"No answer\")\n",
    "            contexts_final.append(formatted_docs)\n",
    "\n",
    "\n",
    "result_search_query = evaluation_rag(questions, answers_final, contexts_final, ground_truths)\n",
    "result_search_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average score is: 0.7181310369478822\n"
     ]
    }
   ],
   "source": [
    "average = dictionary(result_search_query)\n",
    "    # Create a dictionary to store the results\n",
    "system_results = {\n",
    "        \"System\": \"Search query\",\n",
    "        \"Faithfulness\": result_search_query[\"faithfulness\"],\n",
    "        \"Answer Relevancy\": result_search_query[\"answer_relevancy\"],\n",
    "        \"Context Precision\": result_search_query[\"context_precision\"],\n",
    "        \"Context Recall\": result_search_query[\"context_recall\"],\n",
    "        \"Answer Similarity\": result_search_query[\"answer_similarity\"],\n",
    "        \"Answer Correctness\": result_search_query[\"answer_correctness\"],\n",
    "        \"Average\": average\n",
    "    }\n",
    "df_result_search_query = pd.DataFrame([system_results])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>System</th>\n",
       "      <th>Faithfulness</th>\n",
       "      <th>Answer Relevancy</th>\n",
       "      <th>Context Precision</th>\n",
       "      <th>Context Recall</th>\n",
       "      <th>Answer Similarity</th>\n",
       "      <th>Answer Correctness</th>\n",
       "      <th>Average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GPT-3.5</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.379673</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.841376</td>\n",
       "      <td>0.410613</td>\n",
       "      <td>0.663610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GPT-4</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.695899</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.900098</td>\n",
       "      <td>0.492424</td>\n",
       "      <td>0.742388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Naive</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.831993</td>\n",
       "      <td>0.597222</td>\n",
       "      <td>0.820833</td>\n",
       "      <td>0.878165</td>\n",
       "      <td>0.413080</td>\n",
       "      <td>0.747623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Recursive</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.837124</td>\n",
       "      <td>0.597222</td>\n",
       "      <td>0.771429</td>\n",
       "      <td>0.878165</td>\n",
       "      <td>0.402142</td>\n",
       "      <td>0.738421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Chunk 500, overlap 0%</td>\n",
       "      <td>0.532729</td>\n",
       "      <td>0.803469</td>\n",
       "      <td>0.907841</td>\n",
       "      <td>0.752864</td>\n",
       "      <td>0.731083</td>\n",
       "      <td>0.795908</td>\n",
       "      <td>0.753982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Chunk 500, overlap 5%</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>0.829388</td>\n",
       "      <td>0.597222</td>\n",
       "      <td>0.808333</td>\n",
       "      <td>0.882359</td>\n",
       "      <td>0.441887</td>\n",
       "      <td>0.746532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Chunk 500, overlap 10%</td>\n",
       "      <td>0.531527</td>\n",
       "      <td>0.775393</td>\n",
       "      <td>0.907932</td>\n",
       "      <td>0.753544</td>\n",
       "      <td>0.731083</td>\n",
       "      <td>0.802336</td>\n",
       "      <td>0.750303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Chunk 500, overlap 15%</td>\n",
       "      <td>0.800333</td>\n",
       "      <td>0.951028</td>\n",
       "      <td>0.616525</td>\n",
       "      <td>0.783333</td>\n",
       "      <td>0.890919</td>\n",
       "      <td>0.541697</td>\n",
       "      <td>0.763972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Chunk 500, overlap 20%</td>\n",
       "      <td>0.816002</td>\n",
       "      <td>0.950323</td>\n",
       "      <td>0.616575</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.890744</td>\n",
       "      <td>0.532502</td>\n",
       "      <td>0.759358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Chunk 1000, overlap 0%</td>\n",
       "      <td>0.790545</td>\n",
       "      <td>0.932472</td>\n",
       "      <td>0.654176</td>\n",
       "      <td>0.783333</td>\n",
       "      <td>0.890744</td>\n",
       "      <td>0.533308</td>\n",
       "      <td>0.764096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Chunk 1000, overlap 5%</td>\n",
       "      <td>0.757331</td>\n",
       "      <td>0.951969</td>\n",
       "      <td>0.582974</td>\n",
       "      <td>0.783333</td>\n",
       "      <td>0.878419</td>\n",
       "      <td>0.542546</td>\n",
       "      <td>0.749429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Chunk 1000, overlap 10%</td>\n",
       "      <td>0.854167</td>\n",
       "      <td>0.746491</td>\n",
       "      <td>0.597222</td>\n",
       "      <td>0.775000</td>\n",
       "      <td>0.880496</td>\n",
       "      <td>0.433163</td>\n",
       "      <td>0.714423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Chunk 1000, overlap 15%</td>\n",
       "      <td>0.764960</td>\n",
       "      <td>0.949421</td>\n",
       "      <td>0.654338</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.878244</td>\n",
       "      <td>0.534169</td>\n",
       "      <td>0.755189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Chunk 1000, overlap 20%</td>\n",
       "      <td>0.786958</td>\n",
       "      <td>0.951187</td>\n",
       "      <td>0.619133</td>\n",
       "      <td>0.783333</td>\n",
       "      <td>0.890919</td>\n",
       "      <td>0.544212</td>\n",
       "      <td>0.762624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Chunk 2000, overlap 0%</td>\n",
       "      <td>0.753625</td>\n",
       "      <td>0.949662</td>\n",
       "      <td>0.616641</td>\n",
       "      <td>0.783333</td>\n",
       "      <td>0.864847</td>\n",
       "      <td>0.542546</td>\n",
       "      <td>0.751776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Chunk 2000, overlap 5%</td>\n",
       "      <td>0.400117</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.829433</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>0.801053</td>\n",
       "      <td>0.873055</td>\n",
       "      <td>0.744261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Chunk 2000, overlap 10%</td>\n",
       "      <td>0.769649</td>\n",
       "      <td>0.940600</td>\n",
       "      <td>0.655261</td>\n",
       "      <td>0.783333</td>\n",
       "      <td>0.878579</td>\n",
       "      <td>0.544252</td>\n",
       "      <td>0.761946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Chunk 2000, overlap 15%</td>\n",
       "      <td>0.784939</td>\n",
       "      <td>0.955299</td>\n",
       "      <td>0.652623</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.889133</td>\n",
       "      <td>0.543388</td>\n",
       "      <td>0.762564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Chunk 2000, overlap 20%</td>\n",
       "      <td>0.762311</td>\n",
       "      <td>0.944377</td>\n",
       "      <td>0.582052</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.874847</td>\n",
       "      <td>0.542521</td>\n",
       "      <td>0.742685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Chunk 3000, overlap 0%</td>\n",
       "      <td>0.779172</td>\n",
       "      <td>0.949059</td>\n",
       "      <td>0.652841</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.878084</td>\n",
       "      <td>0.532462</td>\n",
       "      <td>0.756936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Chunk 3000, overlap 5%</td>\n",
       "      <td>0.767551</td>\n",
       "      <td>0.942964</td>\n",
       "      <td>0.617704</td>\n",
       "      <td>0.783333</td>\n",
       "      <td>0.868084</td>\n",
       "      <td>0.532438</td>\n",
       "      <td>0.752012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Chunk 3000, overlap 10%</td>\n",
       "      <td>0.765109</td>\n",
       "      <td>0.949812</td>\n",
       "      <td>0.619150</td>\n",
       "      <td>0.783333</td>\n",
       "      <td>0.878084</td>\n",
       "      <td>0.534129</td>\n",
       "      <td>0.754936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Chunk 3000, overlap 15%</td>\n",
       "      <td>0.531527</td>\n",
       "      <td>0.796436</td>\n",
       "      <td>0.912243</td>\n",
       "      <td>0.752622</td>\n",
       "      <td>0.764752</td>\n",
       "      <td>0.815992</td>\n",
       "      <td>0.762262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Chunk 3000, overlap 20%</td>\n",
       "      <td>0.509508</td>\n",
       "      <td>0.751365</td>\n",
       "      <td>0.939013</td>\n",
       "      <td>0.654342</td>\n",
       "      <td>0.742385</td>\n",
       "      <td>0.858955</td>\n",
       "      <td>0.742595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Chunk size 1000, 0%, K=2</td>\n",
       "      <td>0.489705</td>\n",
       "      <td>0.611479</td>\n",
       "      <td>0.618746</td>\n",
       "      <td>0.730000</td>\n",
       "      <td>0.705053</td>\n",
       "      <td>0.576019</td>\n",
       "      <td>0.621834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Chunk size 1000, 0%, K=3</td>\n",
       "      <td>0.524158</td>\n",
       "      <td>0.791466</td>\n",
       "      <td>0.615346</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>0.739531</td>\n",
       "      <td>0.773110</td>\n",
       "      <td>0.694306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Chunk size 1000, 0%, K=5</td>\n",
       "      <td>0.891667</td>\n",
       "      <td>0.933137</td>\n",
       "      <td>0.578194</td>\n",
       "      <td>0.780000</td>\n",
       "      <td>0.893165</td>\n",
       "      <td>0.440939</td>\n",
       "      <td>0.752850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Chunk size 1000, 0%, K=6</td>\n",
       "      <td>0.930060</td>\n",
       "      <td>0.933761</td>\n",
       "      <td>0.594889</td>\n",
       "      <td>0.737576</td>\n",
       "      <td>0.897546</td>\n",
       "      <td>0.498981</td>\n",
       "      <td>0.765469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Chunk size 1000, 0%, K=7</td>\n",
       "      <td>0.911223</td>\n",
       "      <td>0.825997</td>\n",
       "      <td>0.635716</td>\n",
       "      <td>0.884008</td>\n",
       "      <td>0.913225</td>\n",
       "      <td>0.521667</td>\n",
       "      <td>0.781973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Parent Retriever 1000-200</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.753330</td>\n",
       "      <td>0.741667</td>\n",
       "      <td>0.726355</td>\n",
       "      <td>0.891473</td>\n",
       "      <td>0.468106</td>\n",
       "      <td>0.719044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Parent Retriever 500-100</td>\n",
       "      <td>0.820649</td>\n",
       "      <td>0.835459</td>\n",
       "      <td>0.570873</td>\n",
       "      <td>0.727381</td>\n",
       "      <td>0.905459</td>\n",
       "      <td>0.540618</td>\n",
       "      <td>0.733406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Parent Retriever 1500-200</td>\n",
       "      <td>0.817811</td>\n",
       "      <td>0.835280</td>\n",
       "      <td>0.576520</td>\n",
       "      <td>0.735714</td>\n",
       "      <td>0.905459</td>\n",
       "      <td>0.540618</td>\n",
       "      <td>0.735234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>MMR</td>\n",
       "      <td>0.478823</td>\n",
       "      <td>0.873469</td>\n",
       "      <td>0.826085</td>\n",
       "      <td>0.699968</td>\n",
       "      <td>0.754470</td>\n",
       "      <td>0.844428</td>\n",
       "      <td>0.746207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>BM25</td>\n",
       "      <td>0.473940</td>\n",
       "      <td>0.406398</td>\n",
       "      <td>0.661178</td>\n",
       "      <td>0.505556</td>\n",
       "      <td>0.722256</td>\n",
       "      <td>0.758951</td>\n",
       "      <td>0.588047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Ensambler 1</td>\n",
       "      <td>0.505687</td>\n",
       "      <td>0.842514</td>\n",
       "      <td>0.708968</td>\n",
       "      <td>0.610430</td>\n",
       "      <td>0.784137</td>\n",
       "      <td>0.845242</td>\n",
       "      <td>0.716163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Ensambler 2</td>\n",
       "      <td>0.912500</td>\n",
       "      <td>0.821099</td>\n",
       "      <td>0.517745</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.905480</td>\n",
       "      <td>0.527203</td>\n",
       "      <td>0.744957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Ensambler 3</td>\n",
       "      <td>0.896586</td>\n",
       "      <td>0.909414</td>\n",
       "      <td>0.523145</td>\n",
       "      <td>0.976190</td>\n",
       "      <td>0.623810</td>\n",
       "      <td>0.660094</td>\n",
       "      <td>0.764873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Search query</td>\n",
       "      <td>0.741233</td>\n",
       "      <td>0.796264</td>\n",
       "      <td>0.453837</td>\n",
       "      <td>0.998773</td>\n",
       "      <td>0.612588</td>\n",
       "      <td>0.706091</td>\n",
       "      <td>0.718131</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       System  Faithfulness  Answer Relevancy  \\\n",
       "0                     GPT-3.5      1.000000          0.379673   \n",
       "1                       GPT-4      1.000000          0.695899   \n",
       "2                       Naive      0.944444          0.831993   \n",
       "3                   Recursive      0.944444          0.837124   \n",
       "4       Chunk 500, overlap 0%      0.532729          0.803469   \n",
       "5       Chunk 500, overlap 5%      0.920000          0.829388   \n",
       "6      Chunk 500, overlap 10%      0.531527          0.775393   \n",
       "7      Chunk 500, overlap 15%      0.800333          0.951028   \n",
       "8      Chunk 500, overlap 20%      0.816002          0.950323   \n",
       "9      Chunk 1000, overlap 0%      0.790545          0.932472   \n",
       "10     Chunk 1000, overlap 5%      0.757331          0.951969   \n",
       "11    Chunk 1000, overlap 10%      0.854167          0.746491   \n",
       "12    Chunk 1000, overlap 15%      0.764960          0.949421   \n",
       "13    Chunk 1000, overlap 20%      0.786958          0.951187   \n",
       "14     Chunk 2000, overlap 0%      0.753625          0.949662   \n",
       "15     Chunk 2000, overlap 5%      0.400117          0.928571   \n",
       "16    Chunk 2000, overlap 10%      0.769649          0.940600   \n",
       "17    Chunk 2000, overlap 15%      0.784939          0.955299   \n",
       "18    Chunk 2000, overlap 20%      0.762311          0.944377   \n",
       "19     Chunk 3000, overlap 0%      0.779172          0.949059   \n",
       "20     Chunk 3000, overlap 5%      0.767551          0.942964   \n",
       "21    Chunk 3000, overlap 10%      0.765109          0.949812   \n",
       "22    Chunk 3000, overlap 15%      0.531527          0.796436   \n",
       "23    Chunk 3000, overlap 20%      0.509508          0.751365   \n",
       "24   Chunk size 1000, 0%, K=2      0.489705          0.611479   \n",
       "25   Chunk size 1000, 0%, K=3      0.524158          0.791466   \n",
       "26   Chunk size 1000, 0%, K=5      0.891667          0.933137   \n",
       "27   Chunk size 1000, 0%, K=6      0.930060          0.933761   \n",
       "28   Chunk size 1000, 0%, K=7      0.911223          0.825997   \n",
       "29  Parent Retriever 1000-200      0.733333          0.753330   \n",
       "30   Parent Retriever 500-100      0.820649          0.835459   \n",
       "31  Parent Retriever 1500-200      0.817811          0.835280   \n",
       "32                        MMR      0.478823          0.873469   \n",
       "33                       BM25      0.473940          0.406398   \n",
       "34                Ensambler 1      0.505687          0.842514   \n",
       "35                Ensambler 2      0.912500          0.821099   \n",
       "36                Ensambler 3      0.896586          0.909414   \n",
       "37               Search query      0.741233          0.796264   \n",
       "\n",
       "    Context Precision  Context Recall  Answer Similarity  Answer Correctness  \\\n",
       "0                 NaN             NaN           0.841376            0.410613   \n",
       "1                 NaN             NaN           0.900098            0.492424   \n",
       "2            0.597222        0.820833           0.878165            0.413080   \n",
       "3            0.597222        0.771429           0.878165            0.402142   \n",
       "4            0.907841        0.752864           0.731083            0.795908   \n",
       "5            0.597222        0.808333           0.882359            0.441887   \n",
       "6            0.907932        0.753544           0.731083            0.802336   \n",
       "7            0.616525        0.783333           0.890919            0.541697   \n",
       "8            0.616575        0.750000           0.890744            0.532502   \n",
       "9            0.654176        0.783333           0.890744            0.533308   \n",
       "10           0.582974        0.783333           0.878419            0.542546   \n",
       "11           0.597222        0.775000           0.880496            0.433163   \n",
       "12           0.654338        0.750000           0.878244            0.534169   \n",
       "13           0.619133        0.783333           0.890919            0.544212   \n",
       "14           0.616641        0.783333           0.864847            0.542546   \n",
       "15           0.829433        0.633333           0.801053            0.873055   \n",
       "16           0.655261        0.783333           0.878579            0.544252   \n",
       "17           0.652623        0.750000           0.889133            0.543388   \n",
       "18           0.582052        0.750000           0.874847            0.542521   \n",
       "19           0.652841        0.750000           0.878084            0.532462   \n",
       "20           0.617704        0.783333           0.868084            0.532438   \n",
       "21           0.619150        0.783333           0.878084            0.534129   \n",
       "22           0.912243        0.752622           0.764752            0.815992   \n",
       "23           0.939013        0.654342           0.742385            0.858955   \n",
       "24           0.618746        0.730000           0.705053            0.576019   \n",
       "25           0.615346        0.722222           0.739531            0.773110   \n",
       "26           0.578194        0.780000           0.893165            0.440939   \n",
       "27           0.594889        0.737576           0.897546            0.498981   \n",
       "28           0.635716        0.884008           0.913225            0.521667   \n",
       "29           0.741667        0.726355           0.891473            0.468106   \n",
       "30           0.570873        0.727381           0.905459            0.540618   \n",
       "31           0.576520        0.735714           0.905459            0.540618   \n",
       "32           0.826085        0.699968           0.754470            0.844428   \n",
       "33           0.661178        0.505556           0.722256            0.758951   \n",
       "34           0.708968        0.610430           0.784137            0.845242   \n",
       "35           0.517745        0.785714           0.905480            0.527203   \n",
       "36           0.523145        0.976190           0.623810            0.660094   \n",
       "37           0.453837        0.998773           0.612588            0.706091   \n",
       "\n",
       "     Average  \n",
       "0   0.663610  \n",
       "1   0.742388  \n",
       "2   0.747623  \n",
       "3   0.738421  \n",
       "4   0.753982  \n",
       "5   0.746532  \n",
       "6   0.750303  \n",
       "7   0.763972  \n",
       "8   0.759358  \n",
       "9   0.764096  \n",
       "10  0.749429  \n",
       "11  0.714423  \n",
       "12  0.755189  \n",
       "13  0.762624  \n",
       "14  0.751776  \n",
       "15  0.744261  \n",
       "16  0.761946  \n",
       "17  0.762564  \n",
       "18  0.742685  \n",
       "19  0.756936  \n",
       "20  0.752012  \n",
       "21  0.754936  \n",
       "22  0.762262  \n",
       "23  0.742595  \n",
       "24  0.621834  \n",
       "25  0.694306  \n",
       "26  0.752850  \n",
       "27  0.765469  \n",
       "28  0.781973  \n",
       "29  0.719044  \n",
       "30  0.733406  \n",
       "31  0.735234  \n",
       "32  0.746207  \n",
       "33  0.588047  \n",
       "34  0.716163  \n",
       "35  0.744957  \n",
       "36  0.764873  \n",
       "37  0.718131  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df = pd.concat([results_df, df_result_search_query], ignore_index=True)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### change model to GPT-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>System</th>\n",
       "      <th>Faithfulness</th>\n",
       "      <th>Answer Relevancy</th>\n",
       "      <th>Context Precision</th>\n",
       "      <th>Context Recall</th>\n",
       "      <th>Answer Similarity</th>\n",
       "      <th>Answer Correctness</th>\n",
       "      <th>Average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Chunk size 1000, 0%, K=7</td>\n",
       "      <td>0.911223</td>\n",
       "      <td>0.825997</td>\n",
       "      <td>0.635716</td>\n",
       "      <td>0.884008</td>\n",
       "      <td>0.913225</td>\n",
       "      <td>0.521667</td>\n",
       "      <td>0.781973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Chunk size 1000, 0%, K=6</td>\n",
       "      <td>0.930060</td>\n",
       "      <td>0.933761</td>\n",
       "      <td>0.594889</td>\n",
       "      <td>0.737576</td>\n",
       "      <td>0.897546</td>\n",
       "      <td>0.498981</td>\n",
       "      <td>0.765469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Ensambler 3</td>\n",
       "      <td>0.896586</td>\n",
       "      <td>0.909414</td>\n",
       "      <td>0.523145</td>\n",
       "      <td>0.976190</td>\n",
       "      <td>0.623810</td>\n",
       "      <td>0.660094</td>\n",
       "      <td>0.764873</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      System  Faithfulness  Answer Relevancy  \\\n",
       "28  Chunk size 1000, 0%, K=7      0.911223          0.825997   \n",
       "27  Chunk size 1000, 0%, K=6      0.930060          0.933761   \n",
       "36               Ensambler 3      0.896586          0.909414   \n",
       "\n",
       "    Context Precision  Context Recall  Answer Similarity  Answer Correctness  \\\n",
       "28           0.635716        0.884008           0.913225            0.521667   \n",
       "27           0.594889        0.737576           0.897546            0.498981   \n",
       "36           0.523145        0.976190           0.623810            0.660094   \n",
       "\n",
       "     Average  \n",
       "28  0.781973  \n",
       "27  0.765469  \n",
       "36  0.764873  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_3_highest = results_df.nlargest(3, \"Average\")\n",
    "top_3_highest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.to_csv(f\"../ballad/results/results_summarize.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "passing column names as 'ground_truths' is deprecated and will be removed in the next version, please use 'ground_truth' instead. Note that `ground_truth` should be of type string and not Sequence[string] like `ground_truths`\n",
      "Evaluating: 100%|██████████| 60/60 [00:10<00:00,  5.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average score is: 0.7738937121554766\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>System</th>\n",
       "      <th>Faithfulness</th>\n",
       "      <th>Answer Relevancy</th>\n",
       "      <th>Context Precision</th>\n",
       "      <th>Context Recall</th>\n",
       "      <th>Answer Similarity</th>\n",
       "      <th>Answer Correctness</th>\n",
       "      <th>Average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Chunk 1000, overlap 0%, GPT-4</td>\n",
       "      <td>0.725556</td>\n",
       "      <td>0.913338</td>\n",
       "      <td>0.608115</td>\n",
       "      <td>0.913333</td>\n",
       "      <td>0.890853</td>\n",
       "      <td>0.592167</td>\n",
       "      <td>0.773894</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          System  Faithfulness  Answer Relevancy  \\\n",
       "0  Chunk 1000, overlap 0%, GPT-4      0.725556          0.913338   \n",
       "\n",
       "   Context Precision  Context Recall  Answer Similarity  Answer Correctness  \\\n",
       "0           0.608115        0.913333           0.890853            0.592167   \n",
       "\n",
       "    Average  \n",
       "0  0.773894  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_k7_1000_0_gpt4, results_df = run_and_evaluate(f\"Chunk 1000, overlap 0%, GPT-4\", retriever_7, prompt, llm_gpt4, results_df)\n",
    "result_k7_1000_0_gpt4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "passing column names as 'ground_truths' is deprecated and will be removed in the next version, please use 'ground_truth' instead. Note that `ground_truth` should be of type string and not Sequence[string] like `ground_truths`\n",
      "Evaluating:  35%|███▌      | 21/60 [00:05<00:07,  5.11it/s]Runner in Executor raised an exception\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400, 'innererror': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_result': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': True, 'severity': 'medium'}}}}}\n",
      "Evaluating: 100%|██████████| 60/60 [00:11<00:00,  5.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average score is: 0.7504103152560165\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>System</th>\n",
       "      <th>Faithfulness</th>\n",
       "      <th>Answer Relevancy</th>\n",
       "      <th>Context Precision</th>\n",
       "      <th>Context Recall</th>\n",
       "      <th>Answer Similarity</th>\n",
       "      <th>Answer Correctness</th>\n",
       "      <th>Average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Chunk 1000, overlap 0%, GPT-4</td>\n",
       "      <td>0.548149</td>\n",
       "      <td>0.806642</td>\n",
       "      <td>0.799038</td>\n",
       "      <td>0.714333</td>\n",
       "      <td>0.784592</td>\n",
       "      <td>0.849707</td>\n",
       "      <td>0.75041</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          System  Faithfulness  Answer Relevancy  \\\n",
       "0  Chunk 1000, overlap 0%, GPT-4      0.548149          0.806642   \n",
       "\n",
       "   Context Precision  Context Recall  Answer Similarity  Answer Correctness  \\\n",
       "0           0.799038        0.714333           0.784592            0.849707   \n",
       "\n",
       "   Average  \n",
       "0  0.75041  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever6 =  db_k.as_retriever(search_kwargs={\"k\": 6})\n",
    "result_k6_1000_0_gpt4, results_df = run_and_evaluate(f\"Chunk 1000, overlap 0%, GPT-4\", retriever6, prompt, llm_gpt4, results_df)\n",
    "result_k6_1000_0_gpt4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "passing column names as 'ground_truths' is deprecated and will be removed in the next version, please use 'ground_truth' instead. Note that `ground_truth` should be of type string and not Sequence[string] like `ground_truths`\n",
      "Evaluating:   0%|          | 0/60 [00:00<?, ?it/s]Runner in Executor raised an exception\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400, 'innererror': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_result': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'low'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': True, 'severity': 'medium'}}}}}\n",
      "Evaluating:  30%|███       | 18/60 [00:10<00:16,  2.50it/s]Runner in Executor raised an exception\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400, 'innererror': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_result': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': True, 'severity': 'medium'}}}}}\n",
      "Evaluating: 100%|██████████| 60/60 [00:23<00:00,  2.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average score is: 0.7955151771937771\n",
      "This is the new best value!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>System</th>\n",
       "      <th>Faithfulness</th>\n",
       "      <th>Answer Relevancy</th>\n",
       "      <th>Context Precision</th>\n",
       "      <th>Context Recall</th>\n",
       "      <th>Answer Similarity</th>\n",
       "      <th>Answer Correctness</th>\n",
       "      <th>Average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ensambler 3, GPT-4</td>\n",
       "      <td>0.904894</td>\n",
       "      <td>0.602332</td>\n",
       "      <td>0.892218</td>\n",
       "      <td>0.888205</td>\n",
       "      <td>0.677399</td>\n",
       "      <td>0.808044</td>\n",
       "      <td>0.795515</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               System  Faithfulness  Answer Relevancy  Context Precision  \\\n",
       "0  Ensambler 3, GPT-4      0.904894          0.602332           0.892218   \n",
       "\n",
       "   Context Recall  Answer Similarity  Answer Correctness   Average  \n",
       "0        0.888205           0.677399            0.808044  0.795515  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_ensemble3_gpt4, results_df = run_and_evaluate(f\"Ensambler 3, GPT-4\", ensemble_retriever_3, prompt, llm_gpt4, results_df)\n",
    "result_ensemble3_gpt4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.to_csv(f\"../ballad/results/results_summarize.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
